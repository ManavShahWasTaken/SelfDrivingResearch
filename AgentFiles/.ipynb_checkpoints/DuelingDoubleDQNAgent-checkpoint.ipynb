{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0z6tk-uX9bwY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import socket\n",
    "# import shutil\n",
    "# from skimage import io\n",
    "\n",
    "class State:\n",
    "    def __init__(self, state_data):\n",
    "        self.state_data = np.asarray(state_data)\n",
    "  \n",
    "    def process_state(self):\n",
    "        pass\n",
    "  \n",
    "    def get_batch_tensor(self):\n",
    "        holder = np.asarray(self.state_data)\n",
    "        holder.reshape((1, ) + holder.shape)\n",
    "        return holder\n",
    "  \n",
    "    def get_individual_tensor(self):\n",
    "        return np.asarray(self.state_data)\n",
    "\n",
    "    def get_shape(self):\n",
    "        return self.state_data.shape\n",
    "  \n",
    "    def display(self):\n",
    "        print(self.state_data)\n",
    "        \n",
    "# ------------------------------------\n",
    "\n",
    "class Frame(State):\n",
    "    def __init__(self, state_data, crop_factor=None, destination_size=None, vert_cent=0.5):\n",
    "        State.__init__(self, state_data)\n",
    "#         self.state_data = self.process_state(crop_factor, vert_cent, destination_shape)\n",
    "        self.state_data = self.process_state([0.7, 1.0], 0.7, (128,64))\n",
    "  \n",
    "    def process_state(self, crop_factor, vert_cent, destination_shape):\n",
    "        \"\"\"\n",
    "        Does all the processing of the frame using the helper functions\n",
    "        \"\"\"\n",
    "        frame = self.crop_frame(self.state_data, crop_factor, vert_cent)\n",
    "        frame = self.normalise_frame(frame)\n",
    "        frame = self.gray_scale(frame) # cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        assert len(frame.shape) == 2\n",
    "        frame = self.downsample_frame(frame, destination_shape)\n",
    "        return frame\n",
    "\n",
    "  \n",
    "    def gray_scale(self, frame, gray_scale_factor=[0.3, 0.3, 0.3]):\n",
    "        frame = np.dot(frame, np.asarray(gray_scale_factor))\n",
    "        return frame\n",
    "\n",
    "    def normalise_frame(self, frame):\n",
    "        frame = frame.astype('float32') / 255.0\n",
    "        return frame\n",
    "  \n",
    "    def downsample_frame(self, frame, destination_shape):\n",
    "        \"\"\"\n",
    "        downsamples the frame. decreases the resolution\n",
    "        \"\"\"\n",
    "        frame = cv2.resize(np.asarray(frame), dsize=destination_shape, interpolation=cv2.INTER_CUBIC)\n",
    "        return frame\n",
    "  \n",
    "    def crop_frame(self, frame, crop_factor, vert_cent):\n",
    "        \"\"\"\n",
    "        input is the frame\n",
    "        output is the cropped frame\n",
    "        crop_factor is the ratio at which you want to crop the height and width(0.8, 0.8)\n",
    "        cent is the ratio at which the centre of the cropped frame should be\n",
    "        \"\"\"\n",
    "        if crop_factor is None:\n",
    "          return frame\n",
    "    \n",
    "        height_factor = int((crop_factor[0]*frame.shape[0]) // 2)\n",
    "        width_factor = int((crop_factor[1]*frame.shape[1]) // 2)\n",
    "        vert_cent = int(frame.shape[0]*vert_cent)\n",
    "        width_cent = int(frame.shape[1]*0.5)\n",
    "\n",
    "        frame = frame[vert_cent - height_factor: vert_cent + height_factor, \n",
    "                      width_cent - width_factor: width_cent + width_factor]\n",
    "        return frame\n",
    "\n",
    "# ------------------------------------\n",
    "class DataBuffer:\n",
    "    \"\"\"\n",
    "    Keeps track of n latest states \n",
    "    \"\"\"\n",
    "  \n",
    "    def __init__(self, size=1):\n",
    "        self.buffer = []\n",
    "        self.size = size\n",
    "\n",
    "    def get_input_tensor(self, in_batch=True):\n",
    "        arr = np.array(self.buffer)\n",
    "        if self.size == 1 or in_batch:\n",
    "            return arr\n",
    "        else:\n",
    "            return arr.reshape((1, ) + arr.shape)\n",
    "    \n",
    "    def get_input_shape(self):\n",
    "        return np.asarray(self.current_state[0]).shape\n",
    "\n",
    "    def assign_to_buffer(self, state):\n",
    "        if isinstance(state, State):\n",
    "            state = state.get_individual_tensor()\n",
    "        if len(self.buffer) >= self.size:\n",
    "            self.buffer.pop(0)\n",
    "        self.buffer.append(state)\n",
    "        \n",
    "# ------------------------------------\n",
    "\n",
    "class FrameBuffer(DataBuffer):\n",
    "    def __init__(self, size = 4):\n",
    "        DataBuffer.__init__(self, size=size)\n",
    "    \n",
    "    def get_input_shape(self):\n",
    "        return self.get_input_tensor().shape\n",
    "  \n",
    "    def get_input_tensor(self, in_batch=True):\n",
    "        temp = np.array(self.buffer)\n",
    "        return  temp.transpose((1, 2, 0))\n",
    "    \n",
    "    def assign_to_buffer(self, state):\n",
    "        if isinstance(state, State):\n",
    "            state = state.get_individual_tensor()\n",
    "        # if buffer not initialised\n",
    "        if len(self.buffer) == 0:\n",
    "            self.buffer = [state]\n",
    "            return\n",
    "\n",
    "        if len(self.buffer) >= self.size:\n",
    "            self.buffer.pop(0)\n",
    "        \n",
    "        self.buffer.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jh-452ClVFpT"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "class EnvironmentWrapper:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        # initialise comms with the simulator here\n",
    "        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # initialise the socket\n",
    "        # connect to localhost, port 2345 \n",
    "        self.sock.bind((\"127.0.0.1\", 4444))\n",
    "        self.sock.listen(1)\n",
    "        print(\"Waiting to connect to Simulator...\")\n",
    "        self.clientsocket, _ = self.sock.accept() # connect to simulator [BLOCKING]\n",
    "        print(\"Connected to simulator!\")\n",
    "        # =========================================\n",
    "        \n",
    "        \n",
    "        # initialising frame buffer\n",
    "        self.buffer_size = 4 # could change this \n",
    "        \n",
    "         # this is the FrameBuffer that keeps track of the latest frames.\n",
    "         #initialising the frame buffer by just giving it multiple copies of the same starting frame\n",
    "        # =========================================\n",
    "        \n",
    "        self.current_state = None\n",
    "        \n",
    "        self.current_buffer = None\n",
    "        \n",
    "        self.prev_dist = 0\n",
    "        \n",
    "        self.time_steps = 0\n",
    "        \n",
    "        self.done = False\n",
    "        \n",
    "        self.max_time_steps_per_episode = 500 #change this based on the enviorment\n",
    "        \n",
    "        # initialise buffer\n",
    "        self.current_buffer = FrameBuffer(size = self.buffer_size)\n",
    "        \n",
    "        # =========================================\n",
    "        \n",
    "        \n",
    "        # Create target directory if it doesn't exist\n",
    "       \n",
    "        parent_path = os.path.abspath(os.path.join(\"\", os.pardir))\n",
    "        self.final_path = parent_path + \"/simulation/Screenshots\"\n",
    "        if not os.path.exists(self.final_path):\n",
    "            os.mkdir(self.final_path)\n",
    "            print(\"Directory \" , self.final_path,  \" Created \")\n",
    "        else:    \n",
    "            print(\"Directory \" , self.final_path,  \" already exists\")\n",
    "            \n",
    "        \n",
    "        # Save scr1 to Screenshots if it doesn't already exist\n",
    "        if not os.path.exists(self.final_path + '/scr1.png'):\n",
    "            scr1 = Image.open(self.parent_path + '/simulation/scr1.png', 'r')\n",
    "            scr1.save(self.final_path + \"/scr1.png\", \"PNG\")\n",
    "        \n",
    "        # reset actually initializes self.current_state, self.current_buffer etc.\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.action_space = ['as', 'ar', 'al', 'ds', 'dr', 'dl', 'bs', 'br', 'bl']\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_input_shape(self):\n",
    "        \"\"\"\n",
    "        returns the input shape for the input layer of the network\n",
    "        \"\"\"\n",
    "        return self.current_buffer.get_input_shape()\n",
    "    \n",
    "#     def get_state_shape(self):\n",
    "#         \"\"\"\n",
    "#         not to be confused with the input shape. This is the shape of individual state (the shape of an individual processed shape of the environment)\n",
    "#         \"\"\"\n",
    "#         return self.current_state\n",
    "    \n",
    "    def get_random_action(self):\n",
    "        \"\"\"\n",
    "        returns a random action to be taken. [steering, acceleration, brake]\n",
    "        \"\"\"\n",
    "        return random.choice(self.action_space)\n",
    "    \n",
    "    def get_action_at_index(self, index):\n",
    "        return self.action_space[index]\n",
    "    \n",
    "    def get_num_action_space(self):\n",
    "        \"\"\"\n",
    "        returns the number of permuations of valide actions. For Eg. [steer left, accelerate and no brake] is ONE action\n",
    "        [steer right, accelerate and brake] is invalid as we cannot accelerate and brake at the same time.\n",
    "        there are 9 possible actions I think?\n",
    "        \"\"\"\n",
    "        return len(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        resets the environment. self.done denotes whether the episode is done i.e. the car has crashed or we have stopped it\n",
    "        \"\"\"\n",
    "        self.done = False\n",
    "        self.time_steps = 0\n",
    "        \n",
    "        tup = self.step('reset') # initial step. Says don't do anything but send the first 4 frames and game info\n",
    "        self.current_state, _, self.done = tup\n",
    "        return self.current_state[0] # send only the frames\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\" \n",
    "        does the action and returns the reward for that action along with the next state\n",
    "\n",
    "        This function may get complicated as it has to interact with the car simulator throught sockets.\n",
    "        \"\"\"\n",
    "        self.time_steps += 1\n",
    "        \n",
    "        if not self.is_done():\n",
    "            # if the episode has not ended\n",
    "            #=======================\n",
    "            \n",
    "            # send the action\n",
    "            self.send_message(action)\n",
    "            \n",
    "            # wait for results from that action\n",
    "            angle, distance, speed, self.done, frames_captured = self.get_game_stats() # blocking line\n",
    "            # print(\"5: info:{0}, {1}, {2}, {3}, {4}\".format(angle, distance, speed, self.done, frames_captured))\n",
    "            \n",
    "            \n",
    "            # add images from path to current_buffer\n",
    "            for i in range(1, frames_captured + 1):\n",
    "                # each Frame object is then assigned to the FrameBuffer class in chronological order\n",
    "                path = self.final_path + '/scr{0}.png'.format(i)\n",
    "                self.current_buffer.assign_to_buffer(self.get_frame(path))\n",
    "            \n",
    "            buffer_tensor = self.current_buffer.get_input_tensor()\n",
    "            # ========================================\n",
    "            \n",
    "            # calculate reward\n",
    "            dist_delta = self.prev_dist - distance\n",
    "            self.prev_dist = distance\n",
    "            if abs(dist_delta) > 10:\n",
    "                dist_delta = 5 # if there's too big a negative jump in the distance, the car has passed a checkpoint.\n",
    "                # so, don't penalise it for that.\n",
    " \n",
    "            reward = (dist_delta * 0.9) - (abs(angle) * 0.1)\n",
    "            #=================\n",
    "            \n",
    "            # A buffer is a collection of consecutive frames that we feed to the NN. These frames are already processed.\n",
    "            \n",
    "            # the current state consists of all the information from the environment\n",
    "            self.current_state = (buffer_tensor, angle, distance, speed)\n",
    "            \n",
    "            # this returns the state of the environment after the action has been completed, the reward for the action and if the episode ended.\n",
    "            return self.current_state , reward, self.done\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def send_message(self, string):\n",
    "        self.clientsocket.sendall(string.encode())\n",
    "    \n",
    "    def receive_message(self):\n",
    "        data  = self.clientsocket.recv(256).decode()\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def is_done(self):\n",
    "        \"\"\"\n",
    "        returns if the episode is finished\n",
    "        \"\"\"\n",
    "        return self.done\n",
    "        \n",
    "    \n",
    "    def get_frame(self, path: str) -> Frame:\n",
    "        \"\"\"\n",
    "        communicates with the sim to get the latest state/frame. \n",
    "        returns a Frame object\n",
    "        Get image from path then convert to np array then make a frame object\n",
    "        \"\"\"\n",
    "        image = Image.open(path, 'r')\n",
    "        image.load()\n",
    "        np_data = np.asarray(image, dtype=\"float32\" )\n",
    "        return Frame(np_data)\n",
    "    \n",
    "    \n",
    "    # def delete_screenshots(self, folder_path: str) -> None:\n",
    "    #     \"\"\"\n",
    "    #     This method deletes the four screenshots saved in folder_path, along with the entire folder.\n",
    "    #     Method must be called after all four screenshots are converted to Frame objects.\n",
    "    #     \"\"\"\n",
    "    #     shutil.rmtree(folder_path)\n",
    "    \n",
    "    \n",
    "    def get_current_state():\n",
    "        \"\"\"\n",
    "        get the last n frames from the simulator (they might be stored in a folder by the simulator)\n",
    "        and store them in a buffer and return them\n",
    "        \"\"\"\n",
    "        return self.current_buff\n",
    "\n",
    "    \n",
    "    def get_game_stats(self):\n",
    "        \"\"\"\n",
    "        returns a tuple of angle, distance from checkpoint and speed from the sim. Again requires comms with simulator.\n",
    "        \"\"\"\n",
    "        # wait for info to arrive\n",
    "        string = self.receive_message()\n",
    "        \n",
    "        # process string\n",
    "        value_list = string.split(\", \")\n",
    "        angle = float(value_list[0])\n",
    "        distance = float(value_list[1])\n",
    "        speed = float(value_list[2])\n",
    "        crashed_state = False\n",
    "        if value_list[3] == '1':\n",
    "            crashed_state = True\n",
    "        frames_captured = int(value_list[4])\n",
    "        # return tuple of values\n",
    "        return angle, distance, speed, crashed_state, frames_captured\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        in case we need to 'close' the environment\n",
    "        \"\"\"\n",
    "        self.sock.close()\n",
    "        self.clientsocket.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u36eHVMV285q"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, environment, network, run_only=False, eps_decay_rate=0.9975,max_exp_rate=1.0, min_exp_rate=0.05):\n",
    "        self.env = environment # this should be the environment wrapper class\n",
    "        \n",
    "        if not run_only:\n",
    "            self.exp_rate = max_exp_rate     # our network starts off with this exploration rate\n",
    "        else:\n",
    "            self.exp_rate = 0.0\n",
    "            self.min_exp_rate = 0.0\n",
    "        \n",
    "        self.min_exp_rate = min_exp_rate  # have at least 0.01 exploration rate at all times\n",
    "        \n",
    "        self.decay_rate = eps_decay_rate   # decay the exploration rate at this rate\n",
    "        \n",
    "        self.time_step = 0     # keeps track of time steps\n",
    "        \n",
    "        self.network = network\n",
    "    \n",
    "    def take_action(self, current_state):\n",
    "        # Implement the epsilon greedy strategy \n",
    "        result = random.random()                      # get a random number from 0 to 1 with linear distribution\n",
    "        if result > self.get_exp_rate():              # if it falls over the explore rate, exploit\n",
    "            # Get the action with the maximum q-value\n",
    "            action = self.env.get_action_at_index(\n",
    "                self.network.get_max_q_value_index(current_state, which_net = 'online', batch=False))  # exploit\n",
    "        else:                                         # if it falls under the explore rate, explore\n",
    "            action = self.env.get_random_action()          # explore (generate a random action from the environment class)\n",
    "            \n",
    "        self.increment_time_step()                    # increment time step as well as update the decay rate\n",
    "        next_state, reward, done = self.env.step(action)# finally, take the action and record the reward\n",
    "        \n",
    "        return current_state, self.env.action_space.index(action), reward, next_state[0], done  # return an experience Tuple\n",
    "        \n",
    "    \n",
    "    def reset_time_steps(self, i=0):\n",
    "        self.timesteps = i\n",
    "    \n",
    "    def increment_time_step(self):\n",
    "        self.time_step += 1\n",
    "    \n",
    "    def update_epsilon(self):\n",
    "        if self.exp_rate > self.min_exp_rate:\n",
    "            self.exp_rate = self.exp_rate * self.decay_rate\n",
    "        else:\n",
    "            self.exp_rate = self.min_exp_rate\n",
    "    \n",
    "    def get_exp_rate(self):\n",
    "        return self.exp_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MVpqLFJ83IXp",
    "outputId": "27566a6e-9187-4053-ce13-02fa2abb6cbe"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "class NetworkTracker:\n",
    "    \n",
    "    def __init__(self, environment, source=True, verbose = True, network_name = None): # pass in the environment which has input shape of the frame\n",
    "        self.network_name = network_name\n",
    "        if source:\n",
    "            self.model = models.load_model(self.network_name)\n",
    "        else:\n",
    "            self.model = self.define_model(environment)\n",
    "        \n",
    "        self.target_model = None\n",
    "        self.clone_policy()\n",
    "        \n",
    "        self.verbose = 0\n",
    "        if verbose:\n",
    "            self.verbose = 1\n",
    "              \n",
    "    def define_model(self, env):\n",
    "        \n",
    "        inp_layer = layers.Input(env.get_input_shape())\n",
    "        \n",
    "        conv_1 = layers.Conv2D(filters=10, \n",
    "                                kernel_size=(4,4), \n",
    "                                activation='relu')(inp_layer) # first layer takes input shape from the environment\n",
    "        \n",
    "        maxpool_1 = layers.MaxPool2D((3, 3))(conv_1)\n",
    "        \n",
    "        conv_2 = layers.Conv2D(filters=20, kernel_size = (3, 3), strides=2, activation='relu')(maxpool_1)\n",
    "\n",
    "        maxpool_2 = layers.MaxPool2D(3, 3)(conv_2)\n",
    "        \n",
    "        flatten = layers.Flatten()(maxpool_2)\n",
    "        \n",
    "        adv_dense_1 = layers.Dense(64, activation = 'relu')(flatten)\n",
    "        \n",
    "        adv_out = layers.Dense(env.get_num_action_space(), activation='linear', name = 'advantage') (adv_dense_1)\n",
    "        \n",
    "        val_dense_1 = layers.Dense(32, activation = 'relu')(flatten)\n",
    "        \n",
    "        val_out = layers.Dense(1, activation='linear', name = 'value') (val_dense_1)\n",
    "        \n",
    "        def q_out(x):\n",
    "            value = x[0]\n",
    "            advantage = x[1]\n",
    "            return value + advantage\n",
    "        \n",
    "        q_output = layers.Lambda(q_out)([val_out, adv_out])\n",
    "        \n",
    "        model = models.Model(inp_layer, q_output, name='dueling_dqn')\n",
    "        \n",
    "        model.compile(optimizer=Adam(lr=0.0012), loss='mse')\n",
    "        return model\n",
    "    \n",
    "    def get_q_values(self, states, which_net = 'online', batch = False):\n",
    "        \"\"\"\n",
    "        get q values for specified states.\n",
    "        INPUTS:\n",
    "        1. states: the input states\n",
    "        2. which_net: which net you want the prediction from\n",
    "        3. batch: true if there are multiple states, false if there is only one state\n",
    "        \"\"\"\n",
    "        if isinstance(states[0], DataBuffer): # if you have a list of buffers, convert them to numpy tensors\n",
    "            states = np.asarray([i.get_input_tensor(in_batch=True) for i in states])\n",
    "        \n",
    "        if (not batch) and (not states.shape[0] == 1):\n",
    "            states = np.expand_dims(states, axis=0)\n",
    "        \n",
    "        output_tensor = None\n",
    "        \n",
    "        if which_net == 'online':\n",
    "            output_tensor = self.model.predict(states) \n",
    "        elif which_net == 'target':\n",
    "            output_tensor = self.target_model.predict(states) \n",
    "        \n",
    "        \n",
    "        if not batch:\n",
    "            return output_tensor[0]  # you want to convert the 2 dimensional output to 1 dimension to call argmax\n",
    "        else:\n",
    "            return output_tensor\n",
    "    \n",
    "    def get_max_q_value_index(self, states, which_net = 'online', batch=False):\n",
    "        return np.argmax(self.get_q_values(states, which_net=which_net, batch = batch), axis=int(batch))\n",
    "    \n",
    "    def fit(self, states_batch, targets_batch):\n",
    "        \"\"\"\n",
    "        Fit the states with the target batch\n",
    "        \"\"\"\n",
    "        self.model.fit(states_batch, targets_batch, verbose=1)\n",
    "        \n",
    "    def clone_policy(self):\n",
    "        \"\"\"\n",
    "        Clone the target policy\n",
    "        \"\"\"\n",
    "        self.model.save(self.network_name)\n",
    "        self.target_model = models.load_model(self.network_name)\n",
    "                  \n",
    "    def get_model_summary(self):\n",
    "        \"\"\"\n",
    "        Return a summary of the defined model\n",
    "        \"\"\"\n",
    "        return self.model.summary()\n",
    "    \n",
    "    def save_policy(self):\n",
    "        self.model.save(self.network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "class Memory:\n",
    "    def __init__(self, size, save_path, mem_source = None):\n",
    "        self.save_path = save_path\n",
    "        self.replay = []\n",
    "        self.limit = size\n",
    "        self.exp_count = 0\n",
    "        if mem_source is not None:\n",
    "            # pick up memory from the specified progess folder\n",
    "            with open(mem_source + '/memory.pkl', 'rb') as file:\n",
    "                self.replay = pickle.load(file)[:self.limit] # limit the list size based on the memory limit you specify\n",
    "            \n",
    "            self.exp_count = len(self.replay)\n",
    "    \n",
    "    def push(self, experience):\n",
    "        self.exp_count += 1\n",
    "        \n",
    "        if self.exp_count < self.limit:\n",
    "            self.replay.append(experience)  #append to experiences\n",
    "        else:\n",
    "            self.replay[self.exp_count%len(self.replay)] = experience  #wrap around if the memory capacity is reached\n",
    "        assert len(self.replay) <= self.limit\n",
    "        \n",
    "    def is_usable(self, batch_size):\n",
    "        return len(self.replay) >= batch_size\n",
    "    \n",
    "    def reset_replay_memory(self):\n",
    "        self.exp_count = 0\n",
    "        self.replay = []\n",
    "        \n",
    "    def save_to_disk(self):\n",
    "        # dump memory in the \n",
    "        with open(self.save_path + '/memory.pkl', 'wb') as file:\n",
    "            pickle.dump(self.replay, file)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.replay, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tensors(sample):\n",
    "    \"\"\"\n",
    "    takes a sample of experiences and converts them into individual tensors.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    next_states = []\n",
    "    done_tensor = []\n",
    "    for experience in sample:\n",
    "        states.append(experience[0])\n",
    "        actions.append(experience[1])\n",
    "        rewards.append(experience[2])\n",
    "        next_states.append(experience[3])\n",
    "        done_tensor.append(experience[4])\n",
    "    \n",
    "    return np.asarray(states), np.asarray(actions), np.asarray(rewards), np.asarray(next_states), np.asarray(done_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_batch(states, actions, rewards, next_states, dones, net, gamma):\n",
    "    assert actions.ndim == 1\n",
    "    assert rewards.ndim == 1\n",
    "    assert dones.ndim == 1\n",
    "    assert len(actions) == len(rewards) == len(dones) == len(states) == len(next_states)\n",
    "    \n",
    "    target_q_values = net.get_q_values(states, which_net = 'online', batch = True) # get the q values from the current states\n",
    "    \n",
    "    which_acts = net.get_max_q_value_index(next_states, which_net= 'online', batch = True) # this gives you a list of action indices\n",
    "    \n",
    "    q_estimates = net.get_q_values(next_states, which_net = 'target', batch = True) # get the q estimates from the target net for the next states\n",
    "    \n",
    "    for index in range(len(target_q_values)):\n",
    "        # index indexes the batch axis\n",
    "        q_estimate = q_estimates[index]\n",
    "        decoupled_action = which_acts[index]\n",
    "        reward = rewards[index]\n",
    "        action_taken = actions[index]\n",
    "        ended = dones[index]\n",
    "        \n",
    "        # bellman equation related target value calculation for DDQNs\n",
    "        if not ended:\n",
    "            prev_target = q_estimate[decoupled_action]\n",
    "        else:\n",
    "            prev_target = 0\n",
    "        \n",
    "        target = reward + gamma * prev_target\n",
    "        \n",
    "        target_q_values[index][action_taken] = target # assign the target to the corresponding (state, action) pair\n",
    "\n",
    "    return target_q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tempfile import TemporaryFile\n",
    "quit = False\n",
    "import pickle \n",
    "def train_agent(contd=True, network_name = None, save_path = 'training_progress', contd_path = None, verbose=True, num_episodes=1500,\n",
    "                discount = 0.95, batch_size = 64, N = 40, memory_size = 1024, \n",
    "                eps_decay_rate=0.9975, max_exp_rate=1.0, min_exp_rate=0.05, max_reward = 1000 ):\n",
    "    # get all the hyperparameters in one place!\n",
    "            \n",
    "     \n",
    "    # initialise your environment\n",
    "    env = EnvironmentWrapper()\n",
    "    \n",
    "    # initialise your policy and target networks inside net\n",
    "    net = NetworkTracker(env, source=contd, verbose=verbose, network_name=network_name)\n",
    "    print(net.get_model_summary())\n",
    "    \n",
    "    # initialise your agent that will follow the epsilon greedy strategy\n",
    "    agent = Agent(env, net, eps_decay_rate=eps_decay_rate, max_exp_rate=max_exp_rate,min_exp_rate=min_exp_rate )    \n",
    "    \n",
    "    # initialise experience replay memory\n",
    "    memory = Memory(memory_size, save_path = save_path, mem_source = contd_path)\n",
    "    \n",
    "    # stores all the total reward per episode\n",
    "    \n",
    "    training_stats = []\n",
    "    epochs = []\n",
    "    starting_episode = 0\n",
    "    \n",
    "    sum_over_ten = 0\n",
    "    moving_avg = []\n",
    "    avg_epochs = []\n",
    "    \n",
    "    validations = []\n",
    "    validation_epochs = []\n",
    "    if contd:\n",
    "        with open(save_path + '/training_stats.pkl', 'rb') as file:\n",
    "            epochs, training_stats = pickle.load(file)\n",
    "#             counter_temp = 0\n",
    "#             temp_sum = 0\n",
    "#             t = 0\n",
    "#             for stat in training_stats:\n",
    "#                 t += 1\n",
    "#                 counter_temp += 1\n",
    "#                 temp_sum += stat\n",
    "#                 if counter_temp%10 == 0:\n",
    "#                     counter_temp = 0\n",
    "#                     avg = temp_sum / 10.0\n",
    "#                     moving_avg.append(avg)\n",
    "#                     avg_epochs.append(t)\n",
    "#                     temp_sum = 0\n",
    "        \n",
    "        with open(save_path + '/moving_average.pkl', 'rb') as file:\n",
    "            avg_epochs, moving_avg = pickle.load(file)          \n",
    "        \n",
    "        with open(save_path + '/episode_count.pkl', 'rb') as file:\n",
    "            starting_episode = pickle.load(file)\n",
    "            \n",
    "    # graph display init code\n",
    "    %matplotlib notebook\n",
    "    plt.rcParams['animation.html'] = 'jshtml'\n",
    "    fig = plt.figure()\n",
    "    subplot = fig.add_subplot(111)\n",
    "    \n",
    "    for episode_count in range(starting_episode, num_episodes):\n",
    "        # uncomment if you want to start the environmet with a random move\n",
    "        # state = env.step(env.get_random_action())[0]\n",
    "        valid_episode = False\n",
    "        \n",
    "        \n",
    "        # check if the environment is available to run\n",
    "        while not valid_episode:\n",
    "            # keeps track of how many steps has been since the reward hasn't moved\n",
    "            stuck_counter = 0\n",
    "\n",
    "            # keeps track of the total reward that we got for this episode\n",
    "            cumulative_reward = 0\n",
    "\n",
    "            # keeps track of steps in the episode.\n",
    "            counter = 0\n",
    "\n",
    "            # reset environement and record the initial state before every episode\n",
    "            state = env.reset()\n",
    "\n",
    "            # store the experiences in a temporary tuple so that we only add them to memory if it was a valid episode.\n",
    "            temp_exp = []\n",
    "            stuck = False\n",
    "            # ==============================\n",
    "            while not env.is_done() and not stuck and cumulative_reward < max_reward: # run the environment for one episode\n",
    "                counter += 1\n",
    "                current_state, action, reward, next_state, done = agent.take_action(state) # let the agent take an action for one time step\n",
    "                \n",
    "                cumulative_reward += reward # add the reward to total rewards.\n",
    "                \n",
    "                # check if the car is stuck when the reward isn't changing by much\n",
    "                if abs(reward) < 0.5:\n",
    "                    stuck_counter += 1\n",
    "                    if stuck_counter > 7:\n",
    "                        done = True\n",
    "                        stuck = True\n",
    "                else:\n",
    "                    stuck_counter = 0\n",
    "                experience = current_state, action, reward, next_state, done # experience tuple \n",
    "                state = next_state # update the current state\n",
    "                 # push the experience in memory\n",
    "                temp_exp.append(experience)\n",
    "            # ==============================\n",
    "            \n",
    "            if counter > 5:\n",
    "                valid_episode = True\n",
    "                for i in range(len(temp_exp)):\n",
    "                    # temp_exp[i][-1] = cumulative_reward\n",
    "                    memory.push(temp_exp[i])\n",
    "                sum_over_ten += cumulative_reward\n",
    "\n",
    "        agent.update_epsilon() # update the exploration rate of the agent after each episode\n",
    "\n",
    "        if memory.is_usable(batch_size):\n",
    "                experience_batch = memory.sample(batch_size) # sample randomly from memory\n",
    "                states, actions, rewards, next_states, done_tensor = extract_tensors(experience_batch) # unzips the tensors\n",
    "\n",
    "                target_batch = get_target_batch(states, actions, rewards, next_states, done_tensor, net, discount) # get a batch of target values to fit against\n",
    "\n",
    "                net.fit(states, target_batch) # fit the network\n",
    "\n",
    "        # append the training stats\n",
    "        training_stats.append(cumulative_reward)\n",
    "        epochs.append(episode_count)\n",
    "\n",
    "        # clone the target policy every N episodes.\n",
    "        if (episode_count + 1) % N == 0:\n",
    "            net.clone_policy()\n",
    "        \n",
    "        if  (episode_count) % (N*2) == 0:\n",
    "            performance = evaluate_agent(runs = 5, model_name = network_name, env = env)\n",
    "            validations.append(performance)\n",
    "            validation_epochs.append(epochs[-1])\n",
    "            with open(save_path + '/validation.pkl', 'wb') as file:\n",
    "                pickle.dump((validation_epochs, validations), file)\n",
    "            \n",
    "\n",
    "        # update the training chart every 10 episodes\n",
    "        if (episode_count + 1) % 10 == 0:\n",
    "            avg = sum_over_ten / 10.0\n",
    "            sum_over_ten = 0\n",
    "            moving_avg.append(avg)\n",
    "            avg_epochs.append(epochs[-1])\n",
    "            subplot.plot(epochs, training_stats, color='b')\n",
    "            subplot.plot(avg_epochs, moving_avg, color = 'r')\n",
    "            subplot.plot(validation_epochs, validations, color = 'g')\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "            # periodically save training progress.\n",
    "            memory.save_to_disk()\n",
    "            with open(save_path + '/training_stats.pkl', 'wb') as file:\n",
    "                pickle.dump((epochs, training_stats), file)\n",
    "            \n",
    "            with open(save_path + '/moving_average.pkl', 'wb') as file:\n",
    "                pickle.dump((avg_epochs, moving_avg), file)\n",
    "            \n",
    "            with open(save_path + '/episode_count.pkl', 'wb') as file:\n",
    "                pickle.dump(episode_count, file)\n",
    "            \n",
    "            with open(save_path + '/epsilon.pkl', 'wb') as file:\n",
    "                pickle.dump(agent.exp_rate, file)\n",
    "            \n",
    "\n",
    "        # if specified, print stats.\n",
    "        if verbose:\n",
    "            print(\"Episode Count: \", episode_count, \"\\t Cumulative Reward: \", round(cumulative_reward, 2), \"\\t eps: \", round(agent.exp_rate, 3) )\n",
    "\n",
    "    \n",
    "    memory.save_to_disk()\n",
    "    net.save_policy()\n",
    "    env.close()\n",
    "    \n",
    "    return epochs, training_stats, net\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(runs, model_name, env = None):\n",
    "    if env is None:\n",
    "        env = EnvironmentWrapper()\n",
    "    net = NetworkTracker(env, source=True, verbose=False, network_name=model_name)\n",
    "    agent = Agent(env, net, run_only = True)\n",
    "    \n",
    "    perf_sum = 0\n",
    "    for run in range(runs):\n",
    "        valid_episode = False\n",
    "        cumulative_reward = 0\n",
    "        time_steps = 0\n",
    "        while not valid_episode:\n",
    "            state = env.reset()\n",
    "            cumulative_reward = 0\n",
    "            time_steps = 0\n",
    "            stuck_counter = 0\n",
    "            stuck = False\n",
    "            while not env.is_done() and not stuck:\n",
    "                _ , action, reward, next_state, done = agent.take_action(state)\n",
    "                state = next_state\n",
    "                time_steps += 1\n",
    "                cumulative_reward += reward \n",
    "                if abs(reward) < 0.5:\n",
    "                    stuck_counter += 1\n",
    "                    if stuck_counter > 7:\n",
    "                        done = True\n",
    "                        stuck = True\n",
    "                else:\n",
    "                    stuck_counter = 0\n",
    "            \n",
    "            if time_steps > 3:\n",
    "                valid_episode = True\n",
    "                cumulative_reward = round(cumulative_reward, 2)\n",
    "        perf_sum += cumulative_reward\n",
    "        print('run {0}: cumulative_reward: {1}, ran for: {2} timesteps'.format(run, round(cumulative_reward, 2), time_steps))\n",
    "    \n",
    "    avg_perf = float(perf_sum/runs)\n",
    "    \n",
    "    print('average performance: ', avg_perf)\n",
    "#     env.close()\n",
    "    return avg_perf\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting to connect to Simulator...\n",
      "Connected to simulator!\n",
      "Directory  C:\\Users\\Sohaib Saqib\\Documents\\GitHub\\SelfDrivingResearch/simulation/Screenshots  already exists\n",
      "Model: \"dueling_dqn\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 128, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 61, 125, 10)  650         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 20, 41, 10)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 9, 20, 20)    1820        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 3, 6, 20)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 360)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           11552       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           23104       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "value (Dense)                   (None, 1)            33          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "advantage (Dense)               (None, 9)            585         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 9)            0           value[0][0]                      \n",
      "                                                                 advantage[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 37,744\n",
      "Trainable params: 37,744\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0: cumulative_reward: 6.64, ran for: 4 timesteps\n",
      "run 1: cumulative_reward: 13.41, ran for: 4 timesteps\n",
      "run 2: cumulative_reward: 12.83, ran for: 4 timesteps\n",
      "run 3: cumulative_reward: 13.69, ran for: 4 timesteps\n",
      "run 4: cumulative_reward: 7.51, ran for: 4 timesteps\n",
      "average performance:  10.815999999999999\n",
      "Episode Count:  0 \t Cumulative Reward:  20.76 \t eps:  0.999\n",
      "Episode Count:  1 \t Cumulative Reward:  15.72 \t eps:  0.998\n",
      "Episode Count:  2 \t Cumulative Reward:  16.64 \t eps:  0.997\n",
      "Episode Count:  3 \t Cumulative Reward:  4.03 \t eps:  0.996\n",
      "Episode Count:  4 \t Cumulative Reward:  16.14 \t eps:  0.995\n",
      "Episode Count:  5 \t Cumulative Reward:  11.49 \t eps:  0.994\n",
      "Episode Count:  6 \t Cumulative Reward:  15.31 \t eps:  0.993\n",
      "Episode Count:  7 \t Cumulative Reward:  15.43 \t eps:  0.992\n",
      "Episode Count:  8 \t Cumulative Reward:  22.78 \t eps:  0.991\n",
      "Episode Count:  9 \t Cumulative Reward:  15.75 \t eps:  0.99\n",
      "Episode Count:  10 \t Cumulative Reward:  22.23 \t eps:  0.989\n",
      "Episode Count:  11 \t Cumulative Reward:  6.67 \t eps:  0.988\n",
      "Episode Count:  12 \t Cumulative Reward:  7.22 \t eps:  0.987\n",
      "Episode Count:  13 \t Cumulative Reward:  4.06 \t eps:  0.986\n",
      "Episode Count:  14 \t Cumulative Reward:  18.43 \t eps:  0.985\n",
      "Episode Count:  15 \t Cumulative Reward:  4.82 \t eps:  0.984\n",
      "Episode Count:  16 \t Cumulative Reward:  1.76 \t eps:  0.983\n",
      "Episode Count:  17 \t Cumulative Reward:  20.06 \t eps:  0.982\n",
      "Episode Count:  18 \t Cumulative Reward:  6.3 \t eps:  0.981\n",
      "Episode Count:  19 \t Cumulative Reward:  17.89 \t eps:  0.98\n",
      "Episode Count:  20 \t Cumulative Reward:  6.3 \t eps:  0.979\n",
      "Episode Count:  21 \t Cumulative Reward:  8.39 \t eps:  0.978\n",
      "Episode Count:  22 \t Cumulative Reward:  5.72 \t eps:  0.977\n",
      "Episode Count:  23 \t Cumulative Reward:  17.98 \t eps:  0.976\n",
      "Episode Count:  24 \t Cumulative Reward:  31.57 \t eps:  0.975\n",
      "Episode Count:  25 \t Cumulative Reward:  18.53 \t eps:  0.974\n",
      "Episode Count:  26 \t Cumulative Reward:  7.61 \t eps:  0.973\n",
      "Episode Count:  27 \t Cumulative Reward:  23.09 \t eps:  0.972\n",
      "Episode Count:  28 \t Cumulative Reward:  22.73 \t eps:  0.971\n",
      "Episode Count:  29 \t Cumulative Reward:  13.29 \t eps:  0.97\n",
      "Episode Count:  30 \t Cumulative Reward:  17.37 \t eps:  0.969\n",
      "Episode Count:  31 \t Cumulative Reward:  28.85 \t eps:  0.968\n",
      "Episode Count:  32 \t Cumulative Reward:  7.09 \t eps:  0.968\n",
      "Episode Count:  33 \t Cumulative Reward:  4.64 \t eps:  0.967\n",
      "Episode Count:  34 \t Cumulative Reward:  7.97 \t eps:  0.966\n",
      "Episode Count:  35 \t Cumulative Reward:  13.87 \t eps:  0.965\n",
      "Episode Count:  36 \t Cumulative Reward:  17.89 \t eps:  0.964\n",
      "Episode Count:  37 \t Cumulative Reward:  14.12 \t eps:  0.963\n",
      "Episode Count:  38 \t Cumulative Reward:  4.16 \t eps:  0.962\n",
      "Episode Count:  39 \t Cumulative Reward:  5.02 \t eps:  0.961\n",
      "Episode Count:  40 \t Cumulative Reward:  19.68 \t eps:  0.96\n",
      "Episode Count:  41 \t Cumulative Reward:  26.85 \t eps:  0.959\n",
      "Episode Count:  42 \t Cumulative Reward:  25.5 \t eps:  0.958\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6296\n",
      "Episode Count:  43 \t Cumulative Reward:  52.81 \t eps:  0.957\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.5537\n",
      "Episode Count:  44 \t Cumulative Reward:  17.28 \t eps:  0.956\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.4973\n",
      "Episode Count:  45 \t Cumulative Reward:  0.25 \t eps:  0.955\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.4883\n",
      "Episode Count:  46 \t Cumulative Reward:  34.88 \t eps:  0.954\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.4523\n",
      "Episode Count:  47 \t Cumulative Reward:  -0.13 \t eps:  0.953\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.4475\n",
      "Episode Count:  48 \t Cumulative Reward:  18.5 \t eps:  0.952\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3985\n",
      "Episode Count:  49 \t Cumulative Reward:  12.39 \t eps:  0.951\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.3812\n",
      "Episode Count:  50 \t Cumulative Reward:  10.65 \t eps:  0.95\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.3889\n",
      "Episode Count:  51 \t Cumulative Reward:  24.84 \t eps:  0.949\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.3568\n",
      "Episode Count:  52 \t Cumulative Reward:  14.69 \t eps:  0.948\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.3563\n",
      "Episode Count:  53 \t Cumulative Reward:  33.73 \t eps:  0.947\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3515\n",
      "Episode Count:  54 \t Cumulative Reward:  18.28 \t eps:  0.946\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3484\n",
      "Episode Count:  55 \t Cumulative Reward:  40.85 \t eps:  0.946\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2859\n",
      "Episode Count:  56 \t Cumulative Reward:  14.74 \t eps:  0.945\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2605\n",
      "Episode Count:  57 \t Cumulative Reward:  7.15 \t eps:  0.944\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2527\n",
      "Episode Count:  58 \t Cumulative Reward:  9.57 \t eps:  0.943\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2349\n",
      "Episode Count:  59 \t Cumulative Reward:  17.38 \t eps:  0.942\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2595\n",
      "Episode Count:  60 \t Cumulative Reward:  27.82 \t eps:  0.941\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2063\n",
      "Episode Count:  61 \t Cumulative Reward:  17.43 \t eps:  0.94\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.1792\n",
      "Episode Count:  62 \t Cumulative Reward:  25.99 \t eps:  0.939\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1748\n",
      "Episode Count:  63 \t Cumulative Reward:  6.31 \t eps:  0.938\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.1571\n",
      "Episode Count:  64 \t Cumulative Reward:  -0.22 \t eps:  0.937\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1384\n",
      "Episode Count:  65 \t Cumulative Reward:  22.91 \t eps:  0.936\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1538\n",
      "Episode Count:  66 \t Cumulative Reward:  8.86 \t eps:  0.935\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1409\n",
      "Episode Count:  67 \t Cumulative Reward:  12.14 \t eps:  0.934\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.0957\n",
      "Episode Count:  68 \t Cumulative Reward:  12.88 \t eps:  0.933\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1085\n",
      "Episode Count:  69 \t Cumulative Reward:  12.26 \t eps:  0.932\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.1202\n",
      "Episode Count:  70 \t Cumulative Reward:  35.34 \t eps:  0.931\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.1163\n",
      "Episode Count:  71 \t Cumulative Reward:  7.34 \t eps:  0.93\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1213\n",
      "Episode Count:  72 \t Cumulative Reward:  16.7 \t eps:  0.93\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0833\n",
      "Episode Count:  73 \t Cumulative Reward:  17.73 \t eps:  0.929\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.0916\n",
      "Episode Count:  74 \t Cumulative Reward:  11.95 \t eps:  0.928\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1041\n",
      "Episode Count:  75 \t Cumulative Reward:  2.25 \t eps:  0.927\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.0780\n",
      "Episode Count:  76 \t Cumulative Reward:  4.11 \t eps:  0.926\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0863\n",
      "Episode Count:  77 \t Cumulative Reward:  27.21 \t eps:  0.925\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0793\n",
      "Episode Count:  78 \t Cumulative Reward:  8.87 \t eps:  0.924\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0760\n",
      "Episode Count:  79 \t Cumulative Reward:  0.64 \t eps:  0.923\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1034\n",
      "Episode Count:  80 \t Cumulative Reward:  15.73 \t eps:  0.922\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0914\n",
      "Episode Count:  81 \t Cumulative Reward:  4.74 \t eps:  0.921\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0809\n",
      "Episode Count:  82 \t Cumulative Reward:  17.33 \t eps:  0.92\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0712\n",
      "Episode Count:  83 \t Cumulative Reward:  22.26 \t eps:  0.919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0583\n",
      "Episode Count:  84 \t Cumulative Reward:  5.91 \t eps:  0.918\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0559\n",
      "Episode Count:  85 \t Cumulative Reward:  17.89 \t eps:  0.918\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0595\n",
      "Episode Count:  86 \t Cumulative Reward:  4.33 \t eps:  0.917\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0613\n",
      "Episode Count:  87 \t Cumulative Reward:  40.69 \t eps:  0.916\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0504\n",
      "Episode Count:  88 \t Cumulative Reward:  15.39 \t eps:  0.915\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0468\n",
      "Episode Count:  89 \t Cumulative Reward:  26.07 \t eps:  0.914\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0784\n",
      "Episode Count:  90 \t Cumulative Reward:  34.06 \t eps:  0.913\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0764\n",
      "Episode Count:  91 \t Cumulative Reward:  26.73 \t eps:  0.912\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0728\n",
      "Episode Count:  92 \t Cumulative Reward:  50.7 \t eps:  0.911\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0830\n",
      "Episode Count:  93 \t Cumulative Reward:  15.55 \t eps:  0.91\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0646\n",
      "Episode Count:  94 \t Cumulative Reward:  7.52 \t eps:  0.909\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0584\n",
      "Episode Count:  95 \t Cumulative Reward:  19.67 \t eps:  0.908\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0652\n",
      "Episode Count:  96 \t Cumulative Reward:  7.77 \t eps:  0.908\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0644\n",
      "Episode Count:  97 \t Cumulative Reward:  18.04 \t eps:  0.907\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0687\n",
      "Episode Count:  98 \t Cumulative Reward:  18.91 \t eps:  0.906\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0713\n",
      "Episode Count:  99 \t Cumulative Reward:  9.44 \t eps:  0.905\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.9172\n",
      "Episode Count:  100 \t Cumulative Reward:  9.69 \t eps:  0.904\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.8572\n",
      "Episode Count:  101 \t Cumulative Reward:  8.03 \t eps:  0.903\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.7637\n",
      "Episode Count:  102 \t Cumulative Reward:  20.72 \t eps:  0.902\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6542\n",
      "Episode Count:  103 \t Cumulative Reward:  29.07 \t eps:  0.901\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.4885\n",
      "Episode Count:  104 \t Cumulative Reward:  15.53 \t eps:  0.9\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.4483\n",
      "Episode Count:  105 \t Cumulative Reward:  27.77 \t eps:  0.899\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.3896\n",
      "Episode Count:  106 \t Cumulative Reward:  7.18 \t eps:  0.898\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.3650\n",
      "Episode Count:  107 \t Cumulative Reward:  30.65 \t eps:  0.898\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3626\n",
      "Episode Count:  108 \t Cumulative Reward:  7.0 \t eps:  0.897\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2926\n",
      "Episode Count:  109 \t Cumulative Reward:  8.38 \t eps:  0.896\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3525\n",
      "Episode Count:  110 \t Cumulative Reward:  22.93 \t eps:  0.895\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.2292\n",
      "Episode Count:  111 \t Cumulative Reward:  8.22 \t eps:  0.894\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2092\n",
      "Episode Count:  112 \t Cumulative Reward:  10.42 \t eps:  0.893\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2252\n",
      "Episode Count:  113 \t Cumulative Reward:  19.1 \t eps:  0.892\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2083\n",
      "Episode Count:  114 \t Cumulative Reward:  0.32 \t eps:  0.891\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2047\n",
      "Episode Count:  115 \t Cumulative Reward:  13.63 \t eps:  0.89\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1507\n",
      "Episode Count:  116 \t Cumulative Reward:  9.53 \t eps:  0.89\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1633\n",
      "Episode Count:  117 \t Cumulative Reward:  5.68 \t eps:  0.889\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.1684\n",
      "Episode Count:  118 \t Cumulative Reward:  6.91 \t eps:  0.888\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1838\n",
      "Episode Count:  119 \t Cumulative Reward:  20.0 \t eps:  0.887\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.1904\n",
      "Episode Count:  120 \t Cumulative Reward:  18.95 \t eps:  0.886\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1369\n",
      "Episode Count:  121 \t Cumulative Reward:  22.05 \t eps:  0.885\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.1553\n",
      "Episode Count:  122 \t Cumulative Reward:  7.69 \t eps:  0.884\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1486\n",
      "Episode Count:  123 \t Cumulative Reward:  10.58 \t eps:  0.883\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.1510\n",
      "Episode Count:  124 \t Cumulative Reward:  7.32 \t eps:  0.882\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1296\n",
      "Episode Count:  125 \t Cumulative Reward:  16.75 \t eps:  0.882\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.1890\n",
      "Episode Count:  126 \t Cumulative Reward:  18.88 \t eps:  0.881\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1781\n",
      "Episode Count:  127 \t Cumulative Reward:  21.38 \t eps:  0.88\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1655\n",
      "Episode Count:  128 \t Cumulative Reward:  28.67 \t eps:  0.879\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1989\n",
      "Episode Count:  129 \t Cumulative Reward:  15.45 \t eps:  0.878\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1631\n",
      "Episode Count:  130 \t Cumulative Reward:  26.16 \t eps:  0.877\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1669\n",
      "Episode Count:  131 \t Cumulative Reward:  8.91 \t eps:  0.876\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1784\n",
      "Episode Count:  132 \t Cumulative Reward:  22.88 \t eps:  0.875\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.2360\n",
      "Episode Count:  133 \t Cumulative Reward:  16.61 \t eps:  0.875\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1824\n",
      "Episode Count:  134 \t Cumulative Reward:  32.04 \t eps:  0.874\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1801\n",
      "Episode Count:  135 \t Cumulative Reward:  42.79 \t eps:  0.873\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1773\n",
      "Episode Count:  136 \t Cumulative Reward:  19.2 \t eps:  0.872\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1776\n",
      "Episode Count:  137 \t Cumulative Reward:  8.33 \t eps:  0.871\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1590\n",
      "Episode Count:  138 \t Cumulative Reward:  27.46 \t eps:  0.87\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1459\n",
      "Episode Count:  139 \t Cumulative Reward:  9.97 \t eps:  0.869\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1452\n",
      "Episode Count:  140 \t Cumulative Reward:  9.6 \t eps:  0.868\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1367\n",
      "Episode Count:  141 \t Cumulative Reward:  13.37 \t eps:  0.868\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1601\n",
      "Episode Count:  142 \t Cumulative Reward:  11.15 \t eps:  0.867\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1662\n",
      "Episode Count:  143 \t Cumulative Reward:  21.46 \t eps:  0.866\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1341\n",
      "Episode Count:  144 \t Cumulative Reward:  10.14 \t eps:  0.865\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.1463\n",
      "Episode Count:  145 \t Cumulative Reward:  12.41 \t eps:  0.864\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1165\n",
      "Episode Count:  146 \t Cumulative Reward:  28.0 \t eps:  0.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1286\n",
      "Episode Count:  147 \t Cumulative Reward:  18.54 \t eps:  0.862\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1516\n",
      "Episode Count:  148 \t Cumulative Reward:  14.19 \t eps:  0.862\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1118\n",
      "Episode Count:  149 \t Cumulative Reward:  22.46 \t eps:  0.861\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1138\n",
      "Episode Count:  150 \t Cumulative Reward:  4.94 \t eps:  0.86\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1306\n",
      "Episode Count:  151 \t Cumulative Reward:  20.49 \t eps:  0.859\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.1119\n",
      "Episode Count:  152 \t Cumulative Reward:  51.95 \t eps:  0.858\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.1240\n",
      "Episode Count:  153 \t Cumulative Reward:  12.83 \t eps:  0.857\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1284\n",
      "Episode Count:  154 \t Cumulative Reward:  12.53 \t eps:  0.856\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1250\n",
      "Episode Count:  155 \t Cumulative Reward:  14.93 \t eps:  0.855\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1221\n",
      "Episode Count:  156 \t Cumulative Reward:  24.23 \t eps:  0.855\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1211\n",
      "Episode Count:  157 \t Cumulative Reward:  29.73 \t eps:  0.854\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1153\n",
      "Episode Count:  158 \t Cumulative Reward:  19.35 \t eps:  0.853\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.1387\n",
      "Episode Count:  159 \t Cumulative Reward:  9.1 \t eps:  0.852\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1464\n",
      "Episode Count:  160 \t Cumulative Reward:  6.15 \t eps:  0.851\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1124\n",
      "Episode Count:  161 \t Cumulative Reward:  13.9 \t eps:  0.85\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1076\n",
      "Episode Count:  162 \t Cumulative Reward:  15.89 \t eps:  0.85\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1540\n",
      "Episode Count:  163 \t Cumulative Reward:  11.26 \t eps:  0.849\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1668\n",
      "Episode Count:  164 \t Cumulative Reward:  11.09 \t eps:  0.848\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1055\n",
      "Episode Count:  165 \t Cumulative Reward:  13.97 \t eps:  0.847\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1376\n",
      "Episode Count:  166 \t Cumulative Reward:  3.46 \t eps:  0.846\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1358\n",
      "Episode Count:  167 \t Cumulative Reward:  -8.67 \t eps:  0.845\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1263\n",
      "Episode Count:  168 \t Cumulative Reward:  16.32 \t eps:  0.844\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1703\n",
      "Episode Count:  169 \t Cumulative Reward:  19.11 \t eps:  0.844\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1215\n",
      "Episode Count:  170 \t Cumulative Reward:  21.03 \t eps:  0.843\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1426\n",
      "Episode Count:  171 \t Cumulative Reward:  4.19 \t eps:  0.842\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1413\n",
      "Episode Count:  172 \t Cumulative Reward:  8.69 \t eps:  0.841\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1257\n",
      "Episode Count:  173 \t Cumulative Reward:  6.79 \t eps:  0.84\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1077\n",
      "Episode Count:  174 \t Cumulative Reward:  27.31 \t eps:  0.839\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1260\n",
      "Episode Count:  175 \t Cumulative Reward:  13.08 \t eps:  0.839\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1096\n",
      "Episode Count:  176 \t Cumulative Reward:  15.61 \t eps:  0.838\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.1561\n",
      "Episode Count:  177 \t Cumulative Reward:  27.21 \t eps:  0.837\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.1037\n",
      "Episode Count:  178 \t Cumulative Reward:  13.53 \t eps:  0.836\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.0971\n",
      "Episode Count:  179 \t Cumulative Reward:  6.68 \t eps:  0.835\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0999\n",
      "Episode Count:  180 \t Cumulative Reward:  10.75 \t eps:  0.834\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1057\n",
      "Episode Count:  181 \t Cumulative Reward:  33.3 \t eps:  0.834\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.1197\n",
      "Episode Count:  182 \t Cumulative Reward:  10.11 \t eps:  0.833\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1091\n",
      "Episode Count:  183 \t Cumulative Reward:  8.87 \t eps:  0.832\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0979\n",
      "Episode Count:  184 \t Cumulative Reward:  32.29 \t eps:  0.831\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1025\n",
      "Episode Count:  185 \t Cumulative Reward:  32.84 \t eps:  0.83\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1643\n",
      "Episode Count:  186 \t Cumulative Reward:  25.77 \t eps:  0.829\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.1210\n",
      "Episode Count:  187 \t Cumulative Reward:  13.58 \t eps:  0.829\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0970\n",
      "Episode Count:  188 \t Cumulative Reward:  18.98 \t eps:  0.828\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.1061\n",
      "Episode Count:  189 \t Cumulative Reward:  36.19 \t eps:  0.827\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1227\n",
      "Episode Count:  190 \t Cumulative Reward:  13.25 \t eps:  0.826\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1335\n",
      "Episode Count:  191 \t Cumulative Reward:  32.29 \t eps:  0.825\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.1083\n",
      "Episode Count:  192 \t Cumulative Reward:  22.16 \t eps:  0.824\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1056\n",
      "Episode Count:  193 \t Cumulative Reward:  11.02 \t eps:  0.824\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.1312\n",
      "Episode Count:  194 \t Cumulative Reward:  41.09 \t eps:  0.823\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.1361\n",
      "Episode Count:  195 \t Cumulative Reward:  29.53 \t eps:  0.822\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.1047\n",
      "Episode Count:  196 \t Cumulative Reward:  18.65 \t eps:  0.821\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.1244\n",
      "Episode Count:  197 \t Cumulative Reward:  15.13 \t eps:  0.82\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1266\n",
      "Episode Count:  198 \t Cumulative Reward:  5.9 \t eps:  0.819\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1256\n",
      "Episode Count:  199 \t Cumulative Reward:  18.72 \t eps:  0.819\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 1.5210\n",
      "run 0: cumulative_reward: 9.73, ran for: 4 timesteps\n",
      "run 1: cumulative_reward: 6.68, ran for: 17 timesteps\n",
      "run 2: cumulative_reward: 30.59, ran for: 6 timesteps\n",
      "run 3: cumulative_reward: 43.21, ran for: 9 timesteps\n",
      "run 4: cumulative_reward: 17.21, ran for: 4 timesteps\n",
      "average performance:  21.484\n",
      "Episode Count:  200 \t Cumulative Reward:  5.7 \t eps:  0.818\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 1.3703\n",
      "Episode Count:  201 \t Cumulative Reward:  43.9 \t eps:  0.817\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 1.0091\n",
      "Episode Count:  202 \t Cumulative Reward:  3.61 \t eps:  0.816\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.8464\n",
      "Episode Count:  203 \t Cumulative Reward:  3.87 \t eps:  0.815\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6977\n",
      "Episode Count:  204 \t Cumulative Reward:  11.76 \t eps:  0.815\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5765: 0s - los\n",
      "Episode Count:  205 \t Cumulative Reward:  31.22 \t eps:  0.814\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.4811\n",
      "Episode Count:  206 \t Cumulative Reward:  20.9 \t eps:  0.813\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.4282\n",
      "Episode Count:  207 \t Cumulative Reward:  24.38 \t eps:  0.812\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 0.4536\n",
      "Episode Count:  208 \t Cumulative Reward:  13.12 \t eps:  0.811\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.4597\n",
      "Episode Count:  209 \t Cumulative Reward:  5.18 \t eps:  0.81\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.4106\n",
      "Episode Count:  210 \t Cumulative Reward:  5.72 \t eps:  0.81\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.4663\n",
      "Episode Count:  211 \t Cumulative Reward:  15.51 \t eps:  0.809\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.4281\n",
      "Episode Count:  212 \t Cumulative Reward:  50.73 \t eps:  0.808\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.4847\n",
      "Episode Count:  213 \t Cumulative Reward:  35.46 \t eps:  0.807\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.4406\n",
      "Episode Count:  214 \t Cumulative Reward:  21.43 \t eps:  0.806\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.4830\n",
      "Episode Count:  215 \t Cumulative Reward:  37.91 \t eps:  0.806\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.4462\n",
      "Episode Count:  216 \t Cumulative Reward:  15.17 \t eps:  0.805\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.3598\n",
      "Episode Count:  217 \t Cumulative Reward:  11.38 \t eps:  0.804\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.3539\n",
      "Episode Count:  218 \t Cumulative Reward:  5.19 \t eps:  0.803\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2910\n",
      "Episode Count:  219 \t Cumulative Reward:  16.22 \t eps:  0.802\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3521\n",
      "Episode Count:  220 \t Cumulative Reward:  16.72 \t eps:  0.802\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.3375\n",
      "Episode Count:  221 \t Cumulative Reward:  21.76 \t eps:  0.801\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.3168\n",
      "Episode Count:  222 \t Cumulative Reward:  25.31 \t eps:  0.8\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2914\n",
      "Episode Count:  223 \t Cumulative Reward:  3.09 \t eps:  0.799\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2687\n",
      "Episode Count:  224 \t Cumulative Reward:  25.27 \t eps:  0.798\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.2658\n",
      "Episode Count:  225 \t Cumulative Reward:  6.19 \t eps:  0.798\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2505\n",
      "Episode Count:  226 \t Cumulative Reward:  6.93 \t eps:  0.797\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.3069\n",
      "Episode Count:  227 \t Cumulative Reward:  23.59 \t eps:  0.796\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2770\n",
      "Episode Count:  228 \t Cumulative Reward:  27.03 \t eps:  0.795\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2201\n",
      "Episode Count:  229 \t Cumulative Reward:  7.96 \t eps:  0.794\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2436\n",
      "Episode Count:  230 \t Cumulative Reward:  15.58 \t eps:  0.794\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2590\n",
      "Episode Count:  231 \t Cumulative Reward:  7.74 \t eps:  0.793\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2616\n",
      "Episode Count:  232 \t Cumulative Reward:  14.22 \t eps:  0.792\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.2295\n",
      "Episode Count:  233 \t Cumulative Reward:  33.08 \t eps:  0.791\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.3418\n",
      "Episode Count:  234 \t Cumulative Reward:  10.75 \t eps:  0.79\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3138\n",
      "Episode Count:  235 \t Cumulative Reward:  46.3 \t eps:  0.79\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.3049\n",
      "Episode Count:  236 \t Cumulative Reward:  8.49 \t eps:  0.789\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2078\n",
      "Episode Count:  237 \t Cumulative Reward:  17.61 \t eps:  0.788\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2562\n",
      "Episode Count:  238 \t Cumulative Reward:  18.73 \t eps:  0.787\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2417\n",
      "Episode Count:  239 \t Cumulative Reward:  22.8 \t eps:  0.787\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2638\n",
      "Episode Count:  240 \t Cumulative Reward:  14.58 \t eps:  0.786\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2527\n",
      "Episode Count:  241 \t Cumulative Reward:  11.06 \t eps:  0.785\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2539\n",
      "Episode Count:  242 \t Cumulative Reward:  16.98 \t eps:  0.784\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2700\n",
      "Episode Count:  243 \t Cumulative Reward:  18.59 \t eps:  0.783\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2340\n",
      "Episode Count:  244 \t Cumulative Reward:  14.05 \t eps:  0.783\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2306\n",
      "Episode Count:  245 \t Cumulative Reward:  16.02 \t eps:  0.782\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.2578\n",
      "Episode Count:  246 \t Cumulative Reward:  18.53 \t eps:  0.781\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2955\n",
      "Episode Count:  247 \t Cumulative Reward:  31.73 \t eps:  0.78\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2097\n",
      "Episode Count:  248 \t Cumulative Reward:  10.62 \t eps:  0.779\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 0.3058\n",
      "Episode Count:  249 \t Cumulative Reward:  20.15 \t eps:  0.779\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3284\n",
      "Episode Count:  250 \t Cumulative Reward:  8.2 \t eps:  0.778\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2205\n",
      "Episode Count:  251 \t Cumulative Reward:  24.68 \t eps:  0.777\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2632\n",
      "Episode Count:  252 \t Cumulative Reward:  14.29 \t eps:  0.776\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2731\n",
      "Episode Count:  253 \t Cumulative Reward:  41.0 \t eps:  0.776\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2650\n",
      "Episode Count:  254 \t Cumulative Reward:  24.86 \t eps:  0.775\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2489\n",
      "Episode Count:  255 \t Cumulative Reward:  14.43 \t eps:  0.774\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2493\n",
      "Episode Count:  256 \t Cumulative Reward:  5.12 \t eps:  0.773\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2804\n",
      "Episode Count:  257 \t Cumulative Reward:  11.75 \t eps:  0.772\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2472\n",
      "Episode Count:  258 \t Cumulative Reward:  42.88 \t eps:  0.772\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2408\n",
      "Episode Count:  259 \t Cumulative Reward:  28.23 \t eps:  0.771\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2642\n",
      "Episode Count:  260 \t Cumulative Reward:  26.03 \t eps:  0.77\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2365\n",
      "Episode Count:  261 \t Cumulative Reward:  5.81 \t eps:  0.769\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3015\n",
      "Episode Count:  262 \t Cumulative Reward:  35.24 \t eps:  0.769\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2463\n",
      "Episode Count:  263 \t Cumulative Reward:  19.45 \t eps:  0.768\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.2472\n",
      "Episode Count:  264 \t Cumulative Reward:  9.7 \t eps:  0.767\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2436\n",
      "Episode Count:  265 \t Cumulative Reward:  -2.11 \t eps:  0.766\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2126\n",
      "Episode Count:  266 \t Cumulative Reward:  19.62 \t eps:  0.766\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2271\n",
      "Episode Count:  267 \t Cumulative Reward:  6.99 \t eps:  0.765\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2392\n",
      "Episode Count:  268 \t Cumulative Reward:  23.92 \t eps:  0.764\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.2448\n",
      "Episode Count:  269 \t Cumulative Reward:  28.22 \t eps:  0.763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3070\n",
      "Episode Count:  270 \t Cumulative Reward:  18.0 \t eps:  0.763\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2565\n",
      "Episode Count:  271 \t Cumulative Reward:  26.2 \t eps:  0.762\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2559\n",
      "Episode Count:  272 \t Cumulative Reward:  10.54 \t eps:  0.761\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2427\n",
      "Episode Count:  273 \t Cumulative Reward:  11.59 \t eps:  0.76\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2194\n",
      "Episode Count:  274 \t Cumulative Reward:  17.63 \t eps:  0.759\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.2002\n",
      "Episode Count:  275 \t Cumulative Reward:  28.01 \t eps:  0.759\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2325\n",
      "Episode Count:  276 \t Cumulative Reward:  12.37 \t eps:  0.758\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.2091\n",
      "Episode Count:  277 \t Cumulative Reward:  21.92 \t eps:  0.757\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.2539\n",
      "Episode Count:  278 \t Cumulative Reward:  43.05 \t eps:  0.756\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.3489\n",
      "Episode Count:  279 \t Cumulative Reward:  19.64 \t eps:  0.756\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.2689\n",
      "Episode Count:  280 \t Cumulative Reward:  37.24 \t eps:  0.755\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 0.2666\n",
      "Episode Count:  281 \t Cumulative Reward:  33.8 \t eps:  0.754\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 0.2329\n",
      "Episode Count:  282 \t Cumulative Reward:  12.09 \t eps:  0.753\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.2667\n",
      "Episode Count:  283 \t Cumulative Reward:  22.94 \t eps:  0.753\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.2458\n",
      "Episode Count:  284 \t Cumulative Reward:  15.51 \t eps:  0.752\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.2439\n",
      "Episode Count:  285 \t Cumulative Reward:  24.45 \t eps:  0.751\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.2759\n",
      "Episode Count:  286 \t Cumulative Reward:  21.53 \t eps:  0.75\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.2588\n",
      "Episode Count:  287 \t Cumulative Reward:  40.8 \t eps:  0.75\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.2636\n",
      "Episode Count:  288 \t Cumulative Reward:  8.65 \t eps:  0.749\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.3497\n",
      "Episode Count:  289 \t Cumulative Reward:  20.45 \t eps:  0.748\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.2488\n",
      "Episode Count:  290 \t Cumulative Reward:  5.63 \t eps:  0.747\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.2183\n",
      "Episode Count:  291 \t Cumulative Reward:  48.96 \t eps:  0.747\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.2850\n",
      "Episode Count:  292 \t Cumulative Reward:  11.1 \t eps:  0.746\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.3369\n",
      "Episode Count:  293 \t Cumulative Reward:  16.07 \t eps:  0.745\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.2905\n",
      "Episode Count:  294 \t Cumulative Reward:  22.4 \t eps:  0.744\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.2287\n",
      "Episode Count:  295 \t Cumulative Reward:  9.56 \t eps:  0.744\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.2196\n",
      "Episode Count:  296 \t Cumulative Reward:  25.72 \t eps:  0.743\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.2735\n",
      "Episode Count:  297 \t Cumulative Reward:  6.28 \t eps:  0.742\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.2805\n",
      "Episode Count:  298 \t Cumulative Reward:  23.54 \t eps:  0.741\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.2803\n",
      "Episode Count:  299 \t Cumulative Reward:  29.67 \t eps:  0.741\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 1.7640\n",
      "Episode Count:  300 \t Cumulative Reward:  39.32 \t eps:  0.74\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 1.5768\n",
      "Episode Count:  301 \t Cumulative Reward:  7.43 \t eps:  0.739\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 1.1569\n",
      "Episode Count:  302 \t Cumulative Reward:  13.95 \t eps:  0.738\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 1.2346\n",
      "Episode Count:  303 \t Cumulative Reward:  13.76 \t eps:  0.738\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 1.0510\n",
      "Episode Count:  304 \t Cumulative Reward:  31.57 \t eps:  0.737\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.8806\n",
      "Episode Count:  305 \t Cumulative Reward:  20.46 \t eps:  0.736\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.8926\n",
      "Episode Count:  306 \t Cumulative Reward:  27.32 \t eps:  0.736\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.9169\n",
      "Episode Count:  307 \t Cumulative Reward:  23.86 \t eps:  0.735\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.8275\n",
      "Episode Count:  308 \t Cumulative Reward:  17.61 \t eps:  0.734\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.8455\n",
      "Episode Count:  309 \t Cumulative Reward:  78.21 \t eps:  0.733\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.8476\n",
      "Episode Count:  310 \t Cumulative Reward:  21.37 \t eps:  0.733\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.7767\n",
      "Episode Count:  311 \t Cumulative Reward:  9.27 \t eps:  0.732\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.7199\n",
      "Episode Count:  312 \t Cumulative Reward:  13.67 \t eps:  0.731\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.8387\n",
      "Episode Count:  313 \t Cumulative Reward:  28.84 \t eps:  0.73\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.6913\n",
      "Episode Count:  314 \t Cumulative Reward:  10.0 \t eps:  0.73\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.6356\n",
      "Episode Count:  315 \t Cumulative Reward:  21.21 \t eps:  0.729\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.6749\n",
      "Episode Count:  316 \t Cumulative Reward:  8.58 \t eps:  0.728\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.6586\n",
      "Episode Count:  317 \t Cumulative Reward:  42.99 \t eps:  0.727\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.6418\n",
      "Episode Count:  318 \t Cumulative Reward:  29.95 \t eps:  0.727\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.5577\n",
      "Episode Count:  319 \t Cumulative Reward:  16.28 \t eps:  0.726\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.5123\n",
      "Episode Count:  320 \t Cumulative Reward:  18.62 \t eps:  0.725\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.5661\n",
      "Episode Count:  321 \t Cumulative Reward:  58.77 \t eps:  0.725\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.5741\n",
      "Episode Count:  322 \t Cumulative Reward:  41.97 \t eps:  0.724\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.5284\n",
      "Episode Count:  323 \t Cumulative Reward:  15.69 \t eps:  0.723\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.5769\n",
      "Episode Count:  324 \t Cumulative Reward:  25.31 \t eps:  0.722\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.5084\n",
      "Episode Count:  325 \t Cumulative Reward:  9.96 \t eps:  0.722\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.4898\n",
      "Episode Count:  326 \t Cumulative Reward:  19.57 \t eps:  0.721\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.5151\n",
      "Episode Count:  327 \t Cumulative Reward:  11.63 \t eps:  0.72\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5904\n",
      "Episode Count:  328 \t Cumulative Reward:  14.59 \t eps:  0.72\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.5742\n",
      "Episode Count:  329 \t Cumulative Reward:  40.01 \t eps:  0.719\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.5518\n",
      "Episode Count:  330 \t Cumulative Reward:  6.95 \t eps:  0.718\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.6056: 0s - loss: 0.61\n",
      "Episode Count:  331 \t Cumulative Reward:  65.67 \t eps:  0.717\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.6524\n",
      "Episode Count:  332 \t Cumulative Reward:  30.18 \t eps:  0.717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5614\n",
      "Episode Count:  333 \t Cumulative Reward:  12.53 \t eps:  0.716\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.4871\n",
      "Episode Count:  334 \t Cumulative Reward:  42.14 \t eps:  0.715\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.5915\n",
      "Episode Count:  335 \t Cumulative Reward:  9.87 \t eps:  0.715\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.6130\n",
      "Episode Count:  336 \t Cumulative Reward:  40.42 \t eps:  0.714\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.5884\n",
      "Episode Count:  337 \t Cumulative Reward:  13.12 \t eps:  0.713\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.4998\n",
      "Episode Count:  338 \t Cumulative Reward:  24.62 \t eps:  0.712\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.5454\n",
      "Episode Count:  339 \t Cumulative Reward:  28.34 \t eps:  0.712\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4946\n",
      "Episode Count:  340 \t Cumulative Reward:  25.21 \t eps:  0.711\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.4836\n",
      "Episode Count:  341 \t Cumulative Reward:  4.81 \t eps:  0.71\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.5456\n",
      "Episode Count:  342 \t Cumulative Reward:  23.17 \t eps:  0.71\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.5349\n",
      "Episode Count:  343 \t Cumulative Reward:  28.59 \t eps:  0.709\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.4798\n",
      "Episode Count:  344 \t Cumulative Reward:  13.81 \t eps:  0.708\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.5578\n",
      "Episode Count:  345 \t Cumulative Reward:  44.38 \t eps:  0.707\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.4938\n",
      "Episode Count:  346 \t Cumulative Reward:  11.85 \t eps:  0.707\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.4549\n",
      "Episode Count:  347 \t Cumulative Reward:  22.25 \t eps:  0.706\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4455\n",
      "Episode Count:  348 \t Cumulative Reward:  50.75 \t eps:  0.705\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4466\n",
      "Episode Count:  349 \t Cumulative Reward:  6.94 \t eps:  0.705\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.4556\n",
      "Episode Count:  350 \t Cumulative Reward:  6.31 \t eps:  0.704\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.5331\n",
      "Episode Count:  351 \t Cumulative Reward:  27.22 \t eps:  0.703\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.5388\n",
      "Episode Count:  352 \t Cumulative Reward:  19.12 \t eps:  0.702\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.5580\n",
      "Episode Count:  353 \t Cumulative Reward:  27.46 \t eps:  0.702\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.5216\n",
      "Episode Count:  354 \t Cumulative Reward:  27.32 \t eps:  0.701\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.4657\n",
      "Episode Count:  355 \t Cumulative Reward:  4.71 \t eps:  0.7\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4611\n",
      "Episode Count:  356 \t Cumulative Reward:  29.69 \t eps:  0.7\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4404\n",
      "Episode Count:  357 \t Cumulative Reward:  41.09 \t eps:  0.699\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.4600\n",
      "Episode Count:  358 \t Cumulative Reward:  24.94 \t eps:  0.698\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5299\n",
      "Episode Count:  359 \t Cumulative Reward:  64.18 \t eps:  0.698\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.4792\n",
      "Episode Count:  360 \t Cumulative Reward:  18.09 \t eps:  0.697\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.5348\n",
      "Episode Count:  361 \t Cumulative Reward:  10.67 \t eps:  0.696\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.5196\n",
      "Episode Count:  362 \t Cumulative Reward:  22.59 \t eps:  0.695\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.4995\n",
      "Episode Count:  363 \t Cumulative Reward:  48.64 \t eps:  0.695\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.5351\n",
      "Episode Count:  364 \t Cumulative Reward:  10.23 \t eps:  0.694\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.5221\n",
      "Episode Count:  365 \t Cumulative Reward:  25.75 \t eps:  0.693\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.4534\n",
      "Episode Count:  366 \t Cumulative Reward:  23.42 \t eps:  0.693\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.5071\n",
      "Episode Count:  367 \t Cumulative Reward:  21.74 \t eps:  0.692\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.5591\n",
      "Episode Count:  368 \t Cumulative Reward:  24.05 \t eps:  0.691\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.5736\n",
      "Episode Count:  369 \t Cumulative Reward:  25.92 \t eps:  0.691\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4821\n",
      "Episode Count:  370 \t Cumulative Reward:  19.56 \t eps:  0.69\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.5261\n",
      "Episode Count:  371 \t Cumulative Reward:  44.07 \t eps:  0.689\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4999\n",
      "Episode Count:  372 \t Cumulative Reward:  8.17 \t eps:  0.689\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4579\n",
      "Episode Count:  373 \t Cumulative Reward:  19.41 \t eps:  0.688\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5490\n",
      "Episode Count:  374 \t Cumulative Reward:  20.44 \t eps:  0.687\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.4324\n",
      "Episode Count:  375 \t Cumulative Reward:  35.86 \t eps:  0.686\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.4762\n",
      "Episode Count:  376 \t Cumulative Reward:  42.63 \t eps:  0.686\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.5161\n",
      "Episode Count:  377 \t Cumulative Reward:  9.39 \t eps:  0.685\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5120\n",
      "Episode Count:  378 \t Cumulative Reward:  32.19 \t eps:  0.684\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.4753\n",
      "Episode Count:  379 \t Cumulative Reward:  36.45 \t eps:  0.684\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.5198\n",
      "Episode Count:  380 \t Cumulative Reward:  27.63 \t eps:  0.683\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.5231\n",
      "Episode Count:  381 \t Cumulative Reward:  7.47 \t eps:  0.682\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 0.5700\n",
      "Episode Count:  382 \t Cumulative Reward:  10.57 \t eps:  0.682\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.5283\n",
      "Episode Count:  383 \t Cumulative Reward:  45.31 \t eps:  0.681\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.5258\n",
      "Episode Count:  384 \t Cumulative Reward:  23.65 \t eps:  0.68\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.4421\n",
      "Episode Count:  385 \t Cumulative Reward:  40.49 \t eps:  0.68\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.4924\n",
      "Episode Count:  386 \t Cumulative Reward:  25.55 \t eps:  0.679\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.5544\n",
      "Episode Count:  387 \t Cumulative Reward:  22.98 \t eps:  0.678\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.4694\n",
      "Episode Count:  388 \t Cumulative Reward:  51.07 \t eps:  0.678\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.5063\n",
      "Episode Count:  389 \t Cumulative Reward:  20.99 \t eps:  0.677\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5599\n",
      "Episode Count:  390 \t Cumulative Reward:  40.18 \t eps:  0.676\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5358\n",
      "Episode Count:  391 \t Cumulative Reward:  18.94 \t eps:  0.676\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.4721\n",
      "Episode Count:  392 \t Cumulative Reward:  20.62 \t eps:  0.675\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.4810\n",
      "Episode Count:  393 \t Cumulative Reward:  11.74 \t eps:  0.674\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.4883\n",
      "Episode Count:  394 \t Cumulative Reward:  42.38 \t eps:  0.674\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.4466\n",
      "Episode Count:  395 \t Cumulative Reward:  37.8 \t eps:  0.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 88ms/step - loss: 0.5480\n",
      "Episode Count:  396 \t Cumulative Reward:  8.26 \t eps:  0.672\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5810\n",
      "Episode Count:  397 \t Cumulative Reward:  24.22 \t eps:  0.672\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.5219\n",
      "Episode Count:  398 \t Cumulative Reward:  10.92 \t eps:  0.671\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.5455\n",
      "Episode Count:  399 \t Cumulative Reward:  16.36 \t eps:  0.67\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 1.3814: 0s - los\n",
      "run 0: cumulative_reward: 33.14, ran for: 15 timesteps\n",
      "run 1: cumulative_reward: 49.98, ran for: 24 timesteps\n",
      "run 2: cumulative_reward: 19.65, ran for: 32 timesteps\n",
      "run 3: cumulative_reward: 21.82, ran for: 10 timesteps\n",
      "run 4: cumulative_reward: 21.48, ran for: 13 timesteps\n",
      "average performance:  29.214\n",
      "Episode Count:  400 \t Cumulative Reward:  46.45 \t eps:  0.67\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 1.3347\n",
      "Episode Count:  401 \t Cumulative Reward:  11.64 \t eps:  0.669\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.1824\n",
      "Episode Count:  402 \t Cumulative Reward:  19.73 \t eps:  0.668\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 1.1105\n",
      "Episode Count:  403 \t Cumulative Reward:  25.32 \t eps:  0.668\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.0153\n",
      "Episode Count:  404 \t Cumulative Reward:  22.47 \t eps:  0.667\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.9174\n",
      "Episode Count:  405 \t Cumulative Reward:  22.47 \t eps:  0.666\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.8948\n",
      "Episode Count:  406 \t Cumulative Reward:  22.24 \t eps:  0.666\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.9268\n",
      "Episode Count:  407 \t Cumulative Reward:  47.14 \t eps:  0.665\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.8261: 0s - loss: \n",
      "Episode Count:  408 \t Cumulative Reward:  12.54 \t eps:  0.664\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.8301\n",
      "Episode Count:  409 \t Cumulative Reward:  39.38 \t eps:  0.664\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.7175\n",
      "Episode Count:  410 \t Cumulative Reward:  44.95 \t eps:  0.663\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.7761\n",
      "Episode Count:  411 \t Cumulative Reward:  17.46 \t eps:  0.662\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.7084\n",
      "Episode Count:  412 \t Cumulative Reward:  30.39 \t eps:  0.662\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.7815\n",
      "Episode Count:  413 \t Cumulative Reward:  16.07 \t eps:  0.661\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.7839\n",
      "Episode Count:  414 \t Cumulative Reward:  22.35 \t eps:  0.66\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7270\n",
      "Episode Count:  415 \t Cumulative Reward:  40.39 \t eps:  0.66\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6993\n",
      "Episode Count:  416 \t Cumulative Reward:  27.37 \t eps:  0.659\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6697\n",
      "Episode Count:  417 \t Cumulative Reward:  29.84 \t eps:  0.658\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.6915\n",
      "Episode Count:  418 \t Cumulative Reward:  25.49 \t eps:  0.658\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.7959\n",
      "Episode Count:  419 \t Cumulative Reward:  40.57 \t eps:  0.657\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.7172\n",
      "Episode Count:  420 \t Cumulative Reward:  18.92 \t eps:  0.656\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.7755\n",
      "Episode Count:  421 \t Cumulative Reward:  20.58 \t eps:  0.656\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8014\n",
      "Episode Count:  422 \t Cumulative Reward:  21.64 \t eps:  0.655\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.6875\n",
      "Episode Count:  423 \t Cumulative Reward:  51.43 \t eps:  0.654\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.7000\n",
      "Episode Count:  424 \t Cumulative Reward:  30.18 \t eps:  0.654\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6101\n",
      "Episode Count:  425 \t Cumulative Reward:  26.23 \t eps:  0.653\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6908\n",
      "Episode Count:  426 \t Cumulative Reward:  15.68 \t eps:  0.652\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6094\n",
      "Episode Count:  427 \t Cumulative Reward:  32.0 \t eps:  0.652\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.5785\n",
      "Episode Count:  428 \t Cumulative Reward:  12.8 \t eps:  0.651\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.6054\n",
      "Episode Count:  429 \t Cumulative Reward:  22.92 \t eps:  0.65\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.6008\n",
      "Episode Count:  430 \t Cumulative Reward:  7.58 \t eps:  0.65\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.6108\n",
      "Episode Count:  431 \t Cumulative Reward:  16.71 \t eps:  0.649\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 0.6749\n",
      "Episode Count:  432 \t Cumulative Reward:  5.11 \t eps:  0.648\n",
      "16/16 [==============================] - 2s 106ms/step - loss: 0.6981\n",
      "Episode Count:  433 \t Cumulative Reward:  19.5 \t eps:  0.648\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.5674\n",
      "Episode Count:  434 \t Cumulative Reward:  38.44 \t eps:  0.647\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6397\n",
      "Episode Count:  435 \t Cumulative Reward:  42.21 \t eps:  0.646\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.5531\n",
      "Episode Count:  436 \t Cumulative Reward:  37.86 \t eps:  0.646\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.6593\n",
      "Episode Count:  437 \t Cumulative Reward:  54.37 \t eps:  0.645\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6630\n",
      "Episode Count:  438 \t Cumulative Reward:  14.46 \t eps:  0.645\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.4864\n",
      "Episode Count:  439 \t Cumulative Reward:  22.23 \t eps:  0.644\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.6366\n",
      "Episode Count:  440 \t Cumulative Reward:  7.38 \t eps:  0.643\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.5713\n",
      "Episode Count:  441 \t Cumulative Reward:  24.97 \t eps:  0.643\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.5880\n",
      "Episode Count:  442 \t Cumulative Reward:  35.53 \t eps:  0.642\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.5799\n",
      "Episode Count:  443 \t Cumulative Reward:  43.49 \t eps:  0.641\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6306\n",
      "Episode Count:  444 \t Cumulative Reward:  47.99 \t eps:  0.641\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.6752\n",
      "Episode Count:  445 \t Cumulative Reward:  30.89 \t eps:  0.64\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6439\n",
      "Episode Count:  446 \t Cumulative Reward:  6.68 \t eps:  0.639\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6538\n",
      "Episode Count:  447 \t Cumulative Reward:  31.13 \t eps:  0.639\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.6994\n",
      "Episode Count:  448 \t Cumulative Reward:  22.45 \t eps:  0.638\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6599\n",
      "Episode Count:  449 \t Cumulative Reward:  44.83 \t eps:  0.637\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6801\n",
      "Episode Count:  450 \t Cumulative Reward:  78.08 \t eps:  0.637\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6707\n",
      "Episode Count:  451 \t Cumulative Reward:  27.11 \t eps:  0.636\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6642\n",
      "Episode Count:  452 \t Cumulative Reward:  24.65 \t eps:  0.636\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5982\n",
      "Episode Count:  453 \t Cumulative Reward:  21.01 \t eps:  0.635\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5428\n",
      "Episode Count:  454 \t Cumulative Reward:  40.69 \t eps:  0.634\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.6187\n",
      "Episode Count:  455 \t Cumulative Reward:  41.93 \t eps:  0.634\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.6216\n",
      "Episode Count:  456 \t Cumulative Reward:  20.62 \t eps:  0.633\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.6843\n",
      "Episode Count:  457 \t Cumulative Reward:  7.29 \t eps:  0.632\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.6282\n",
      "Episode Count:  458 \t Cumulative Reward:  20.57 \t eps:  0.632\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6661\n",
      "Episode Count:  459 \t Cumulative Reward:  71.86 \t eps:  0.631\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5914\n",
      "Episode Count:  460 \t Cumulative Reward:  26.33 \t eps:  0.631\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6354\n",
      "Episode Count:  461 \t Cumulative Reward:  41.22 \t eps:  0.63\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6129\n",
      "Episode Count:  462 \t Cumulative Reward:  11.51 \t eps:  0.629\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6978\n",
      "Episode Count:  463 \t Cumulative Reward:  17.37 \t eps:  0.629\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.7688\n",
      "Episode Count:  464 \t Cumulative Reward:  49.79 \t eps:  0.628\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5839\n",
      "Episode Count:  465 \t Cumulative Reward:  54.72 \t eps:  0.627\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6746\n",
      "Episode Count:  466 \t Cumulative Reward:  23.25 \t eps:  0.627\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.5659\n",
      "Episode Count:  467 \t Cumulative Reward:  15.12 \t eps:  0.626\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.6240\n",
      "Episode Count:  468 \t Cumulative Reward:  40.75 \t eps:  0.625\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6875\n",
      "Episode Count:  469 \t Cumulative Reward:  48.64 \t eps:  0.625\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.6428\n",
      "Episode Count:  470 \t Cumulative Reward:  20.27 \t eps:  0.624\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.5741\n",
      "Episode Count:  471 \t Cumulative Reward:  21.07 \t eps:  0.624\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6862: 0s - loss: 0.686\n",
      "Episode Count:  472 \t Cumulative Reward:  12.23 \t eps:  0.623\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6382\n",
      "Episode Count:  473 \t Cumulative Reward:  12.36 \t eps:  0.622\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6790\n",
      "Episode Count:  474 \t Cumulative Reward:  37.0 \t eps:  0.622\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6073\n",
      "Episode Count:  475 \t Cumulative Reward:  30.93 \t eps:  0.621\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6030\n",
      "Episode Count:  476 \t Cumulative Reward:  15.18 \t eps:  0.62\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5830\n",
      "Episode Count:  477 \t Cumulative Reward:  13.03 \t eps:  0.62\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5809\n",
      "Episode Count:  478 \t Cumulative Reward:  20.46 \t eps:  0.619\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.5854\n",
      "Episode Count:  479 \t Cumulative Reward:  43.97 \t eps:  0.619\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6159\n",
      "Episode Count:  480 \t Cumulative Reward:  6.3 \t eps:  0.618\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6310\n",
      "Episode Count:  481 \t Cumulative Reward:  19.74 \t eps:  0.617\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6791\n",
      "Episode Count:  482 \t Cumulative Reward:  16.25 \t eps:  0.617\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5917\n",
      "Episode Count:  483 \t Cumulative Reward:  21.93 \t eps:  0.616\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.5557\n",
      "Episode Count:  484 \t Cumulative Reward:  22.22 \t eps:  0.616\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6518\n",
      "Episode Count:  485 \t Cumulative Reward:  12.43 \t eps:  0.615\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.5611\n",
      "Episode Count:  486 \t Cumulative Reward:  34.17 \t eps:  0.614\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6113: 0s - lo\n",
      "Episode Count:  487 \t Cumulative Reward:  10.85 \t eps:  0.614\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.6030\n",
      "Episode Count:  488 \t Cumulative Reward:  6.26 \t eps:  0.613\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5116\n",
      "Episode Count:  489 \t Cumulative Reward:  23.69 \t eps:  0.612\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5236\n",
      "Episode Count:  490 \t Cumulative Reward:  102.8 \t eps:  0.612\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.5776\n",
      "Episode Count:  491 \t Cumulative Reward:  54.72 \t eps:  0.611\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5670\n",
      "Episode Count:  492 \t Cumulative Reward:  55.66 \t eps:  0.611\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6050\n",
      "Episode Count:  493 \t Cumulative Reward:  23.66 \t eps:  0.61\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5353: 0s - loss: 0.\n",
      "Episode Count:  494 \t Cumulative Reward:  15.09 \t eps:  0.609\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5230\n",
      "Episode Count:  495 \t Cumulative Reward:  22.35 \t eps:  0.609\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.6251\n",
      "Episode Count:  496 \t Cumulative Reward:  46.83 \t eps:  0.608\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5767\n",
      "Episode Count:  497 \t Cumulative Reward:  24.4 \t eps:  0.608\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.6015\n",
      "Episode Count:  498 \t Cumulative Reward:  22.12 \t eps:  0.607\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6202\n",
      "Episode Count:  499 \t Cumulative Reward:  18.24 \t eps:  0.606\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 1.1215\n",
      "Episode Count:  500 \t Cumulative Reward:  42.24 \t eps:  0.606\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.9947\n",
      "Episode Count:  501 \t Cumulative Reward:  52.13 \t eps:  0.605\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.0721\n",
      "Episode Count:  502 \t Cumulative Reward:  33.08 \t eps:  0.605\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.9659\n",
      "Episode Count:  503 \t Cumulative Reward:  16.15 \t eps:  0.604\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.1422\n",
      "Episode Count:  504 \t Cumulative Reward:  40.1 \t eps:  0.603\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.1313\n",
      "Episode Count:  505 \t Cumulative Reward:  87.28 \t eps:  0.603\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.0150\n",
      "Episode Count:  506 \t Cumulative Reward:  43.55 \t eps:  0.602\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.9074\n",
      "Episode Count:  507 \t Cumulative Reward:  9.03 \t eps:  0.602\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.8002\n",
      "Episode Count:  508 \t Cumulative Reward:  12.83 \t eps:  0.601\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8082\n",
      "Episode Count:  509 \t Cumulative Reward:  73.69 \t eps:  0.6\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.8564\n",
      "Episode Count:  510 \t Cumulative Reward:  32.31 \t eps:  0.6\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.8350\n",
      "Episode Count:  511 \t Cumulative Reward:  19.38 \t eps:  0.599\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.7193\n",
      "Episode Count:  512 \t Cumulative Reward:  33.87 \t eps:  0.599\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.7997\n",
      "Episode Count:  513 \t Cumulative Reward:  42.18 \t eps:  0.598\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.8153\n",
      "Episode Count:  514 \t Cumulative Reward:  44.95 \t eps:  0.597\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.7723\n",
      "Episode Count:  515 \t Cumulative Reward:  13.52 \t eps:  0.597\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.7488\n",
      "Episode Count:  516 \t Cumulative Reward:  30.21 \t eps:  0.596\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.7756\n",
      "Episode Count:  517 \t Cumulative Reward:  16.94 \t eps:  0.596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 92ms/step - loss: 0.7692\n",
      "Episode Count:  518 \t Cumulative Reward:  7.33 \t eps:  0.595\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6846\n",
      "Episode Count:  519 \t Cumulative Reward:  20.96 \t eps:  0.594\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5968\n",
      "Episode Count:  520 \t Cumulative Reward:  65.68 \t eps:  0.594\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5875\n",
      "Episode Count:  521 \t Cumulative Reward:  7.04 \t eps:  0.593\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.6164\n",
      "Episode Count:  522 \t Cumulative Reward:  13.56 \t eps:  0.593\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.7365\n",
      "Episode Count:  523 \t Cumulative Reward:  38.79 \t eps:  0.592\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8586\n",
      "Episode Count:  524 \t Cumulative Reward:  12.52 \t eps:  0.591\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.7315\n",
      "Episode Count:  525 \t Cumulative Reward:  49.34 \t eps:  0.591\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6609\n",
      "Episode Count:  526 \t Cumulative Reward:  39.73 \t eps:  0.59\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6506\n",
      "Episode Count:  527 \t Cumulative Reward:  30.99 \t eps:  0.59\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6885\n",
      "Episode Count:  528 \t Cumulative Reward:  13.25 \t eps:  0.589\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5345: 0s - loss:\n",
      "Episode Count:  529 \t Cumulative Reward:  18.32 \t eps:  0.588\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.6193\n",
      "Episode Count:  530 \t Cumulative Reward:  22.92 \t eps:  0.588\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.5855\n",
      "Episode Count:  531 \t Cumulative Reward:  64.0 \t eps:  0.587\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6758\n",
      "Episode Count:  532 \t Cumulative Reward:  96.68 \t eps:  0.587\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6653\n",
      "Episode Count:  533 \t Cumulative Reward:  16.67 \t eps:  0.586\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 0.7543\n",
      "Episode Count:  534 \t Cumulative Reward:  13.13 \t eps:  0.586\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.6224\n",
      "Episode Count:  535 \t Cumulative Reward:  20.27 \t eps:  0.585\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6612\n",
      "Episode Count:  536 \t Cumulative Reward:  18.09 \t eps:  0.584\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.6042\n",
      "Episode Count:  537 \t Cumulative Reward:  68.45 \t eps:  0.584\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6147\n",
      "Episode Count:  538 \t Cumulative Reward:  15.06 \t eps:  0.583\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6247\n",
      "Episode Count:  539 \t Cumulative Reward:  41.88 \t eps:  0.583\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.5555\n",
      "Episode Count:  540 \t Cumulative Reward:  55.35 \t eps:  0.582\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6372\n",
      "Episode Count:  541 \t Cumulative Reward:  18.95 \t eps:  0.581\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.5954\n",
      "Episode Count:  542 \t Cumulative Reward:  31.28 \t eps:  0.581\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5688\n",
      "Episode Count:  543 \t Cumulative Reward:  9.16 \t eps:  0.58\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.6326\n",
      "Episode Count:  544 \t Cumulative Reward:  67.4 \t eps:  0.58\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6645: 0s - los\n",
      "Episode Count:  545 \t Cumulative Reward:  66.63 \t eps:  0.579\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.6118\n",
      "Episode Count:  546 \t Cumulative Reward:  22.51 \t eps:  0.579\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6796\n",
      "Episode Count:  547 \t Cumulative Reward:  9.29 \t eps:  0.578\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.6997\n",
      "Episode Count:  548 \t Cumulative Reward:  12.93 \t eps:  0.577\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6106\n",
      "Episode Count:  549 \t Cumulative Reward:  53.08 \t eps:  0.577\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.7410\n",
      "Episode Count:  550 \t Cumulative Reward:  25.94 \t eps:  0.576\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6453\n",
      "Episode Count:  551 \t Cumulative Reward:  8.0 \t eps:  0.576\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.7361\n",
      "Episode Count:  552 \t Cumulative Reward:  20.6 \t eps:  0.575\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.6780\n",
      "Episode Count:  553 \t Cumulative Reward:  22.31 \t eps:  0.574\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6365\n",
      "Episode Count:  554 \t Cumulative Reward:  42.42 \t eps:  0.574\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6539\n",
      "Episode Count:  555 \t Cumulative Reward:  25.51 \t eps:  0.573\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5423\n",
      "Episode Count:  556 \t Cumulative Reward:  8.08 \t eps:  0.573\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.5904\n",
      "Episode Count:  557 \t Cumulative Reward:  46.13 \t eps:  0.572\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6587\n",
      "Episode Count:  558 \t Cumulative Reward:  9.48 \t eps:  0.572\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.6321\n",
      "Episode Count:  559 \t Cumulative Reward:  20.35 \t eps:  0.571\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6359\n",
      "Episode Count:  560 \t Cumulative Reward:  28.86 \t eps:  0.57\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.5979\n",
      "Episode Count:  561 \t Cumulative Reward:  15.54 \t eps:  0.57\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.6134\n",
      "Episode Count:  562 \t Cumulative Reward:  26.1 \t eps:  0.569\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.6593\n",
      "Episode Count:  563 \t Cumulative Reward:  12.77 \t eps:  0.569\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6984\n",
      "Episode Count:  564 \t Cumulative Reward:  19.83 \t eps:  0.568\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6104\n",
      "Episode Count:  565 \t Cumulative Reward:  39.46 \t eps:  0.568\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.5516\n",
      "Episode Count:  566 \t Cumulative Reward:  24.77 \t eps:  0.567\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.6884\n",
      "Episode Count:  567 \t Cumulative Reward:  17.16 \t eps:  0.566\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6820\n",
      "Episode Count:  568 \t Cumulative Reward:  14.33 \t eps:  0.566\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5793\n",
      "Episode Count:  569 \t Cumulative Reward:  18.3 \t eps:  0.565\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.6627\n",
      "Episode Count:  570 \t Cumulative Reward:  5.84 \t eps:  0.565\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6298: 0s - loss: 0.62\n",
      "Episode Count:  571 \t Cumulative Reward:  22.28 \t eps:  0.564\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.5292\n",
      "Episode Count:  572 \t Cumulative Reward:  73.54 \t eps:  0.564\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.5418\n",
      "Episode Count:  573 \t Cumulative Reward:  44.16 \t eps:  0.563\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6017\n",
      "Episode Count:  574 \t Cumulative Reward:  29.38 \t eps:  0.563\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.6052\n",
      "Episode Count:  575 \t Cumulative Reward:  78.52 \t eps:  0.562\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.5683\n",
      "Episode Count:  576 \t Cumulative Reward:  7.85 \t eps:  0.561\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.5958\n",
      "Episode Count:  577 \t Cumulative Reward:  26.3 \t eps:  0.561\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.5389\n",
      "Episode Count:  578 \t Cumulative Reward:  37.32 \t eps:  0.56\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6307\n",
      "Episode Count:  579 \t Cumulative Reward:  21.07 \t eps:  0.56\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5689\n",
      "Episode Count:  580 \t Cumulative Reward:  17.98 \t eps:  0.559\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6074\n",
      "Episode Count:  581 \t Cumulative Reward:  43.97 \t eps:  0.559\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.5969\n",
      "Episode Count:  582 \t Cumulative Reward:  9.15 \t eps:  0.558\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.5754\n",
      "Episode Count:  583 \t Cumulative Reward:  13.29 \t eps:  0.558\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.5307\n",
      "Episode Count:  584 \t Cumulative Reward:  46.24 \t eps:  0.557\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.5924\n",
      "Episode Count:  585 \t Cumulative Reward:  38.61 \t eps:  0.556\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.5487\n",
      "Episode Count:  586 \t Cumulative Reward:  32.34 \t eps:  0.556\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6444\n",
      "Episode Count:  587 \t Cumulative Reward:  17.71 \t eps:  0.555\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.5358\n",
      "Episode Count:  588 \t Cumulative Reward:  48.67 \t eps:  0.555\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.6278\n",
      "Episode Count:  589 \t Cumulative Reward:  6.4 \t eps:  0.554\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.5227\n",
      "Episode Count:  590 \t Cumulative Reward:  25.73 \t eps:  0.554\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.5083\n",
      "Episode Count:  591 \t Cumulative Reward:  20.21 \t eps:  0.553\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.5746\n",
      "Episode Count:  592 \t Cumulative Reward:  28.08 \t eps:  0.553\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.5660\n",
      "Episode Count:  593 \t Cumulative Reward:  39.25 \t eps:  0.552\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.5854\n",
      "Episode Count:  594 \t Cumulative Reward:  37.39 \t eps:  0.551\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.5876\n",
      "Episode Count:  595 \t Cumulative Reward:  21.73 \t eps:  0.551\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6627\n",
      "Episode Count:  596 \t Cumulative Reward:  37.66 \t eps:  0.55\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.6087\n",
      "Episode Count:  597 \t Cumulative Reward:  4.32 \t eps:  0.55\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.5561\n",
      "Episode Count:  598 \t Cumulative Reward:  26.19 \t eps:  0.549\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6410\n",
      "Episode Count:  599 \t Cumulative Reward:  25.73 \t eps:  0.549\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.0849\n",
      "run 0: cumulative_reward: 186.28, ran for: 68 timesteps\n",
      "run 1: cumulative_reward: 73.34, ran for: 50 timesteps\n",
      "run 2: cumulative_reward: 48.55, ran for: 18 timesteps\n",
      "run 3: cumulative_reward: 30.77, ran for: 16 timesteps\n",
      "run 4: cumulative_reward: 22.88, ran for: 9 timesteps\n",
      "average performance:  72.364\n",
      "Episode Count:  600 \t Cumulative Reward:  10.13 \t eps:  0.548\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 1.0319\n",
      "Episode Count:  601 \t Cumulative Reward:  15.29 \t eps:  0.548\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.9926\n",
      "Episode Count:  602 \t Cumulative Reward:  0.37 \t eps:  0.547\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 1.0573\n",
      "Episode Count:  603 \t Cumulative Reward:  17.34 \t eps:  0.546\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 1.0022\n",
      "Episode Count:  604 \t Cumulative Reward:  15.71 \t eps:  0.546\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.9366\n",
      "Episode Count:  605 \t Cumulative Reward:  28.04 \t eps:  0.545\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.8839\n",
      "Episode Count:  606 \t Cumulative Reward:  40.71 \t eps:  0.545\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 0.9058\n",
      "Episode Count:  607 \t Cumulative Reward:  12.88 \t eps:  0.544\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.9037: 0s - loss: \n",
      "Episode Count:  608 \t Cumulative Reward:  16.96 \t eps:  0.544\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7416\n",
      "Episode Count:  609 \t Cumulative Reward:  16.57 \t eps:  0.543\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.8875\n",
      "Episode Count:  610 \t Cumulative Reward:  28.08 \t eps:  0.543\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.7410\n",
      "Episode Count:  611 \t Cumulative Reward:  3.09 \t eps:  0.542\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7617\n",
      "Episode Count:  612 \t Cumulative Reward:  34.2 \t eps:  0.542\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 0.8503\n",
      "Episode Count:  613 \t Cumulative Reward:  21.31 \t eps:  0.541\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.8043\n",
      "Episode Count:  614 \t Cumulative Reward:  24.82 \t eps:  0.54\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.8390\n",
      "Episode Count:  615 \t Cumulative Reward:  39.81 \t eps:  0.54\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.8794: 0s - loss: 0.86\n",
      "Episode Count:  616 \t Cumulative Reward:  91.77 \t eps:  0.539\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6886\n",
      "Episode Count:  617 \t Cumulative Reward:  24.15 \t eps:  0.539\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.8281\n",
      "Episode Count:  618 \t Cumulative Reward:  6.71 \t eps:  0.538\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.7340\n",
      "Episode Count:  619 \t Cumulative Reward:  19.23 \t eps:  0.538\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7595: 0s -\n",
      "Episode Count:  620 \t Cumulative Reward:  22.87 \t eps:  0.537\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6499\n",
      "Episode Count:  621 \t Cumulative Reward:  17.0 \t eps:  0.537\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.7018\n",
      "Episode Count:  622 \t Cumulative Reward:  46.4 \t eps:  0.536\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.8531\n",
      "Episode Count:  623 \t Cumulative Reward:  31.38 \t eps:  0.536\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.6916\n",
      "Episode Count:  624 \t Cumulative Reward:  22.45 \t eps:  0.535\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.6514\n",
      "Episode Count:  625 \t Cumulative Reward:  20.43 \t eps:  0.535\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.7368\n",
      "Episode Count:  626 \t Cumulative Reward:  33.71 \t eps:  0.534\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6033\n",
      "Episode Count:  627 \t Cumulative Reward:  61.16 \t eps:  0.533\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.7189\n",
      "Episode Count:  628 \t Cumulative Reward:  25.27 \t eps:  0.533\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.7017\n",
      "Episode Count:  629 \t Cumulative Reward:  67.45 \t eps:  0.532\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.9099\n",
      "Episode Count:  630 \t Cumulative Reward:  16.43 \t eps:  0.532\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.8134\n",
      "Episode Count:  631 \t Cumulative Reward:  12.29 \t eps:  0.531\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.8181\n",
      "Episode Count:  632 \t Cumulative Reward:  12.56 \t eps:  0.531\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6808\n",
      "Episode Count:  633 \t Cumulative Reward:  42.07 \t eps:  0.53\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.8115\n",
      "Episode Count:  634 \t Cumulative Reward:  65.09 \t eps:  0.53\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.8541\n",
      "Episode Count:  635 \t Cumulative Reward:  21.89 \t eps:  0.529\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.7162\n",
      "Episode Count:  636 \t Cumulative Reward:  21.57 \t eps:  0.529\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 0.7151\n",
      "Episode Count:  637 \t Cumulative Reward:  51.19 \t eps:  0.528\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.7719\n",
      "Episode Count:  638 \t Cumulative Reward:  12.02 \t eps:  0.528\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.8265\n",
      "Episode Count:  639 \t Cumulative Reward:  19.77 \t eps:  0.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 82ms/step - loss: 0.8457\n",
      "Episode Count:  640 \t Cumulative Reward:  9.01 \t eps:  0.527\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.8291\n",
      "Episode Count:  641 \t Cumulative Reward:  33.11 \t eps:  0.526\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.7842\n",
      "Episode Count:  642 \t Cumulative Reward:  42.93 \t eps:  0.526\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.7012\n",
      "Episode Count:  643 \t Cumulative Reward:  18.44 \t eps:  0.525\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.7194\n",
      "Episode Count:  644 \t Cumulative Reward:  35.65 \t eps:  0.524\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.7641: 0s - loss: 0.73\n",
      "Episode Count:  645 \t Cumulative Reward:  7.78 \t eps:  0.524\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.6648\n",
      "Episode Count:  646 \t Cumulative Reward:  25.26 \t eps:  0.523\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6935\n",
      "Episode Count:  647 \t Cumulative Reward:  11.27 \t eps:  0.523\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6543\n",
      "Episode Count:  648 \t Cumulative Reward:  39.42 \t eps:  0.522\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6959\n",
      "Episode Count:  649 \t Cumulative Reward:  25.72 \t eps:  0.522\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6791\n",
      "Episode Count:  650 \t Cumulative Reward:  12.76 \t eps:  0.521\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.6329: 0s - loss: 0.632\n",
      "Episode Count:  651 \t Cumulative Reward:  17.92 \t eps:  0.521\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.6550\n",
      "Episode Count:  652 \t Cumulative Reward:  50.18 \t eps:  0.52\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6932\n",
      "Episode Count:  653 \t Cumulative Reward:  48.08 \t eps:  0.52\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6959\n",
      "Episode Count:  654 \t Cumulative Reward:  16.53 \t eps:  0.519\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.6426\n",
      "Episode Count:  655 \t Cumulative Reward:  21.4 \t eps:  0.519\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6845\n",
      "Episode Count:  656 \t Cumulative Reward:  28.0 \t eps:  0.518\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6807\n",
      "Episode Count:  657 \t Cumulative Reward:  -0.0 \t eps:  0.518\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.6821\n",
      "Episode Count:  658 \t Cumulative Reward:  19.01 \t eps:  0.517\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6226\n",
      "Episode Count:  659 \t Cumulative Reward:  13.54 \t eps:  0.517\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6254\n",
      "Episode Count:  660 \t Cumulative Reward:  48.48 \t eps:  0.516\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.7683\n",
      "Episode Count:  661 \t Cumulative Reward:  3.74 \t eps:  0.516\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.8429\n",
      "Episode Count:  662 \t Cumulative Reward:  55.54 \t eps:  0.515\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6781\n",
      "Episode Count:  663 \t Cumulative Reward:  14.41 \t eps:  0.515\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.7060\n",
      "Episode Count:  664 \t Cumulative Reward:  23.97 \t eps:  0.514\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.7399\n",
      "Episode Count:  665 \t Cumulative Reward:  33.71 \t eps:  0.514\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.7916\n",
      "Episode Count:  666 \t Cumulative Reward:  19.27 \t eps:  0.513\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 0.6707\n",
      "Episode Count:  667 \t Cumulative Reward:  50.01 \t eps:  0.513\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.6443\n",
      "Episode Count:  668 \t Cumulative Reward:  22.6 \t eps:  0.512\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6882\n",
      "Episode Count:  669 \t Cumulative Reward:  21.96 \t eps:  0.512\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.6358\n",
      "Episode Count:  670 \t Cumulative Reward:  10.73 \t eps:  0.511\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.7269\n",
      "Episode Count:  671 \t Cumulative Reward:  19.07 \t eps:  0.511\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 0.6484\n",
      "Episode Count:  672 \t Cumulative Reward:  19.39 \t eps:  0.51\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.6005: 0s - loss: 0.55\n",
      "Episode Count:  673 \t Cumulative Reward:  50.33 \t eps:  0.509\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.7535\n",
      "Episode Count:  674 \t Cumulative Reward:  44.25 \t eps:  0.509\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.6123\n",
      "Episode Count:  675 \t Cumulative Reward:  24.67 \t eps:  0.508\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6925\n",
      "Episode Count:  676 \t Cumulative Reward:  18.82 \t eps:  0.508\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.7374\n",
      "Episode Count:  677 \t Cumulative Reward:  25.25 \t eps:  0.507\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.7827: 0s - los\n",
      "Episode Count:  678 \t Cumulative Reward:  24.37 \t eps:  0.507\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.8661\n",
      "Episode Count:  679 \t Cumulative Reward:  33.1 \t eps:  0.506\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.6724\n",
      "Episode Count:  680 \t Cumulative Reward:  18.87 \t eps:  0.506\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.6624\n",
      "Episode Count:  681 \t Cumulative Reward:  37.42 \t eps:  0.505\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.6971\n",
      "Episode Count:  682 \t Cumulative Reward:  18.27 \t eps:  0.505\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.5825\n",
      "Episode Count:  683 \t Cumulative Reward:  20.5 \t eps:  0.504\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.6078\n",
      "Episode Count:  684 \t Cumulative Reward:  35.38 \t eps:  0.504\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6521\n",
      "Episode Count:  685 \t Cumulative Reward:  64.49 \t eps:  0.503\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5698\n",
      "Episode Count:  686 \t Cumulative Reward:  27.75 \t eps:  0.503\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6185\n",
      "Episode Count:  687 \t Cumulative Reward:  13.0 \t eps:  0.502\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.6144\n",
      "Episode Count:  688 \t Cumulative Reward:  20.06 \t eps:  0.502\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.7269\n",
      "Episode Count:  689 \t Cumulative Reward:  28.3 \t eps:  0.501\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.6306\n",
      "Episode Count:  690 \t Cumulative Reward:  6.6 \t eps:  0.501\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.6306\n",
      "Episode Count:  691 \t Cumulative Reward:  32.09 \t eps:  0.5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.7606\n",
      "Episode Count:  692 \t Cumulative Reward:  30.52 \t eps:  0.5\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 0.6221\n",
      "Episode Count:  693 \t Cumulative Reward:  41.64 \t eps:  0.499\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.5960\n",
      "Episode Count:  694 \t Cumulative Reward:  56.73 \t eps:  0.499\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.6376\n",
      "Episode Count:  695 \t Cumulative Reward:  38.79 \t eps:  0.498\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.7488\n",
      "Episode Count:  696 \t Cumulative Reward:  16.82 \t eps:  0.498\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.6877\n",
      "Episode Count:  697 \t Cumulative Reward:  22.8 \t eps:  0.497\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6312\n",
      "Episode Count:  698 \t Cumulative Reward:  59.38 \t eps:  0.497\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.7616\n",
      "Episode Count:  699 \t Cumulative Reward:  66.16 \t eps:  0.496\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 1.3260\n",
      "Episode Count:  700 \t Cumulative Reward:  27.11 \t eps:  0.496\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 1.5182\n",
      "Episode Count:  701 \t Cumulative Reward:  12.31 \t eps:  0.495\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 1.4957\n",
      "Episode Count:  702 \t Cumulative Reward:  62.26 \t eps:  0.495\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 1.2904\n",
      "Episode Count:  703 \t Cumulative Reward:  62.11 \t eps:  0.494\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.4463\n",
      "Episode Count:  704 \t Cumulative Reward:  27.93 \t eps:  0.494\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.1756\n",
      "Episode Count:  705 \t Cumulative Reward:  40.59 \t eps:  0.493\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.2446\n",
      "Episode Count:  706 \t Cumulative Reward:  20.05 \t eps:  0.493\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.3032\n",
      "Episode Count:  707 \t Cumulative Reward:  31.33 \t eps:  0.492\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 1.6124\n",
      "Episode Count:  708 \t Cumulative Reward:  25.1 \t eps:  0.492\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 1.1610\n",
      "Episode Count:  709 \t Cumulative Reward:  39.99 \t eps:  0.491\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 1.2452\n",
      "Episode Count:  710 \t Cumulative Reward:  40.89 \t eps:  0.491\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.0663\n",
      "Episode Count:  711 \t Cumulative Reward:  16.13 \t eps:  0.49\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 1.0117\n",
      "Episode Count:  712 \t Cumulative Reward:  25.55 \t eps:  0.49\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 1.0713\n",
      "Episode Count:  713 \t Cumulative Reward:  20.89 \t eps:  0.49\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.9849\n",
      "Episode Count:  714 \t Cumulative Reward:  26.27 \t eps:  0.489\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 1.0499\n",
      "Episode Count:  715 \t Cumulative Reward:  34.49 \t eps:  0.489\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.9500\n",
      "Episode Count:  716 \t Cumulative Reward:  131.59 \t eps:  0.488\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 1.0312\n",
      "Episode Count:  717 \t Cumulative Reward:  44.2 \t eps:  0.488\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.9758\n",
      "Episode Count:  718 \t Cumulative Reward:  23.47 \t eps:  0.487\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 1.0823\n",
      "Episode Count:  719 \t Cumulative Reward:  44.52 \t eps:  0.487\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 1.0148\n",
      "Episode Count:  720 \t Cumulative Reward:  16.42 \t eps:  0.486\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.9868\n",
      "Episode Count:  721 \t Cumulative Reward:  11.67 \t eps:  0.486\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.9942\n",
      "Episode Count:  722 \t Cumulative Reward:  62.21 \t eps:  0.485\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.0341\n",
      "Episode Count:  723 \t Cumulative Reward:  11.08 \t eps:  0.485\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.0491\n",
      "Episode Count:  724 \t Cumulative Reward:  54.8 \t eps:  0.484\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.9057\n",
      "Episode Count:  725 \t Cumulative Reward:  35.59 \t eps:  0.484\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.2386\n",
      "Episode Count:  726 \t Cumulative Reward:  43.1 \t eps:  0.483\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.8478\n",
      "Episode Count:  727 \t Cumulative Reward:  45.02 \t eps:  0.483\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.0441\n",
      "Episode Count:  728 \t Cumulative Reward:  14.1 \t eps:  0.482\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.1060\n",
      "Episode Count:  729 \t Cumulative Reward:  19.33 \t eps:  0.482\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 0.9165\n",
      "Episode Count:  730 \t Cumulative Reward:  28.55 \t eps:  0.481\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 0.9623\n",
      "Episode Count:  731 \t Cumulative Reward:  32.87 \t eps:  0.481\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.8780\n",
      "Episode Count:  732 \t Cumulative Reward:  13.96 \t eps:  0.48\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.9779\n",
      "Episode Count:  733 \t Cumulative Reward:  84.42 \t eps:  0.48\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.9651\n",
      "Episode Count:  734 \t Cumulative Reward:  15.87 \t eps:  0.479\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.8878\n",
      "Episode Count:  735 \t Cumulative Reward:  47.95 \t eps:  0.479\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.9433\n",
      "Episode Count:  736 \t Cumulative Reward:  21.72 \t eps:  0.478\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.9846\n",
      "Episode Count:  737 \t Cumulative Reward:  63.86 \t eps:  0.478\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.8655\n",
      "Episode Count:  738 \t Cumulative Reward:  19.95 \t eps:  0.477\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 1.0070\n",
      "Episode Count:  739 \t Cumulative Reward:  17.53 \t eps:  0.477\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 0.9624\n",
      "Episode Count:  740 \t Cumulative Reward:  4.83 \t eps:  0.476\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.9156\n",
      "Episode Count:  741 \t Cumulative Reward:  25.98 \t eps:  0.476\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 1.0386\n",
      "Episode Count:  742 \t Cumulative Reward:  52.69 \t eps:  0.476\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8627\n",
      "Episode Count:  743 \t Cumulative Reward:  16.08 \t eps:  0.475\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 0.9272\n",
      "Episode Count:  744 \t Cumulative Reward:  39.07 \t eps:  0.475\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.8174\n",
      "Episode Count:  745 \t Cumulative Reward:  27.22 \t eps:  0.474\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.7928\n",
      "Episode Count:  746 \t Cumulative Reward:  18.24 \t eps:  0.474\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 0.7660\n",
      "Episode Count:  747 \t Cumulative Reward:  42.8 \t eps:  0.473\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.7084\n",
      "Episode Count:  748 \t Cumulative Reward:  29.44 \t eps:  0.473\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.9290\n",
      "Episode Count:  749 \t Cumulative Reward:  38.73 \t eps:  0.472\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 0.9841\n",
      "Episode Count:  750 \t Cumulative Reward:  28.05 \t eps:  0.472\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.0066\n",
      "Episode Count:  751 \t Cumulative Reward:  22.23 \t eps:  0.471\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 1.0574\n",
      "Episode Count:  752 \t Cumulative Reward:  57.44 \t eps:  0.471\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.9249\n",
      "Episode Count:  753 \t Cumulative Reward:  20.81 \t eps:  0.47\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.9841: 0s - loss: 0\n",
      "Episode Count:  754 \t Cumulative Reward:  23.8 \t eps:  0.47\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.9917\n",
      "Episode Count:  755 \t Cumulative Reward:  45.93 \t eps:  0.469\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.0402\n",
      "Episode Count:  756 \t Cumulative Reward:  35.26 \t eps:  0.469\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8685\n",
      "Episode Count:  757 \t Cumulative Reward:  6.52 \t eps:  0.468\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.8655\n",
      "Episode Count:  758 \t Cumulative Reward:  45.53 \t eps:  0.468\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.8169\n",
      "Episode Count:  759 \t Cumulative Reward:  6.68 \t eps:  0.467\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.8450\n",
      "Episode Count:  760 \t Cumulative Reward:  6.27 \t eps:  0.467\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.9996\n",
      "Episode Count:  761 \t Cumulative Reward:  66.5 \t eps:  0.467\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.9783\n",
      "Episode Count:  762 \t Cumulative Reward:  4.46 \t eps:  0.466\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.8390\n",
      "Episode Count:  763 \t Cumulative Reward:  64.62 \t eps:  0.466\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.8105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Count:  764 \t Cumulative Reward:  32.4 \t eps:  0.465\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.9025\n",
      "Episode Count:  765 \t Cumulative Reward:  36.68 \t eps:  0.465\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 1.0020\n",
      "Episode Count:  766 \t Cumulative Reward:  23.97 \t eps:  0.464\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 0.8454\n",
      "Episode Count:  767 \t Cumulative Reward:  16.8 \t eps:  0.464\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 0.9778\n",
      "Episode Count:  768 \t Cumulative Reward:  24.18 \t eps:  0.463\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.8203\n",
      "Episode Count:  769 \t Cumulative Reward:  22.19 \t eps:  0.463\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.8808\n",
      "Episode Count:  770 \t Cumulative Reward:  32.82 \t eps:  0.462\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.8775\n",
      "Episode Count:  771 \t Cumulative Reward:  17.49 \t eps:  0.462\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.7148\n",
      "Episode Count:  772 \t Cumulative Reward:  14.17 \t eps:  0.461\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.7969\n",
      "Episode Count:  773 \t Cumulative Reward:  12.45 \t eps:  0.461\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.8167\n",
      "Episode Count:  774 \t Cumulative Reward:  21.63 \t eps:  0.461\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.8363\n",
      "Episode Count:  775 \t Cumulative Reward:  13.36 \t eps:  0.46\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.9110\n",
      "Episode Count:  776 \t Cumulative Reward:  32.7 \t eps:  0.46\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.9522\n",
      "Episode Count:  777 \t Cumulative Reward:  20.91 \t eps:  0.459\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.7516\n",
      "Episode Count:  778 \t Cumulative Reward:  11.85 \t eps:  0.459\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.9076\n",
      "Episode Count:  779 \t Cumulative Reward:  24.95 \t eps:  0.458\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.8746\n",
      "Episode Count:  780 \t Cumulative Reward:  73.12 \t eps:  0.458\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.8513\n",
      "Episode Count:  781 \t Cumulative Reward:  51.73 \t eps:  0.457\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.8069\n",
      "Episode Count:  782 \t Cumulative Reward:  15.27 \t eps:  0.457\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.8301\n",
      "Episode Count:  783 \t Cumulative Reward:  0.72 \t eps:  0.456\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.9414\n",
      "Episode Count:  784 \t Cumulative Reward:  8.37 \t eps:  0.456\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.8454\n",
      "Episode Count:  785 \t Cumulative Reward:  31.09 \t eps:  0.455\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 0.7344\n",
      "Episode Count:  786 \t Cumulative Reward:  23.55 \t eps:  0.455\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.7495\n",
      "Episode Count:  787 \t Cumulative Reward:  11.21 \t eps:  0.455\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.7685\n",
      "Episode Count:  788 \t Cumulative Reward:  23.81 \t eps:  0.454\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.7519\n",
      "Episode Count:  789 \t Cumulative Reward:  14.24 \t eps:  0.454\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.8634\n",
      "Episode Count:  790 \t Cumulative Reward:  2.92 \t eps:  0.453\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.9081\n",
      "Episode Count:  791 \t Cumulative Reward:  47.38 \t eps:  0.453\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 0.7842\n",
      "Episode Count:  792 \t Cumulative Reward:  52.62 \t eps:  0.452\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.1237\n",
      "Episode Count:  793 \t Cumulative Reward:  14.25 \t eps:  0.452\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.7846\n",
      "Episode Count:  794 \t Cumulative Reward:  61.19 \t eps:  0.451\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.8321\n",
      "Episode Count:  795 \t Cumulative Reward:  36.8 \t eps:  0.451\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.9077\n",
      "Episode Count:  796 \t Cumulative Reward:  50.44 \t eps:  0.45\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.9813\n",
      "Episode Count:  797 \t Cumulative Reward:  32.26 \t eps:  0.45\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.8959\n",
      "Episode Count:  798 \t Cumulative Reward:  15.22 \t eps:  0.45\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.8843\n",
      "Episode Count:  799 \t Cumulative Reward:  29.42 \t eps:  0.449\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.5900\n",
      "run 0: cumulative_reward: 73.67, ran for: 43 timesteps\n",
      "run 1: cumulative_reward: 34.97, ran for: 13 timesteps\n",
      "run 2: cumulative_reward: 53.09, ran for: 34 timesteps\n",
      "run 3: cumulative_reward: 24.56, ran for: 13 timesteps\n",
      "run 4: cumulative_reward: 52.5, ran for: 23 timesteps\n",
      "average performance:  47.758\n",
      "Episode Count:  800 \t Cumulative Reward:  4.49 \t eps:  0.449\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 1.5027\n",
      "Episode Count:  801 \t Cumulative Reward:  69.27 \t eps:  0.448\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 1.3438\n",
      "Episode Count:  802 \t Cumulative Reward:  17.79 \t eps:  0.448\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.3238\n",
      "Episode Count:  803 \t Cumulative Reward:  22.41 \t eps:  0.447\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.1814\n",
      "Episode Count:  804 \t Cumulative Reward:  35.77 \t eps:  0.447\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.1482\n",
      "Episode Count:  805 \t Cumulative Reward:  38.6 \t eps:  0.446\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 1.2544\n",
      "Episode Count:  806 \t Cumulative Reward:  18.17 \t eps:  0.446\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 1.3047\n",
      "Episode Count:  807 \t Cumulative Reward:  31.98 \t eps:  0.446\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 1.1995\n",
      "Episode Count:  808 \t Cumulative Reward:  17.62 \t eps:  0.445\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.0361\n",
      "Episode Count:  809 \t Cumulative Reward:  12.71 \t eps:  0.445\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 0.9782\n",
      "Episode Count:  810 \t Cumulative Reward:  10.98 \t eps:  0.444\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 0.9936\n",
      "Episode Count:  811 \t Cumulative Reward:  34.3 \t eps:  0.444\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 1.0753\n",
      "Episode Count:  812 \t Cumulative Reward:  31.55 \t eps:  0.443\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 1.1401\n",
      "Episode Count:  813 \t Cumulative Reward:  17.48 \t eps:  0.443\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.9713\n",
      "Episode Count:  814 \t Cumulative Reward:  48.4 \t eps:  0.442\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 1.0229\n",
      "Episode Count:  815 \t Cumulative Reward:  9.69 \t eps:  0.442\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 1.1126\n",
      "Episode Count:  816 \t Cumulative Reward:  38.51 \t eps:  0.442\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.2302\n",
      "Episode Count:  817 \t Cumulative Reward:  9.28 \t eps:  0.441\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.2152\n",
      "Episode Count:  818 \t Cumulative Reward:  43.76 \t eps:  0.441\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.1817\n",
      "Episode Count:  819 \t Cumulative Reward:  11.35 \t eps:  0.44\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.2768\n",
      "Episode Count:  820 \t Cumulative Reward:  23.41 \t eps:  0.44\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.0667\n",
      "Episode Count:  821 \t Cumulative Reward:  22.45 \t eps:  0.439\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.4614\n",
      "Episode Count:  822 \t Cumulative Reward:  18.07 \t eps:  0.439\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 1.2414\n",
      "Episode Count:  823 \t Cumulative Reward:  55.56 \t eps:  0.438\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.2013\n",
      "Episode Count:  824 \t Cumulative Reward:  19.47 \t eps:  0.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 89ms/step - loss: 1.0633\n",
      "Episode Count:  825 \t Cumulative Reward:  17.5 \t eps:  0.438\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 1.0767\n",
      "Episode Count:  826 \t Cumulative Reward:  39.51 \t eps:  0.437\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 1.0953\n",
      "Episode Count:  827 \t Cumulative Reward:  40.04 \t eps:  0.437\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 1.1121\n",
      "Episode Count:  828 \t Cumulative Reward:  25.1 \t eps:  0.436\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 1.3539\n",
      "Episode Count:  829 \t Cumulative Reward:  56.18 \t eps:  0.436\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 1.1389\n",
      "Episode Count:  830 \t Cumulative Reward:  27.43 \t eps:  0.435\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 1.0345\n",
      "Episode Count:  831 \t Cumulative Reward:  16.66 \t eps:  0.435\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 1.1174\n",
      "Episode Count:  832 \t Cumulative Reward:  27.31 \t eps:  0.435\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 1.0041\n",
      "Episode Count:  833 \t Cumulative Reward:  53.56 \t eps:  0.434\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 1.1168\n",
      "Episode Count:  834 \t Cumulative Reward:  12.59 \t eps:  0.434\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 1.0371\n",
      "Episode Count:  835 \t Cumulative Reward:  7.45 \t eps:  0.433\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 0.9955\n",
      "Episode Count:  836 \t Cumulative Reward:  101.6 \t eps:  0.433\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.0549\n",
      "Episode Count:  837 \t Cumulative Reward:  20.05 \t eps:  0.432\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 0.9837\n",
      "Episode Count:  838 \t Cumulative Reward:  8.81 \t eps:  0.432\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 1.1136\n",
      "Episode Count:  839 \t Cumulative Reward:  34.23 \t eps:  0.432\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.1796\n",
      "Episode Count:  840 \t Cumulative Reward:  37.97 \t eps:  0.431\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.1036\n",
      "Episode Count:  841 \t Cumulative Reward:  22.37 \t eps:  0.431\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.1031\n",
      "Episode Count:  842 \t Cumulative Reward:  20.43 \t eps:  0.43\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.1410\n",
      "Episode Count:  843 \t Cumulative Reward:  19.45 \t eps:  0.43\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 1.1815\n",
      "Episode Count:  844 \t Cumulative Reward:  1.89 \t eps:  0.429\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 1.0757\n",
      "Episode Count:  845 \t Cumulative Reward:  8.43 \t eps:  0.429\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 1.1217\n",
      "Episode Count:  846 \t Cumulative Reward:  12.78 \t eps:  0.429\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 1.0876\n",
      "Episode Count:  847 \t Cumulative Reward:  31.67 \t eps:  0.428\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.9332\n",
      "Episode Count:  848 \t Cumulative Reward:  7.8 \t eps:  0.428\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.0018\n",
      "Episode Count:  849 \t Cumulative Reward:  53.52 \t eps:  0.427\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.0739\n",
      "Episode Count:  850 \t Cumulative Reward:  64.18 \t eps:  0.427\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 0.9556\n",
      "Episode Count:  851 \t Cumulative Reward:  5.39 \t eps:  0.426\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.8715\n",
      "Episode Count:  852 \t Cumulative Reward:  26.26 \t eps:  0.426\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.0429\n",
      "Episode Count:  853 \t Cumulative Reward:  29.0 \t eps:  0.426\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 1.0659\n",
      "Episode Count:  854 \t Cumulative Reward:  13.92 \t eps:  0.425\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 0.8539\n",
      "Episode Count:  855 \t Cumulative Reward:  19.33 \t eps:  0.425\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 0.9863\n",
      "Episode Count:  856 \t Cumulative Reward:  14.4 \t eps:  0.424\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.9923\n",
      "Episode Count:  857 \t Cumulative Reward:  13.9 \t eps:  0.424\n",
      "16/16 [==============================] - 4s 231ms/step - loss: 1.0476\n",
      "Episode Count:  858 \t Cumulative Reward:  25.96 \t eps:  0.423\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 1.0015\n",
      "Episode Count:  859 \t Cumulative Reward:  12.63 \t eps:  0.423\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 1.0876\n",
      "Episode Count:  860 \t Cumulative Reward:  32.06 \t eps:  0.423\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.9029\n",
      "Episode Count:  861 \t Cumulative Reward:  6.43 \t eps:  0.422\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 1.2339\n",
      "Episode Count:  862 \t Cumulative Reward:  31.84 \t eps:  0.422\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 1.0661\n",
      "Episode Count:  863 \t Cumulative Reward:  21.03 \t eps:  0.421\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 1.0456\n",
      "Episode Count:  864 \t Cumulative Reward:  25.08 \t eps:  0.421\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 1.2108\n",
      "Episode Count:  865 \t Cumulative Reward:  21.57 \t eps:  0.42\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 1.2264\n",
      "Episode Count:  866 \t Cumulative Reward:  25.23 \t eps:  0.42\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 1.1844\n",
      "Episode Count:  867 \t Cumulative Reward:  20.21 \t eps:  0.42\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 1.3358\n",
      "Episode Count:  868 \t Cumulative Reward:  25.35 \t eps:  0.419\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 1.0783\n",
      "Episode Count:  869 \t Cumulative Reward:  38.14 \t eps:  0.419\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 1.0464\n",
      "Episode Count:  870 \t Cumulative Reward:  29.28 \t eps:  0.418\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 0.9646\n",
      "Episode Count:  871 \t Cumulative Reward:  26.44 \t eps:  0.418\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 1.0713\n",
      "Episode Count:  872 \t Cumulative Reward:  10.98 \t eps:  0.418\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.0664\n",
      "Episode Count:  873 \t Cumulative Reward:  41.57 \t eps:  0.417\n",
      "16/16 [==============================] - 3s 216ms/step - loss: 1.0764\n",
      "Episode Count:  874 \t Cumulative Reward:  11.18 \t eps:  0.417\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 0.9279\n",
      "Episode Count:  875 \t Cumulative Reward:  25.23 \t eps:  0.416\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.9588\n",
      "Episode Count:  876 \t Cumulative Reward:  32.01 \t eps:  0.416\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 1.1486\n",
      "Episode Count:  877 \t Cumulative Reward:  22.3 \t eps:  0.415\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.1333\n",
      "Episode Count:  878 \t Cumulative Reward:  79.0 \t eps:  0.415\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.0786\n",
      "Episode Count:  879 \t Cumulative Reward:  -19.33 \t eps:  0.415\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.1687 1s - l\n",
      "Episode Count:  880 \t Cumulative Reward:  12.28 \t eps:  0.414\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 1.0954\n",
      "Episode Count:  881 \t Cumulative Reward:  13.67 \t eps:  0.414\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.8577\n",
      "Episode Count:  882 \t Cumulative Reward:  24.83 \t eps:  0.413\n",
      "16/16 [==============================] - 3s 209ms/step - loss: 1.0004\n",
      "Episode Count:  883 \t Cumulative Reward:  38.46 \t eps:  0.413\n",
      "16/16 [==============================] - 4s 227ms/step - loss: 1.1459\n",
      "Episode Count:  884 \t Cumulative Reward:  12.49 \t eps:  0.413\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 1.0352\n",
      "Episode Count:  885 \t Cumulative Reward:  30.11 \t eps:  0.412\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 0.9116\n",
      "Episode Count:  886 \t Cumulative Reward:  21.75 \t eps:  0.412\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.1562\n",
      "Episode Count:  887 \t Cumulative Reward:  12.65 \t eps:  0.411\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 1.1008\n",
      "Episode Count:  888 \t Cumulative Reward:  18.07 \t eps:  0.411\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 0.9966\n",
      "Episode Count:  889 \t Cumulative Reward:  24.56 \t eps:  0.41\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.9599\n",
      "Episode Count:  890 \t Cumulative Reward:  -13.9 \t eps:  0.41\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 1.1239\n",
      "Episode Count:  891 \t Cumulative Reward:  19.18 \t eps:  0.41\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 1.2246\n",
      "Episode Count:  892 \t Cumulative Reward:  14.28 \t eps:  0.409\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.0427\n",
      "Episode Count:  893 \t Cumulative Reward:  22.15 \t eps:  0.409\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9807\n",
      "Episode Count:  894 \t Cumulative Reward:  41.8 \t eps:  0.408\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.8723\n",
      "Episode Count:  895 \t Cumulative Reward:  30.16 \t eps:  0.408\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.9772\n",
      "Episode Count:  896 \t Cumulative Reward:  42.81 \t eps:  0.408\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 1.3309\n",
      "Episode Count:  897 \t Cumulative Reward:  22.15 \t eps:  0.407\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.8720\n",
      "Episode Count:  898 \t Cumulative Reward:  68.23 \t eps:  0.407\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 1.1700\n",
      "Episode Count:  899 \t Cumulative Reward:  21.25 \t eps:  0.406\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 1.7771\n",
      "Episode Count:  900 \t Cumulative Reward:  33.88 \t eps:  0.406\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 1.6902\n",
      "Episode Count:  901 \t Cumulative Reward:  10.24 \t eps:  0.406\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 1.6647\n",
      "Episode Count:  902 \t Cumulative Reward:  44.91 \t eps:  0.405\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.6935\n",
      "Episode Count:  903 \t Cumulative Reward:  25.52 \t eps:  0.405\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.4074\n",
      "Episode Count:  904 \t Cumulative Reward:  26.0 \t eps:  0.404\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.4328\n",
      "Episode Count:  905 \t Cumulative Reward:  28.87 \t eps:  0.404\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.3884 1s\n",
      "Episode Count:  906 \t Cumulative Reward:  21.07 \t eps:  0.404\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 1.5341\n",
      "Episode Count:  907 \t Cumulative Reward:  55.7 \t eps:  0.403\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.5258\n",
      "Episode Count:  908 \t Cumulative Reward:  14.19 \t eps:  0.403\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 1.4816\n",
      "Episode Count:  909 \t Cumulative Reward:  32.68 \t eps:  0.402\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 1.5043\n",
      "Episode Count:  910 \t Cumulative Reward:  26.91 \t eps:  0.402\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.2986\n",
      "Episode Count:  911 \t Cumulative Reward:  47.95 \t eps:  0.402\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 1.0324\n",
      "Episode Count:  912 \t Cumulative Reward:  18.8 \t eps:  0.401\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.3491\n",
      "Episode Count:  913 \t Cumulative Reward:  13.1 \t eps:  0.401\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 1.2884\n",
      "Episode Count:  914 \t Cumulative Reward:  50.39 \t eps:  0.4\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 1.3275\n",
      "Episode Count:  915 \t Cumulative Reward:  26.05 \t eps:  0.4\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 1.2234\n",
      "Episode Count:  916 \t Cumulative Reward:  36.41 \t eps:  0.4\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.2541\n",
      "Episode Count:  917 \t Cumulative Reward:  18.21 \t eps:  0.399\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 1.1135\n",
      "Episode Count:  918 \t Cumulative Reward:  25.5 \t eps:  0.399\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 1.3006\n",
      "Episode Count:  919 \t Cumulative Reward:  5.66 \t eps:  0.398\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 1.3347\n",
      "Episode Count:  920 \t Cumulative Reward:  20.44 \t eps:  0.398\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.3683\n",
      "Episode Count:  921 \t Cumulative Reward:  23.44 \t eps:  0.398\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 1.1975\n",
      "Episode Count:  922 \t Cumulative Reward:  2.57 \t eps:  0.397\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 1.2286\n",
      "Episode Count:  923 \t Cumulative Reward:  9.7 \t eps:  0.397\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.3968\n",
      "Episode Count:  924 \t Cumulative Reward:  11.75 \t eps:  0.396\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.3542\n",
      "Episode Count:  925 \t Cumulative Reward:  29.4 \t eps:  0.396\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.2004\n",
      "Episode Count:  926 \t Cumulative Reward:  19.64 \t eps:  0.396\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 1.3516\n",
      "Episode Count:  927 \t Cumulative Reward:  32.34 \t eps:  0.395\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.1180\n",
      "Episode Count:  928 \t Cumulative Reward:  44.32 \t eps:  0.395\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.1675\n",
      "Episode Count:  929 \t Cumulative Reward:  19.03 \t eps:  0.394\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 1.5003\n",
      "Episode Count:  930 \t Cumulative Reward:  21.11 \t eps:  0.394\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.0897\n",
      "Episode Count:  931 \t Cumulative Reward:  20.07 \t eps:  0.394\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.1243\n",
      "Episode Count:  932 \t Cumulative Reward:  49.66 \t eps:  0.393\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.1320\n",
      "Episode Count:  933 \t Cumulative Reward:  15.9 \t eps:  0.393\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.0626\n",
      "Episode Count:  934 \t Cumulative Reward:  40.9 \t eps:  0.392\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 1.0945\n",
      "Episode Count:  935 \t Cumulative Reward:  20.92 \t eps:  0.392\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9927\n",
      "Episode Count:  936 \t Cumulative Reward:  21.55 \t eps:  0.392\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.4472\n",
      "Episode Count:  937 \t Cumulative Reward:  0.91 \t eps:  0.391\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.1683\n",
      "Episode Count:  938 \t Cumulative Reward:  36.3 \t eps:  0.391\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.4008\n",
      "Episode Count:  939 \t Cumulative Reward:  23.49 \t eps:  0.39\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.3090\n",
      "Episode Count:  940 \t Cumulative Reward:  9.92 \t eps:  0.39\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.2089\n",
      "Episode Count:  941 \t Cumulative Reward:  41.98 \t eps:  0.39\n",
      "16/16 [==============================] - 4s 227ms/step - loss: 1.1328\n",
      "Episode Count:  942 \t Cumulative Reward:  27.89 \t eps:  0.389\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 0.9878\n",
      "Episode Count:  943 \t Cumulative Reward:  46.18 \t eps:  0.389\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 1.4230\n",
      "Episode Count:  944 \t Cumulative Reward:  23.64 \t eps:  0.388\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 1.1965\n",
      "Episode Count:  945 \t Cumulative Reward:  41.77 \t eps:  0.388\n",
      "16/16 [==============================] - 4s 224ms/step - loss: 1.3214\n",
      "Episode Count:  946 \t Cumulative Reward:  27.17 \t eps:  0.388\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 1.2834\n",
      "Episode Count:  947 \t Cumulative Reward:  22.6 \t eps:  0.387\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 1.3016\n",
      "Episode Count:  948 \t Cumulative Reward:  16.54 \t eps:  0.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 287ms/step - loss: 1.3338\n",
      "Episode Count:  949 \t Cumulative Reward:  20.16 \t eps:  0.387\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 1.1806\n",
      "Episode Count:  950 \t Cumulative Reward:  7.42 \t eps:  0.386\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 1.1052\n",
      "Episode Count:  951 \t Cumulative Reward:  18.83 \t eps:  0.386\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 1.1258\n",
      "Episode Count:  952 \t Cumulative Reward:  50.94 \t eps:  0.385\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 1.1843\n",
      "Episode Count:  953 \t Cumulative Reward:  27.75 \t eps:  0.385\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.1813\n",
      "Episode Count:  954 \t Cumulative Reward:  27.63 \t eps:  0.385\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 1.3979\n",
      "Episode Count:  955 \t Cumulative Reward:  61.85 \t eps:  0.384\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.2364\n",
      "Episode Count:  956 \t Cumulative Reward:  22.99 \t eps:  0.384\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 1.1994\n",
      "Episode Count:  957 \t Cumulative Reward:  27.01 \t eps:  0.383\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 1.2915\n",
      "Episode Count:  958 \t Cumulative Reward:  17.54 \t eps:  0.383\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 1.0957\n",
      "Episode Count:  959 \t Cumulative Reward:  13.04 \t eps:  0.383\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 1.1315\n",
      "Episode Count:  960 \t Cumulative Reward:  22.53 \t eps:  0.382\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 1.3397\n",
      "Episode Count:  961 \t Cumulative Reward:  34.68 \t eps:  0.382\n",
      "16/16 [==============================] - 5s 301ms/step - loss: 1.2763\n",
      "Episode Count:  962 \t Cumulative Reward:  14.82 \t eps:  0.382\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 1.0967\n",
      "Episode Count:  963 \t Cumulative Reward:  29.85 \t eps:  0.381\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 1.1223\n",
      "Episode Count:  964 \t Cumulative Reward:  22.71 \t eps:  0.381\n",
      "16/16 [==============================] - 5s 299ms/step - loss: 1.1788\n",
      "Episode Count:  965 \t Cumulative Reward:  38.51 \t eps:  0.38\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 1.1768\n",
      "Episode Count:  966 \t Cumulative Reward:  47.75 \t eps:  0.38\n",
      "16/16 [==============================] - 5s 289ms/step - loss: 1.2006\n",
      "Episode Count:  967 \t Cumulative Reward:  28.31 \t eps:  0.38\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 1.1663\n",
      "Episode Count:  968 \t Cumulative Reward:  32.16 \t eps:  0.379\n",
      "16/16 [==============================] - 5s 314ms/step - loss: 1.3811\n",
      "Episode Count:  969 \t Cumulative Reward:  36.97 \t eps:  0.379\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 1.2501\n",
      "Episode Count:  970 \t Cumulative Reward:  31.45 \t eps:  0.379\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.9607\n",
      "Episode Count:  971 \t Cumulative Reward:  14.02 \t eps:  0.378\n",
      "16/16 [==============================] - 5s 319ms/step - loss: 1.1491\n",
      "Episode Count:  972 \t Cumulative Reward:  34.95 \t eps:  0.378\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.1403\n",
      "Episode Count:  973 \t Cumulative Reward:  44.11 \t eps:  0.377\n",
      "16/16 [==============================] - 3s 213ms/step - loss: 1.0098\n",
      "Episode Count:  974 \t Cumulative Reward:  25.05 \t eps:  0.377\n",
      "16/16 [==============================] - 3s 218ms/step - loss: 1.3009\n",
      "Episode Count:  975 \t Cumulative Reward:  53.19 \t eps:  0.377\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.1599\n",
      "Episode Count:  976 \t Cumulative Reward:  17.21 \t eps:  0.376\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.2990\n",
      "Episode Count:  977 \t Cumulative Reward:  51.2 \t eps:  0.376\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.2368\n",
      "Episode Count:  978 \t Cumulative Reward:  24.57 \t eps:  0.376\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 1.2398\n",
      "Episode Count:  979 \t Cumulative Reward:  -14.89 \t eps:  0.375\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 1.1885\n",
      "Episode Count:  980 \t Cumulative Reward:  24.08 \t eps:  0.375\n",
      "16/16 [==============================] - 4s 281ms/step - loss: 1.1931\n",
      "Episode Count:  981 \t Cumulative Reward:  21.11 \t eps:  0.374\n",
      "16/16 [==============================] - 3s 207ms/step - loss: 1.2772\n",
      "Episode Count:  982 \t Cumulative Reward:  19.76 \t eps:  0.374\n",
      "16/16 [==============================] - 4s 240ms/step - loss: 1.1910\n",
      "Episode Count:  983 \t Cumulative Reward:  10.39 \t eps:  0.374\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 1.1822\n",
      "Episode Count:  984 \t Cumulative Reward:  11.76 \t eps:  0.373\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 1.0936\n",
      "Episode Count:  985 \t Cumulative Reward:  11.18 \t eps:  0.373\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 1.2943\n",
      "Episode Count:  986 \t Cumulative Reward:  23.69 \t eps:  0.373\n",
      "16/16 [==============================] - 3s 204ms/step - loss: 1.1389\n",
      "Episode Count:  987 \t Cumulative Reward:  23.92 \t eps:  0.372\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 1.1936\n",
      "Episode Count:  988 \t Cumulative Reward:  26.67 \t eps:  0.372\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.2153\n",
      "Episode Count:  989 \t Cumulative Reward:  28.5 \t eps:  0.371\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.1596\n",
      "Episode Count:  990 \t Cumulative Reward:  16.25 \t eps:  0.371\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 1.2195\n",
      "Episode Count:  991 \t Cumulative Reward:  43.01 \t eps:  0.371\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 1.2020\n",
      "Episode Count:  992 \t Cumulative Reward:  27.7 \t eps:  0.37\n",
      "16/16 [==============================] - 3s 212ms/step - loss: 1.1196\n",
      "Episode Count:  993 \t Cumulative Reward:  27.22 \t eps:  0.37\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 1.2478\n",
      "Episode Count:  994 \t Cumulative Reward:  15.54 \t eps:  0.37\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 1.0597\n",
      "Episode Count:  995 \t Cumulative Reward:  32.32 \t eps:  0.369\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.9300\n",
      "Episode Count:  996 \t Cumulative Reward:  40.38 \t eps:  0.369\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 1.0751\n",
      "Episode Count:  997 \t Cumulative Reward:  24.81 \t eps:  0.368\n",
      "16/16 [==============================] - 4s 220ms/step - loss: 1.0936\n",
      "Episode Count:  998 \t Cumulative Reward:  20.76 \t eps:  0.368\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 0.8537\n",
      "Episode Count:  999 \t Cumulative Reward:  25.25 \t eps:  0.368\n",
      "16/16 [==============================] - 3s 210ms/step - loss: 2.4088\n",
      "run 0: cumulative_reward: 12.28, ran for: 6 timesteps\n",
      "run 1: cumulative_reward: 102.97, ran for: 25 timesteps\n",
      "run 2: cumulative_reward: 16.56, ran for: 8 timesteps\n",
      "run 3: cumulative_reward: 37.14, ran for: 22 timesteps\n",
      "run 4: cumulative_reward: 20.62, ran for: 6 timesteps\n",
      "average performance:  37.914\n",
      "Episode Count:  1000 \t Cumulative Reward:  15.53 \t eps:  0.367\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 1.8824\n",
      "Episode Count:  1001 \t Cumulative Reward:  29.09 \t eps:  0.367\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 1.8166\n",
      "Episode Count:  1002 \t Cumulative Reward:  41.81 \t eps:  0.367\n",
      "16/16 [==============================] - 5s 291ms/step - loss: 1.7424\n",
      "Episode Count:  1003 \t Cumulative Reward:  10.79 \t eps:  0.366\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 1.7435\n",
      "Episode Count:  1004 \t Cumulative Reward:  58.49 \t eps:  0.366\n",
      "16/16 [==============================] - 4s 249ms/step - loss: 1.7574\n",
      "Episode Count:  1005 \t Cumulative Reward:  13.13 \t eps:  0.365\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 1.9781\n",
      "Episode Count:  1006 \t Cumulative Reward:  29.53 \t eps:  0.365\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 1.7119\n",
      "Episode Count:  1007 \t Cumulative Reward:  35.2 \t eps:  0.365\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 1.8881\n",
      "Episode Count:  1008 \t Cumulative Reward:  35.87 \t eps:  0.364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 294ms/step - loss: 1.6502\n",
      "Episode Count:  1009 \t Cumulative Reward:  11.77 \t eps:  0.364\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 1.6103\n",
      "Episode Count:  1010 \t Cumulative Reward:  61.54 \t eps:  0.364\n",
      "16/16 [==============================] - 4s 254ms/step - loss: 1.5236\n",
      "Episode Count:  1011 \t Cumulative Reward:  18.86 \t eps:  0.363\n",
      "16/16 [==============================] - 4s 225ms/step - loss: 1.4884\n",
      "Episode Count:  1012 \t Cumulative Reward:  24.43 \t eps:  0.363\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 1.6192\n",
      "Episode Count:  1013 \t Cumulative Reward:  53.52 \t eps:  0.363\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 1.5504\n",
      "Episode Count:  1014 \t Cumulative Reward:  6.49 \t eps:  0.362\n",
      "16/16 [==============================] - 5s 291ms/step - loss: 1.3625\n",
      "Episode Count:  1015 \t Cumulative Reward:  57.45 \t eps:  0.362\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 1.4687\n",
      "Episode Count:  1016 \t Cumulative Reward:  9.73 \t eps:  0.361\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 1.5638\n",
      "Episode Count:  1017 \t Cumulative Reward:  38.71 \t eps:  0.361\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 1.3790\n",
      "Episode Count:  1018 \t Cumulative Reward:  35.18 \t eps:  0.361\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 1.3454\n",
      "Episode Count:  1019 \t Cumulative Reward:  25.53 \t eps:  0.36\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 1.2682\n",
      "Episode Count:  1020 \t Cumulative Reward:  25.83 \t eps:  0.36\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 1.5159\n",
      "Episode Count:  1021 \t Cumulative Reward:  26.24 \t eps:  0.36\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 1.5829\n",
      "Episode Count:  1022 \t Cumulative Reward:  34.72 \t eps:  0.359\n",
      "16/16 [==============================] - 4s 239ms/step - loss: 1.4472\n",
      "Episode Count:  1023 \t Cumulative Reward:  65.89 \t eps:  0.359\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 1.3398\n",
      "Episode Count:  1024 \t Cumulative Reward:  43.26 \t eps:  0.359\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 1.3346\n",
      "Episode Count:  1025 \t Cumulative Reward:  51.09 \t eps:  0.358\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 1.2307\n",
      "Episode Count:  1026 \t Cumulative Reward:  30.14 \t eps:  0.358\n",
      "16/16 [==============================] - 5s 321ms/step - loss: 1.5165\n",
      "Episode Count:  1027 \t Cumulative Reward:  19.48 \t eps:  0.358\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.5491\n",
      "Episode Count:  1028 \t Cumulative Reward:  22.99 \t eps:  0.357\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 1.5547\n",
      "Episode Count:  1029 \t Cumulative Reward:  20.01 \t eps:  0.357\n",
      "16/16 [==============================] - 4s 281ms/step - loss: 1.4250\n",
      "Episode Count:  1030 \t Cumulative Reward:  49.34 \t eps:  0.356\n",
      "16/16 [==============================] - 4s 222ms/step - loss: 1.4485 1s -\n",
      "Episode Count:  1031 \t Cumulative Reward:  8.13 \t eps:  0.356\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 1.4824\n",
      "Episode Count:  1032 \t Cumulative Reward:  31.33 \t eps:  0.356\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 1.2642\n",
      "Episode Count:  1033 \t Cumulative Reward:  20.72 \t eps:  0.355\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 1.3798\n",
      "Episode Count:  1034 \t Cumulative Reward:  13.6 \t eps:  0.355\n",
      "16/16 [==============================] - 4s 279ms/step - loss: 1.5737\n",
      "Episode Count:  1035 \t Cumulative Reward:  40.72 \t eps:  0.355\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 1.3826\n",
      "Episode Count:  1036 \t Cumulative Reward:  44.07 \t eps:  0.354\n",
      "16/16 [==============================] - 4s 278ms/step - loss: 1.5901\n",
      "Episode Count:  1037 \t Cumulative Reward:  43.37 \t eps:  0.354\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 1.5528\n",
      "Episode Count:  1038 \t Cumulative Reward:  25.34 \t eps:  0.354\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 1.4521 1s - loss:\n",
      "Episode Count:  1039 \t Cumulative Reward:  22.87 \t eps:  0.353\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 1.5050\n",
      "Episode Count:  1040 \t Cumulative Reward:  20.83 \t eps:  0.353\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.6960\n",
      "Episode Count:  1041 \t Cumulative Reward:  35.44 \t eps:  0.353\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 1.3082\n",
      "Episode Count:  1042 \t Cumulative Reward:  36.35 \t eps:  0.352\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 1.5396\n",
      "Episode Count:  1043 \t Cumulative Reward:  8.53 \t eps:  0.352\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 1.3389\n",
      "Episode Count:  1044 \t Cumulative Reward:  32.41 \t eps:  0.352\n",
      "16/16 [==============================] - 2s 125ms/step - loss: 1.3381\n",
      "Episode Count:  1045 \t Cumulative Reward:  53.02 \t eps:  0.351\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.5255\n",
      "Episode Count:  1046 \t Cumulative Reward:  21.11 \t eps:  0.351\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 1.3857\n",
      "Episode Count:  1047 \t Cumulative Reward:  30.85 \t eps:  0.35\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.4761\n",
      "Episode Count:  1048 \t Cumulative Reward:  14.55 \t eps:  0.35\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.7754\n",
      "Episode Count:  1049 \t Cumulative Reward:  27.48 \t eps:  0.35\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.6853\n",
      "Episode Count:  1050 \t Cumulative Reward:  42.87 \t eps:  0.349\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 1.4729\n",
      "Episode Count:  1051 \t Cumulative Reward:  51.1 \t eps:  0.349\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.2933\n",
      "Episode Count:  1052 \t Cumulative Reward:  36.31 \t eps:  0.349\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.4590\n",
      "Episode Count:  1053 \t Cumulative Reward:  30.05 \t eps:  0.348\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.3439\n",
      "Episode Count:  1054 \t Cumulative Reward:  21.1 \t eps:  0.348\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.4694\n",
      "Episode Count:  1055 \t Cumulative Reward:  24.22 \t eps:  0.348\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 1.5060\n",
      "Episode Count:  1056 \t Cumulative Reward:  20.84 \t eps:  0.347\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.4411\n",
      "Episode Count:  1057 \t Cumulative Reward:  21.17 \t eps:  0.347\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 1.3364\n",
      "Episode Count:  1058 \t Cumulative Reward:  21.29 \t eps:  0.347\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 1.3255\n",
      "Episode Count:  1059 \t Cumulative Reward:  10.39 \t eps:  0.346\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.3110\n",
      "Episode Count:  1060 \t Cumulative Reward:  7.67 \t eps:  0.346\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 1.4142\n",
      "Episode Count:  1061 \t Cumulative Reward:  28.38 \t eps:  0.346\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.6756\n",
      "Episode Count:  1062 \t Cumulative Reward:  26.89 \t eps:  0.345\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 1.9661\n",
      "Episode Count:  1063 \t Cumulative Reward:  42.5 \t eps:  0.345\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.5422\n",
      "Episode Count:  1064 \t Cumulative Reward:  34.7 \t eps:  0.345\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.5044\n",
      "Episode Count:  1065 \t Cumulative Reward:  31.11 \t eps:  0.344\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.4468\n",
      "Episode Count:  1066 \t Cumulative Reward:  27.53 \t eps:  0.344\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.2660\n",
      "Episode Count:  1067 \t Cumulative Reward:  22.3 \t eps:  0.344\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 1.1714\n",
      "Episode Count:  1068 \t Cumulative Reward:  21.97 \t eps:  0.343\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.1873\n",
      "Episode Count:  1069 \t Cumulative Reward:  21.12 \t eps:  0.343\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 1.4009\n",
      "Episode Count:  1070 \t Cumulative Reward:  35.36 \t eps:  0.342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 170ms/step - loss: 1.4106\n",
      "Episode Count:  1071 \t Cumulative Reward:  46.01 \t eps:  0.342\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 1.4846\n",
      "Episode Count:  1072 \t Cumulative Reward:  60.08 \t eps:  0.342\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.6789\n",
      "Episode Count:  1073 \t Cumulative Reward:  32.82 \t eps:  0.341\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.5439\n",
      "Episode Count:  1074 \t Cumulative Reward:  15.47 \t eps:  0.341\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.1784\n",
      "Episode Count:  1075 \t Cumulative Reward:  18.07 \t eps:  0.341\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.2100\n",
      "Episode Count:  1076 \t Cumulative Reward:  34.97 \t eps:  0.34\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.4670\n",
      "Episode Count:  1077 \t Cumulative Reward:  22.68 \t eps:  0.34\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 1.3594\n",
      "Episode Count:  1078 \t Cumulative Reward:  47.03 \t eps:  0.34\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.2890\n",
      "Episode Count:  1079 \t Cumulative Reward:  46.13 \t eps:  0.339\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.3281\n",
      "Episode Count:  1080 \t Cumulative Reward:  10.69 \t eps:  0.339\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.3157\n",
      "Episode Count:  1081 \t Cumulative Reward:  43.51 \t eps:  0.339\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.3910\n",
      "Episode Count:  1082 \t Cumulative Reward:  15.74 \t eps:  0.338\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.3961\n",
      "Episode Count:  1083 \t Cumulative Reward:  21.65 \t eps:  0.338\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.4794\n",
      "Episode Count:  1084 \t Cumulative Reward:  23.04 \t eps:  0.338\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 1.5531\n",
      "Episode Count:  1085 \t Cumulative Reward:  24.76 \t eps:  0.337\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 1.4212\n",
      "Episode Count:  1086 \t Cumulative Reward:  17.86 \t eps:  0.337\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.3279\n",
      "Episode Count:  1087 \t Cumulative Reward:  17.85 \t eps:  0.337\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.4601\n",
      "Episode Count:  1088 \t Cumulative Reward:  22.58 \t eps:  0.336\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.2448\n",
      "Episode Count:  1089 \t Cumulative Reward:  30.63 \t eps:  0.336\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.2224\n",
      "Episode Count:  1090 \t Cumulative Reward:  43.26 \t eps:  0.336\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.0452\n",
      "Episode Count:  1091 \t Cumulative Reward:  30.14 \t eps:  0.335\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.3534\n",
      "Episode Count:  1092 \t Cumulative Reward:  12.56 \t eps:  0.335\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.2142\n",
      "Episode Count:  1093 \t Cumulative Reward:  19.89 \t eps:  0.335\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.2932\n",
      "Episode Count:  1094 \t Cumulative Reward:  42.02 \t eps:  0.334\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 1.5003\n",
      "Episode Count:  1095 \t Cumulative Reward:  61.41 \t eps:  0.334\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.3308\n",
      "Episode Count:  1096 \t Cumulative Reward:  28.62 \t eps:  0.334\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 1.3881\n",
      "Episode Count:  1097 \t Cumulative Reward:  25.36 \t eps:  0.333\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.5213\n",
      "Episode Count:  1098 \t Cumulative Reward:  28.7 \t eps:  0.333\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.7356\n",
      "Episode Count:  1099 \t Cumulative Reward:  40.5 \t eps:  0.333\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 2.5403\n",
      "Episode Count:  1100 \t Cumulative Reward:  111.87 \t eps:  0.332\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 2.4066 0s - loss: 2.3\n",
      "Episode Count:  1101 \t Cumulative Reward:  27.89 \t eps:  0.332\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 1.9567\n",
      "Episode Count:  1102 \t Cumulative Reward:  6.87 \t eps:  0.332\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.7009\n",
      "Episode Count:  1103 \t Cumulative Reward:  57.43 \t eps:  0.331\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 2.0369\n",
      "Episode Count:  1104 \t Cumulative Reward:  37.25 \t eps:  0.331\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 2.2823\n",
      "Episode Count:  1105 \t Cumulative Reward:  17.41 \t eps:  0.331\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.8173\n",
      "Episode Count:  1106 \t Cumulative Reward:  82.25 \t eps:  0.33\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 2.0416\n",
      "Episode Count:  1107 \t Cumulative Reward:  54.41 \t eps:  0.33\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 1.8977\n",
      "Episode Count:  1108 \t Cumulative Reward:  31.17 \t eps:  0.33\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 2.3885\n",
      "Episode Count:  1109 \t Cumulative Reward:  39.9 \t eps:  0.329\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.9358\n",
      "Episode Count:  1110 \t Cumulative Reward:  13.79 \t eps:  0.329\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.9475\n",
      "Episode Count:  1111 \t Cumulative Reward:  42.71 \t eps:  0.329\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 2.0850\n",
      "Episode Count:  1112 \t Cumulative Reward:  28.27 \t eps:  0.328\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 2.5692\n",
      "Episode Count:  1113 \t Cumulative Reward:  45.83 \t eps:  0.328\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.8059\n",
      "Episode Count:  1114 \t Cumulative Reward:  60.47 \t eps:  0.328\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 1.8256\n",
      "Episode Count:  1115 \t Cumulative Reward:  23.71 \t eps:  0.327\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 1.8622\n",
      "Episode Count:  1116 \t Cumulative Reward:  63.01 \t eps:  0.327\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 2.0555\n",
      "Episode Count:  1117 \t Cumulative Reward:  50.36 \t eps:  0.327\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 2.1199\n",
      "Episode Count:  1118 \t Cumulative Reward:  51.86 \t eps:  0.326\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 2.1611\n",
      "Episode Count:  1119 \t Cumulative Reward:  37.81 \t eps:  0.326\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 1.8565\n",
      "Episode Count:  1120 \t Cumulative Reward:  25.42 \t eps:  0.326\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.8389\n",
      "Episode Count:  1121 \t Cumulative Reward:  5.52 \t eps:  0.325\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 2.0887\n",
      "Episode Count:  1122 \t Cumulative Reward:  37.87 \t eps:  0.325\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 1.6298\n",
      "Episode Count:  1123 \t Cumulative Reward:  9.66 \t eps:  0.325\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 1.8096\n",
      "Episode Count:  1124 \t Cumulative Reward:  23.0 \t eps:  0.324\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.7194\n",
      "Episode Count:  1125 \t Cumulative Reward:  27.33 \t eps:  0.324\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 1.8328\n",
      "Episode Count:  1126 \t Cumulative Reward:  12.97 \t eps:  0.324\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 1.5642\n",
      "Episode Count:  1127 \t Cumulative Reward:  28.09 \t eps:  0.323\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.7437\n",
      "Episode Count:  1128 \t Cumulative Reward:  19.21 \t eps:  0.323\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 2.0706\n",
      "Episode Count:  1129 \t Cumulative Reward:  51.07 \t eps:  0.323\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 2.1166\n",
      "Episode Count:  1130 \t Cumulative Reward:  67.83 \t eps:  0.323\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.8802\n",
      "Episode Count:  1131 \t Cumulative Reward:  104.74 \t eps:  0.322\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.7008\n",
      "Episode Count:  1132 \t Cumulative Reward:  31.05 \t eps:  0.322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 173ms/step - loss: 1.8686\n",
      "Episode Count:  1133 \t Cumulative Reward:  23.99 \t eps:  0.322\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.7851\n",
      "Episode Count:  1134 \t Cumulative Reward:  25.58 \t eps:  0.321\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 1.5653\n",
      "Episode Count:  1135 \t Cumulative Reward:  35.32 \t eps:  0.321\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 1.8365\n",
      "Episode Count:  1136 \t Cumulative Reward:  23.63 \t eps:  0.321\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.9974\n",
      "Episode Count:  1137 \t Cumulative Reward:  43.05 \t eps:  0.32\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.8253\n",
      "Episode Count:  1138 \t Cumulative Reward:  13.68 \t eps:  0.32\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 1.6919\n",
      "Episode Count:  1139 \t Cumulative Reward:  13.21 \t eps:  0.32\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 1.4918\n",
      "Episode Count:  1140 \t Cumulative Reward:  34.6 \t eps:  0.319\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.6572\n",
      "Episode Count:  1141 \t Cumulative Reward:  21.8 \t eps:  0.319\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 1.7361\n",
      "Episode Count:  1142 \t Cumulative Reward:  81.13 \t eps:  0.319\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 1.6426\n",
      "Episode Count:  1143 \t Cumulative Reward:  15.86 \t eps:  0.318\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.5902\n",
      "Episode Count:  1144 \t Cumulative Reward:  10.48 \t eps:  0.318\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 1.4063\n",
      "Episode Count:  1145 \t Cumulative Reward:  59.6 \t eps:  0.318\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 1.8066\n",
      "Episode Count:  1146 \t Cumulative Reward:  41.09 \t eps:  0.317\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 1.4302\n",
      "Episode Count:  1147 \t Cumulative Reward:  18.47 \t eps:  0.317\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 1.9722\n",
      "Episode Count:  1148 \t Cumulative Reward:  45.92 \t eps:  0.317\n",
      "16/16 [==============================] - 2s 125ms/step - loss: 1.8337\n",
      "Episode Count:  1149 \t Cumulative Reward:  38.35 \t eps:  0.316\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 1.7312\n",
      "Episode Count:  1150 \t Cumulative Reward:  86.39 \t eps:  0.316\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 1.7335\n",
      "Episode Count:  1151 \t Cumulative Reward:  21.22 \t eps:  0.316\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 1.7040\n",
      "Episode Count:  1152 \t Cumulative Reward:  26.85 \t eps:  0.316\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 2.0371\n",
      "Episode Count:  1153 \t Cumulative Reward:  26.59 \t eps:  0.315\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 1.8234\n",
      "Episode Count:  1154 \t Cumulative Reward:  33.15 \t eps:  0.315\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 1.8644\n",
      "Episode Count:  1155 \t Cumulative Reward:  28.58 \t eps:  0.315\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 3.1621\n",
      "Episode Count:  1156 \t Cumulative Reward:  23.61 \t eps:  0.314\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.1565\n",
      "Episode Count:  1157 \t Cumulative Reward:  96.51 \t eps:  0.314\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 2.1560\n",
      "Episode Count:  1158 \t Cumulative Reward:  12.41 \t eps:  0.314\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.8492\n",
      "Episode Count:  1159 \t Cumulative Reward:  23.41 \t eps:  0.313\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 1.6499\n",
      "Episode Count:  1160 \t Cumulative Reward:  29.95 \t eps:  0.313\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 2.0186\n",
      "Episode Count:  1161 \t Cumulative Reward:  7.66 \t eps:  0.313\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.8830\n",
      "Episode Count:  1162 \t Cumulative Reward:  25.37 \t eps:  0.312\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 1.7960\n",
      "Episode Count:  1163 \t Cumulative Reward:  22.11 \t eps:  0.312\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.6040\n",
      "Episode Count:  1164 \t Cumulative Reward:  21.23 \t eps:  0.312\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.9955\n",
      "Episode Count:  1165 \t Cumulative Reward:  62.35 \t eps:  0.311\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 2.0267\n",
      "Episode Count:  1166 \t Cumulative Reward:  -18.73 \t eps:  0.311\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.8945\n",
      "Episode Count:  1167 \t Cumulative Reward:  52.61 \t eps:  0.311\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 1.7854\n",
      "Episode Count:  1168 \t Cumulative Reward:  46.61 \t eps:  0.31\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 2.1588\n",
      "Episode Count:  1169 \t Cumulative Reward:  26.89 \t eps:  0.31\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.3214\n",
      "Episode Count:  1170 \t Cumulative Reward:  16.19 \t eps:  0.31\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 2.0621\n",
      "Episode Count:  1171 \t Cumulative Reward:  38.26 \t eps:  0.31\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 2.1086\n",
      "Episode Count:  1172 \t Cumulative Reward:  55.59 \t eps:  0.309\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.2612\n",
      "Episode Count:  1173 \t Cumulative Reward:  32.19 \t eps:  0.309\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 1.9515\n",
      "Episode Count:  1174 \t Cumulative Reward:  32.41 \t eps:  0.309\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.8576\n",
      "Episode Count:  1175 \t Cumulative Reward:  14.01 \t eps:  0.308\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7751\n",
      "Episode Count:  1176 \t Cumulative Reward:  46.59 \t eps:  0.308\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 1.8863\n",
      "Episode Count:  1177 \t Cumulative Reward:  33.18 \t eps:  0.308\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 2.1130\n",
      "Episode Count:  1178 \t Cumulative Reward:  120.91 \t eps:  0.307\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 1.7491\n",
      "Episode Count:  1179 \t Cumulative Reward:  22.32 \t eps:  0.307\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.0148\n",
      "Episode Count:  1180 \t Cumulative Reward:  40.6 \t eps:  0.307\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.8867\n",
      "Episode Count:  1181 \t Cumulative Reward:  4.95 \t eps:  0.306\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.0360\n",
      "Episode Count:  1182 \t Cumulative Reward:  7.1 \t eps:  0.306\n",
      "16/16 [==============================] - 2s 101ms/step - loss: 1.6872\n",
      "Episode Count:  1183 \t Cumulative Reward:  30.8 \t eps:  0.306\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 2.0031\n",
      "Episode Count:  1184 \t Cumulative Reward:  22.8 \t eps:  0.306\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 2.0706\n",
      "Episode Count:  1185 \t Cumulative Reward:  31.82 \t eps:  0.305\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 1.7210\n",
      "Episode Count:  1186 \t Cumulative Reward:  24.49 \t eps:  0.305\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 1.8221\n",
      "Episode Count:  1187 \t Cumulative Reward:  35.65 \t eps:  0.305\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.7115\n",
      "Episode Count:  1188 \t Cumulative Reward:  6.68 \t eps:  0.304\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 1.6666\n",
      "Episode Count:  1189 \t Cumulative Reward:  64.25 \t eps:  0.304\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 1.7199\n",
      "Episode Count:  1190 \t Cumulative Reward:  23.18 \t eps:  0.304\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.0830\n",
      "Episode Count:  1191 \t Cumulative Reward:  37.68 \t eps:  0.303\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 1.9178\n",
      "Episode Count:  1192 \t Cumulative Reward:  45.62 \t eps:  0.303\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 1.7281\n",
      "Episode Count:  1193 \t Cumulative Reward:  39.92 \t eps:  0.303\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 1.9069\n",
      "Episode Count:  1194 \t Cumulative Reward:  20.95 \t eps:  0.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 161ms/step - loss: 1.8777\n",
      "Episode Count:  1195 \t Cumulative Reward:  19.76 \t eps:  0.302\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 1.7914\n",
      "Episode Count:  1196 \t Cumulative Reward:  34.2 \t eps:  0.302\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 1.7781\n",
      "Episode Count:  1197 \t Cumulative Reward:  38.66 \t eps:  0.302\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 1.9868\n",
      "Episode Count:  1198 \t Cumulative Reward:  88.57 \t eps:  0.301\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 1.9219\n",
      "Episode Count:  1199 \t Cumulative Reward:  14.74 \t eps:  0.301\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 3.0772\n",
      "run 0: cumulative_reward: 56.71, ran for: 27 timesteps\n",
      "run 1: cumulative_reward: 28.02, ran for: 9 timesteps\n",
      "run 2: cumulative_reward: 26.92, ran for: 18 timesteps\n",
      "run 3: cumulative_reward: 35.25, ran for: 8 timesteps\n",
      "run 4: cumulative_reward: 19.41, ran for: 14 timesteps\n",
      "average performance:  33.262\n",
      "Episode Count:  1200 \t Cumulative Reward:  60.53 \t eps:  0.301\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 2.5469\n",
      "Episode Count:  1201 \t Cumulative Reward:  29.81 \t eps:  0.3\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.4928\n",
      "Episode Count:  1202 \t Cumulative Reward:  18.03 \t eps:  0.3\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 2.5599\n",
      "Episode Count:  1203 \t Cumulative Reward:  90.1 \t eps:  0.3\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 2.3135\n",
      "Episode Count:  1204 \t Cumulative Reward:  44.49 \t eps:  0.3\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 2.0509\n",
      "Episode Count:  1205 \t Cumulative Reward:  37.14 \t eps:  0.299\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 2.0091\n",
      "Episode Count:  1206 \t Cumulative Reward:  36.9 \t eps:  0.299\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.4704\n",
      "Episode Count:  1207 \t Cumulative Reward:  40.01 \t eps:  0.299\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.4345\n",
      "Episode Count:  1208 \t Cumulative Reward:  18.72 \t eps:  0.298\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.4019\n",
      "Episode Count:  1209 \t Cumulative Reward:  26.72 \t eps:  0.298\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 2.2627\n",
      "Episode Count:  1210 \t Cumulative Reward:  40.9 \t eps:  0.298\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 2.2647\n",
      "Episode Count:  1211 \t Cumulative Reward:  34.22 \t eps:  0.297\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 2.4223\n",
      "Episode Count:  1212 \t Cumulative Reward:  23.29 \t eps:  0.297\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 2.5051\n",
      "Episode Count:  1213 \t Cumulative Reward:  23.2 \t eps:  0.297\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 2.2463\n",
      "Episode Count:  1214 \t Cumulative Reward:  26.62 \t eps:  0.297\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4018\n",
      "Episode Count:  1215 \t Cumulative Reward:  28.2 \t eps:  0.296\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.0816\n",
      "Episode Count:  1216 \t Cumulative Reward:  28.61 \t eps:  0.296\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 2.0754\n",
      "Episode Count:  1217 \t Cumulative Reward:  34.92 \t eps:  0.296\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 2.3703\n",
      "Episode Count:  1218 \t Cumulative Reward:  69.48 \t eps:  0.295\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.1677\n",
      "Episode Count:  1219 \t Cumulative Reward:  26.43 \t eps:  0.295\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.8436\n",
      "Episode Count:  1220 \t Cumulative Reward:  12.93 \t eps:  0.295\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.9806\n",
      "Episode Count:  1221 \t Cumulative Reward:  61.07 \t eps:  0.294\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.8843\n",
      "Episode Count:  1222 \t Cumulative Reward:  29.51 \t eps:  0.294\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.0527\n",
      "Episode Count:  1223 \t Cumulative Reward:  58.55 \t eps:  0.294\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.0918\n",
      "Episode Count:  1224 \t Cumulative Reward:  11.97 \t eps:  0.294\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.0925\n",
      "Episode Count:  1225 \t Cumulative Reward:  18.03 \t eps:  0.293\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.2362\n",
      "Episode Count:  1226 \t Cumulative Reward:  25.96 \t eps:  0.293\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 2.2085\n",
      "Episode Count:  1227 \t Cumulative Reward:  52.59 \t eps:  0.293\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.1117\n",
      "Episode Count:  1228 \t Cumulative Reward:  24.02 \t eps:  0.292\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8254\n",
      "Episode Count:  1229 \t Cumulative Reward:  14.47 \t eps:  0.292\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 1.7553\n",
      "Episode Count:  1230 \t Cumulative Reward:  27.36 \t eps:  0.292\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 2.1909\n",
      "Episode Count:  1231 \t Cumulative Reward:  59.37 \t eps:  0.292\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.8769\n",
      "Episode Count:  1232 \t Cumulative Reward:  74.58 \t eps:  0.291\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 2.0629\n",
      "Episode Count:  1233 \t Cumulative Reward:  42.03 \t eps:  0.291\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.8153\n",
      "Episode Count:  1234 \t Cumulative Reward:  43.41 \t eps:  0.291\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 1.7410\n",
      "Episode Count:  1235 \t Cumulative Reward:  19.25 \t eps:  0.29\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 1.8415\n",
      "Episode Count:  1236 \t Cumulative Reward:  44.13 \t eps:  0.29\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 2.0364\n",
      "Episode Count:  1237 \t Cumulative Reward:  3.69 \t eps:  0.29\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.1282\n",
      "Episode Count:  1238 \t Cumulative Reward:  26.13 \t eps:  0.289\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.9254\n",
      "Episode Count:  1239 \t Cumulative Reward:  21.56 \t eps:  0.289\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.0143\n",
      "Episode Count:  1240 \t Cumulative Reward:  -0.4 \t eps:  0.289\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0416\n",
      "Episode Count:  1241 \t Cumulative Reward:  18.5 \t eps:  0.289\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.0055\n",
      "Episode Count:  1242 \t Cumulative Reward:  18.9 \t eps:  0.288\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 2.0593\n",
      "Episode Count:  1243 \t Cumulative Reward:  117.88 \t eps:  0.288\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 1.6148\n",
      "Episode Count:  1244 \t Cumulative Reward:  18.73 \t eps:  0.288\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.0301\n",
      "Episode Count:  1245 \t Cumulative Reward:  65.63 \t eps:  0.287\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.8674\n",
      "Episode Count:  1246 \t Cumulative Reward:  52.06 \t eps:  0.287\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.7099\n",
      "Episode Count:  1247 \t Cumulative Reward:  14.41 \t eps:  0.287\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 1.8749\n",
      "Episode Count:  1248 \t Cumulative Reward:  22.35 \t eps:  0.287\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 1.7785\n",
      "Episode Count:  1249 \t Cumulative Reward:  5.17 \t eps:  0.286\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.5711\n",
      "Episode Count:  1250 \t Cumulative Reward:  32.8 \t eps:  0.286\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 1.9609\n",
      "Episode Count:  1251 \t Cumulative Reward:  25.39 \t eps:  0.286\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 1.7408\n",
      "Episode Count:  1252 \t Cumulative Reward:  33.74 \t eps:  0.285\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.0382\n",
      "Episode Count:  1253 \t Cumulative Reward:  21.29 \t eps:  0.285\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.6451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Count:  1254 \t Cumulative Reward:  33.92 \t eps:  0.285\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.0087\n",
      "Episode Count:  1255 \t Cumulative Reward:  16.91 \t eps:  0.285\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.8684\n",
      "Episode Count:  1256 \t Cumulative Reward:  55.18 \t eps:  0.284\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.7975\n",
      "Episode Count:  1257 \t Cumulative Reward:  30.87 \t eps:  0.284\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.9207\n",
      "Episode Count:  1258 \t Cumulative Reward:  56.21 \t eps:  0.284\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 1.8348\n",
      "Episode Count:  1259 \t Cumulative Reward:  21.28 \t eps:  0.283\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 1.9489\n",
      "Episode Count:  1260 \t Cumulative Reward:  26.54 \t eps:  0.283\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 1.7725\n",
      "Episode Count:  1261 \t Cumulative Reward:  12.09 \t eps:  0.283\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 1.8339\n",
      "Episode Count:  1262 \t Cumulative Reward:  42.6 \t eps:  0.283\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.0445\n",
      "Episode Count:  1263 \t Cumulative Reward:  22.64 \t eps:  0.282\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 2.0703\n",
      "Episode Count:  1264 \t Cumulative Reward:  35.92 \t eps:  0.282\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.0645\n",
      "Episode Count:  1265 \t Cumulative Reward:  96.72 \t eps:  0.282\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.7259\n",
      "Episode Count:  1266 \t Cumulative Reward:  14.15 \t eps:  0.281\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.8018\n",
      "Episode Count:  1267 \t Cumulative Reward:  16.31 \t eps:  0.281\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.2335\n",
      "Episode Count:  1268 \t Cumulative Reward:  9.12 \t eps:  0.281\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 1.7924\n",
      "Episode Count:  1269 \t Cumulative Reward:  64.71 \t eps:  0.281\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 1.9158\n",
      "Episode Count:  1270 \t Cumulative Reward:  41.89 \t eps:  0.28\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.8016\n",
      "Episode Count:  1271 \t Cumulative Reward:  105.21 \t eps:  0.28\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.1100\n",
      "Episode Count:  1272 \t Cumulative Reward:  16.14 \t eps:  0.28\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.0614\n",
      "Episode Count:  1273 \t Cumulative Reward:  39.5 \t eps:  0.28\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.8786\n",
      "Episode Count:  1274 \t Cumulative Reward:  36.03 \t eps:  0.279\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.7984\n",
      "Episode Count:  1275 \t Cumulative Reward:  37.21 \t eps:  0.279\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.0397\n",
      "Episode Count:  1276 \t Cumulative Reward:  11.02 \t eps:  0.279\n",
      "16/16 [==============================] - 2s 154ms/step - loss: 1.8067\n",
      "Episode Count:  1277 \t Cumulative Reward:  8.08 \t eps:  0.278\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.0413\n",
      "Episode Count:  1278 \t Cumulative Reward:  41.77 \t eps:  0.278\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 1.9192\n",
      "Episode Count:  1279 \t Cumulative Reward:  72.92 \t eps:  0.278\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.0066\n",
      "Episode Count:  1280 \t Cumulative Reward:  25.76 \t eps:  0.278\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 1.6537\n",
      "Episode Count:  1281 \t Cumulative Reward:  29.06 \t eps:  0.277\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 1.7715\n",
      "Episode Count:  1282 \t Cumulative Reward:  79.31 \t eps:  0.277\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.1513\n",
      "Episode Count:  1283 \t Cumulative Reward:  -0.01 \t eps:  0.277\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 2.5205\n",
      "Episode Count:  1284 \t Cumulative Reward:  18.46 \t eps:  0.276\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 1.9370\n",
      "Episode Count:  1285 \t Cumulative Reward:  0.6 \t eps:  0.276\n",
      "16/16 [==============================] - 2s 156ms/step - loss: 1.9236\n",
      "Episode Count:  1286 \t Cumulative Reward:  26.18 \t eps:  0.276\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 1.9956\n",
      "Episode Count:  1287 \t Cumulative Reward:  43.17 \t eps:  0.276\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 1.5567\n",
      "Episode Count:  1288 \t Cumulative Reward:  37.01 \t eps:  0.275\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 1.9867\n",
      "Episode Count:  1289 \t Cumulative Reward:  73.81 \t eps:  0.275\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 1.8394\n",
      "Episode Count:  1290 \t Cumulative Reward:  81.87 \t eps:  0.275\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.0726\n",
      "Episode Count:  1291 \t Cumulative Reward:  9.71 \t eps:  0.275\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.8992\n",
      "Episode Count:  1292 \t Cumulative Reward:  61.15 \t eps:  0.274\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.1280\n",
      "Episode Count:  1293 \t Cumulative Reward:  19.34 \t eps:  0.274\n",
      "16/16 [==============================] - 2s 155ms/step - loss: 1.9088\n",
      "Episode Count:  1294 \t Cumulative Reward:  27.05 \t eps:  0.274\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 1.8563\n",
      "Episode Count:  1295 \t Cumulative Reward:  28.96 \t eps:  0.273\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 1.7280\n",
      "Episode Count:  1296 \t Cumulative Reward:  41.09 \t eps:  0.273\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 1.6409\n",
      "Episode Count:  1297 \t Cumulative Reward:  86.98 \t eps:  0.273\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.6442\n",
      "Episode Count:  1298 \t Cumulative Reward:  31.2 \t eps:  0.273\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.8011\n",
      "Episode Count:  1299 \t Cumulative Reward:  21.74 \t eps:  0.272\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 3.2925\n",
      "Episode Count:  1300 \t Cumulative Reward:  49.9 \t eps:  0.272\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 3.5376\n",
      "Episode Count:  1301 \t Cumulative Reward:  57.28 \t eps:  0.272\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 3.2397\n",
      "Episode Count:  1302 \t Cumulative Reward:  25.26 \t eps:  0.272\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 3.2235\n",
      "Episode Count:  1303 \t Cumulative Reward:  28.69 \t eps:  0.271\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.9321\n",
      "Episode Count:  1304 \t Cumulative Reward:  51.32 \t eps:  0.271\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 2.6412\n",
      "Episode Count:  1305 \t Cumulative Reward:  21.23 \t eps:  0.271\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 3.0625\n",
      "Episode Count:  1306 \t Cumulative Reward:  49.72 \t eps:  0.27\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 3.2069\n",
      "Episode Count:  1307 \t Cumulative Reward:  21.53 \t eps:  0.27\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.7805\n",
      "Episode Count:  1308 \t Cumulative Reward:  21.5 \t eps:  0.27\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 2.7237\n",
      "Episode Count:  1309 \t Cumulative Reward:  46.29 \t eps:  0.27\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 3.1428\n",
      "Episode Count:  1310 \t Cumulative Reward:  22.3 \t eps:  0.269\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.5702\n",
      "Episode Count:  1311 \t Cumulative Reward:  30.26 \t eps:  0.269\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.7839\n",
      "Episode Count:  1312 \t Cumulative Reward:  80.38 \t eps:  0.269\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.6342\n",
      "Episode Count:  1313 \t Cumulative Reward:  8.88 \t eps:  0.269\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.4484\n",
      "Episode Count:  1314 \t Cumulative Reward:  10.7 \t eps:  0.268\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.8476\n",
      "Episode Count:  1315 \t Cumulative Reward:  92.32 \t eps:  0.268\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.4804\n",
      "Episode Count:  1316 \t Cumulative Reward:  92.84 \t eps:  0.268\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 2.4060\n",
      "Episode Count:  1317 \t Cumulative Reward:  105.07 \t eps:  0.267\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 2.7232\n",
      "Episode Count:  1318 \t Cumulative Reward:  47.82 \t eps:  0.267\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.5686\n",
      "Episode Count:  1319 \t Cumulative Reward:  25.25 \t eps:  0.267\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 2.2251\n",
      "Episode Count:  1320 \t Cumulative Reward:  6.49 \t eps:  0.267\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 2.3272\n",
      "Episode Count:  1321 \t Cumulative Reward:  47.91 \t eps:  0.266\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.4048\n",
      "Episode Count:  1322 \t Cumulative Reward:  75.29 \t eps:  0.266\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.6262\n",
      "Episode Count:  1323 \t Cumulative Reward:  29.09 \t eps:  0.266\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.8018\n",
      "Episode Count:  1324 \t Cumulative Reward:  34.72 \t eps:  0.266\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.6779\n",
      "Episode Count:  1325 \t Cumulative Reward:  21.14 \t eps:  0.265\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.4552\n",
      "Episode Count:  1326 \t Cumulative Reward:  27.41 \t eps:  0.265\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.6050\n",
      "Episode Count:  1327 \t Cumulative Reward:  35.27 \t eps:  0.265\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.3063\n",
      "Episode Count:  1328 \t Cumulative Reward:  30.32 \t eps:  0.265\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.6600\n",
      "Episode Count:  1329 \t Cumulative Reward:  45.79 \t eps:  0.264\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 2.3101\n",
      "Episode Count:  1330 \t Cumulative Reward:  21.29 \t eps:  0.264\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.6973\n",
      "Episode Count:  1331 \t Cumulative Reward:  34.43 \t eps:  0.264\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.4488\n",
      "Episode Count:  1332 \t Cumulative Reward:  57.22 \t eps:  0.264\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 2.4641\n",
      "Episode Count:  1333 \t Cumulative Reward:  18.35 \t eps:  0.263\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.2601\n",
      "Episode Count:  1334 \t Cumulative Reward:  24.41 \t eps:  0.263\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.3858\n",
      "Episode Count:  1335 \t Cumulative Reward:  28.99 \t eps:  0.263\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.3427\n",
      "Episode Count:  1336 \t Cumulative Reward:  56.07 \t eps:  0.262\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 2.3863\n",
      "Episode Count:  1337 \t Cumulative Reward:  6.14 \t eps:  0.262\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.3169\n",
      "Episode Count:  1338 \t Cumulative Reward:  59.0 \t eps:  0.262\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.4607\n",
      "Episode Count:  1339 \t Cumulative Reward:  65.8 \t eps:  0.262\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 2.6504\n",
      "Episode Count:  1340 \t Cumulative Reward:  27.26 \t eps:  0.261\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.3140\n",
      "Episode Count:  1341 \t Cumulative Reward:  20.74 \t eps:  0.261\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 2.3039\n",
      "Episode Count:  1342 \t Cumulative Reward:  49.6 \t eps:  0.261\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.5440\n",
      "Episode Count:  1343 \t Cumulative Reward:  15.34 \t eps:  0.261\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.1070\n",
      "Episode Count:  1344 \t Cumulative Reward:  30.05 \t eps:  0.26\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.2984\n",
      "Episode Count:  1345 \t Cumulative Reward:  27.12 \t eps:  0.26\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.6137\n",
      "Episode Count:  1346 \t Cumulative Reward:  12.24 \t eps:  0.26\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.5441\n",
      "Episode Count:  1347 \t Cumulative Reward:  11.81 \t eps:  0.26\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.0143\n",
      "Episode Count:  1348 \t Cumulative Reward:  22.71 \t eps:  0.259\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.6512\n",
      "Episode Count:  1349 \t Cumulative Reward:  49.01 \t eps:  0.259\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.6357\n",
      "Episode Count:  1350 \t Cumulative Reward:  37.6 \t eps:  0.259\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 2.3432\n",
      "Episode Count:  1351 \t Cumulative Reward:  31.86 \t eps:  0.259\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 2.5566\n",
      "Episode Count:  1352 \t Cumulative Reward:  13.29 \t eps:  0.258\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.4795\n",
      "Episode Count:  1353 \t Cumulative Reward:  50.34 \t eps:  0.258\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.7308\n",
      "Episode Count:  1354 \t Cumulative Reward:  43.27 \t eps:  0.258\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.4447\n",
      "Episode Count:  1355 \t Cumulative Reward:  13.24 \t eps:  0.258\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.8022\n",
      "Episode Count:  1356 \t Cumulative Reward:  15.53 \t eps:  0.257\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 2.1372\n",
      "Episode Count:  1357 \t Cumulative Reward:  11.03 \t eps:  0.257\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 2.7670\n",
      "Episode Count:  1358 \t Cumulative Reward:  18.47 \t eps:  0.257\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 2.4601\n",
      "Episode Count:  1359 \t Cumulative Reward:  27.77 \t eps:  0.256\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.3119\n",
      "Episode Count:  1360 \t Cumulative Reward:  46.53 \t eps:  0.256\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 2.2611\n",
      "Episode Count:  1361 \t Cumulative Reward:  15.56 \t eps:  0.256\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.1300\n",
      "Episode Count:  1362 \t Cumulative Reward:  31.01 \t eps:  0.256\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 2.4696\n",
      "Episode Count:  1363 \t Cumulative Reward:  24.77 \t eps:  0.255\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.2312\n",
      "Episode Count:  1364 \t Cumulative Reward:  59.39 \t eps:  0.255\n",
      "16/16 [==============================] - 2s 125ms/step - loss: 2.8882\n",
      "Episode Count:  1365 \t Cumulative Reward:  35.55 \t eps:  0.255\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.6121\n",
      "Episode Count:  1366 \t Cumulative Reward:  15.62 \t eps:  0.255\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.1668\n",
      "Episode Count:  1367 \t Cumulative Reward:  26.52 \t eps:  0.254\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 2.5703\n",
      "Episode Count:  1368 \t Cumulative Reward:  30.67 \t eps:  0.254\n",
      "16/16 [==============================] - 2s 129ms/step - loss: 2.2190\n",
      "Episode Count:  1369 \t Cumulative Reward:  38.54 \t eps:  0.254\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 2.4165\n",
      "Episode Count:  1370 \t Cumulative Reward:  54.75 \t eps:  0.254\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.1400\n",
      "Episode Count:  1371 \t Cumulative Reward:  41.94 \t eps:  0.253\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.3165\n",
      "Episode Count:  1372 \t Cumulative Reward:  7.1 \t eps:  0.253\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 2.2997\n",
      "Episode Count:  1373 \t Cumulative Reward:  32.99 \t eps:  0.253\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 1.9949\n",
      "Episode Count:  1374 \t Cumulative Reward:  13.02 \t eps:  0.253\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.2212\n",
      "Episode Count:  1375 \t Cumulative Reward:  33.65 \t eps:  0.252\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.2259\n",
      "Episode Count:  1376 \t Cumulative Reward:  14.04 \t eps:  0.252\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.1458\n",
      "Episode Count:  1377 \t Cumulative Reward:  32.45 \t eps:  0.252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 122ms/step - loss: 2.1146\n",
      "Episode Count:  1378 \t Cumulative Reward:  45.11 \t eps:  0.252\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 2.2272\n",
      "Episode Count:  1379 \t Cumulative Reward:  21.51 \t eps:  0.251\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 2.5974\n",
      "Episode Count:  1380 \t Cumulative Reward:  45.24 \t eps:  0.251\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 1.9514\n",
      "Episode Count:  1381 \t Cumulative Reward:  25.73 \t eps:  0.251\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 1.9974\n",
      "Episode Count:  1382 \t Cumulative Reward:  46.58 \t eps:  0.251\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.1388\n",
      "Episode Count:  1383 \t Cumulative Reward:  62.11 \t eps:  0.25\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.3438\n",
      "Episode Count:  1384 \t Cumulative Reward:  36.63 \t eps:  0.25\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 2.3704\n",
      "Episode Count:  1385 \t Cumulative Reward:  28.95 \t eps:  0.25\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 2.2103\n",
      "Episode Count:  1386 \t Cumulative Reward:  5.52 \t eps:  0.25\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 2.3744\n",
      "Episode Count:  1387 \t Cumulative Reward:  11.92 \t eps:  0.249\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.2068\n",
      "Episode Count:  1388 \t Cumulative Reward:  47.2 \t eps:  0.249\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.4913\n",
      "Episode Count:  1389 \t Cumulative Reward:  15.34 \t eps:  0.249\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 2.6321\n",
      "Episode Count:  1390 \t Cumulative Reward:  27.62 \t eps:  0.249\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 2.4743\n",
      "Episode Count:  1391 \t Cumulative Reward:  34.8 \t eps:  0.248\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.2464\n",
      "Episode Count:  1392 \t Cumulative Reward:  22.78 \t eps:  0.248\n",
      "16/16 [==============================] - 2s 124ms/step - loss: 2.7375\n",
      "Episode Count:  1393 \t Cumulative Reward:  42.33 \t eps:  0.248\n",
      "16/16 [==============================] - 2s 123ms/step - loss: 2.5475\n",
      "Episode Count:  1394 \t Cumulative Reward:  18.13 \t eps:  0.248\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 2.4077\n",
      "Episode Count:  1395 \t Cumulative Reward:  18.39 \t eps:  0.247\n",
      "16/16 [==============================] - 2s 130ms/step - loss: 2.1332\n",
      "Episode Count:  1396 \t Cumulative Reward:  18.95 \t eps:  0.247\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.3682\n",
      "Episode Count:  1397 \t Cumulative Reward:  24.81 \t eps:  0.247\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 2.3856\n",
      "Episode Count:  1398 \t Cumulative Reward:  27.62 \t eps:  0.247\n",
      "16/16 [==============================] - 2s 131ms/step - loss: 2.1244\n",
      "Episode Count:  1399 \t Cumulative Reward:  47.45 \t eps:  0.246\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 3.3665\n",
      "run 0: cumulative_reward: 65.19, ran for: 12 timesteps\n",
      "run 1: cumulative_reward: 115.32, ran for: 39 timesteps\n",
      "run 2: cumulative_reward: 60.91, ran for: 19 timesteps\n",
      "run 3: cumulative_reward: 29.35, ran for: 18 timesteps\n",
      "run 4: cumulative_reward: 8.11, ran for: 5 timesteps\n",
      "average performance:  55.775999999999996\n",
      "Episode Count:  1400 \t Cumulative Reward:  23.0 \t eps:  0.246\n",
      "16/16 [==============================] - 2s 128ms/step - loss: 2.9962\n",
      "Episode Count:  1401 \t Cumulative Reward:  32.45 \t eps:  0.246\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.7075\n",
      "Episode Count:  1402 \t Cumulative Reward:  9.54 \t eps:  0.246\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 2.8574\n",
      "Episode Count:  1403 \t Cumulative Reward:  43.85 \t eps:  0.245\n",
      "16/16 [==============================] - 7s 452ms/step - loss: 2.5531\n",
      "Episode Count:  1404 \t Cumulative Reward:  11.15 \t eps:  0.245\n",
      "16/16 [==============================] - 7s 452ms/step - loss: 2.5688\n",
      "Episode Count:  1405 \t Cumulative Reward:  15.68 \t eps:  0.245\n",
      "16/16 [==============================] - 7s 449ms/step - loss: 2.7740\n",
      "Episode Count:  1406 \t Cumulative Reward:  25.68 \t eps:  0.245\n",
      "16/16 [==============================] - 7s 453ms/step - loss: 2.3555\n",
      "Episode Count:  1407 \t Cumulative Reward:  20.26 \t eps:  0.244\n",
      "16/16 [==============================] - 7s 462ms/step - loss: 2.7964\n",
      "Episode Count:  1408 \t Cumulative Reward:  17.7 \t eps:  0.244\n",
      "16/16 [==============================] - 7s 455ms/step - loss: 2.7252\n",
      "Episode Count:  1409 \t Cumulative Reward:  41.47 \t eps:  0.244\n",
      "16/16 [==============================] - 7s 457ms/step - loss: 2.4649\n",
      "Episode Count:  1410 \t Cumulative Reward:  21.33 \t eps:  0.244\n",
      "16/16 [==============================] - 7s 454ms/step - loss: 2.8928\n",
      "Episode Count:  1411 \t Cumulative Reward:  28.97 \t eps:  0.243\n",
      "16/16 [==============================] - 7s 467ms/step - loss: 2.6794\n",
      "Episode Count:  1412 \t Cumulative Reward:  21.75 \t eps:  0.243\n",
      "16/16 [==============================] - 8s 499ms/step - loss: 2.6486\n",
      "Episode Count:  1413 \t Cumulative Reward:  10.82 \t eps:  0.243\n",
      "16/16 [==============================] - 7s 455ms/step - loss: 2.6902\n",
      "Episode Count:  1414 \t Cumulative Reward:  35.68 \t eps:  0.243\n",
      "16/16 [==============================] - 7s 452ms/step - loss: 2.5844\n",
      "Episode Count:  1415 \t Cumulative Reward:  16.23 \t eps:  0.243\n",
      "16/16 [==============================] - 7s 446ms/step - loss: 2.3650\n",
      "Episode Count:  1416 \t Cumulative Reward:  21.05 \t eps:  0.242\n",
      "16/16 [==============================] - 7s 456ms/step - loss: 2.8268\n",
      "Episode Count:  1417 \t Cumulative Reward:  8.94 \t eps:  0.242\n",
      "16/16 [==============================] - 7s 457ms/step - loss: 3.0413\n",
      "Episode Count:  1418 \t Cumulative Reward:  8.49 \t eps:  0.242\n",
      "16/16 [==============================] - 7s 453ms/step - loss: 1.9845\n",
      "Episode Count:  1419 \t Cumulative Reward:  16.21 \t eps:  0.242\n",
      "16/16 [==============================] - 7s 448ms/step - loss: 2.4627\n",
      "Episode Count:  1420 \t Cumulative Reward:  0.69 \t eps:  0.241\n",
      "16/16 [==============================] - 7s 443ms/step - loss: 2.4665\n",
      "Episode Count:  1421 \t Cumulative Reward:  23.46 \t eps:  0.241\n",
      "16/16 [==============================] - 7s 443ms/step - loss: 2.3348\n",
      "Episode Count:  1422 \t Cumulative Reward:  -1.28 \t eps:  0.241\n",
      "16/16 [==============================] - 7s 438ms/step - loss: 2.6329\n",
      "Episode Count:  1423 \t Cumulative Reward:  6.06 \t eps:  0.241\n",
      "16/16 [==============================] - 7s 441ms/step - loss: 2.2125\n",
      "Episode Count:  1424 \t Cumulative Reward:  12.38 \t eps:  0.24\n",
      "16/16 [==============================] - 7s 440ms/step - loss: 2.2453\n",
      "Episode Count:  1425 \t Cumulative Reward:  19.75 \t eps:  0.24\n",
      "16/16 [==============================] - 7s 442ms/step - loss: 2.0702\n",
      "Episode Count:  1426 \t Cumulative Reward:  22.65 \t eps:  0.24\n",
      "16/16 [==============================] - 7s 438ms/step - loss: 2.2158\n",
      "Episode Count:  1427 \t Cumulative Reward:  31.48 \t eps:  0.24\n",
      "16/16 [==============================] - 7s 439ms/step - loss: 2.5098\n",
      "Episode Count:  1428 \t Cumulative Reward:  35.96 \t eps:  0.239\n",
      "16/16 [==============================] - 7s 439ms/step - loss: 2.5272\n",
      "Episode Count:  1429 \t Cumulative Reward:  17.0 \t eps:  0.239\n",
      "16/16 [==============================] - 7s 426ms/step - loss: 2.2333\n",
      "Episode Count:  1430 \t Cumulative Reward:  31.24 \t eps:  0.239\n",
      "16/16 [==============================] - 7s 426ms/step - loss: 2.1070\n",
      "Episode Count:  1431 \t Cumulative Reward:  9.76 \t eps:  0.239\n",
      "16/16 [==============================] - 7s 428ms/step - loss: 2.0174\n",
      "Episode Count:  1432 \t Cumulative Reward:  15.89 \t eps:  0.238\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.2420\n",
      "Episode Count:  1433 \t Cumulative Reward:  17.6 \t eps:  0.238\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 2.3079\n",
      "Episode Count:  1434 \t Cumulative Reward:  23.95 \t eps:  0.238\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 2.4604\n",
      "Episode Count:  1435 \t Cumulative Reward:  25.12 \t eps:  0.238\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.1976\n",
      "Episode Count:  1436 \t Cumulative Reward:  16.6 \t eps:  0.237\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 2.3487\n",
      "Episode Count:  1437 \t Cumulative Reward:  -0.23 \t eps:  0.237\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.1797\n",
      "Episode Count:  1438 \t Cumulative Reward:  84.1 \t eps:  0.237\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.4722\n",
      "Episode Count:  1439 \t Cumulative Reward:  17.09 \t eps:  0.237\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.1959\n",
      "Episode Count:  1440 \t Cumulative Reward:  57.49 \t eps:  0.237\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.4647\n",
      "Episode Count:  1441 \t Cumulative Reward:  42.13 \t eps:  0.236\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.2426\n",
      "Episode Count:  1442 \t Cumulative Reward:  71.02 \t eps:  0.236\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.5031\n",
      "Episode Count:  1443 \t Cumulative Reward:  29.22 \t eps:  0.236\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.3706\n",
      "Episode Count:  1444 \t Cumulative Reward:  15.65 \t eps:  0.236\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.1892\n",
      "Episode Count:  1445 \t Cumulative Reward:  48.85 \t eps:  0.235\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.3534\n",
      "Episode Count:  1446 \t Cumulative Reward:  37.82 \t eps:  0.235\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.6752\n",
      "Episode Count:  1447 \t Cumulative Reward:  42.26 \t eps:  0.235\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.3697\n",
      "Episode Count:  1448 \t Cumulative Reward:  43.85 \t eps:  0.235\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.3414\n",
      "Episode Count:  1449 \t Cumulative Reward:  21.1 \t eps:  0.234\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.3449\n",
      "Episode Count:  1450 \t Cumulative Reward:  31.32 \t eps:  0.234\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.2363\n",
      "Episode Count:  1451 \t Cumulative Reward:  25.09 \t eps:  0.234\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.4185\n",
      "Episode Count:  1452 \t Cumulative Reward:  127.25 \t eps:  0.234\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.0774\n",
      "Episode Count:  1453 \t Cumulative Reward:  22.31 \t eps:  0.233\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.0220\n",
      "Episode Count:  1454 \t Cumulative Reward:  64.69 \t eps:  0.233\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.6289\n",
      "Episode Count:  1455 \t Cumulative Reward:  5.95 \t eps:  0.233\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.2234\n",
      "Episode Count:  1456 \t Cumulative Reward:  38.58 \t eps:  0.233\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.4064\n",
      "Episode Count:  1457 \t Cumulative Reward:  41.75 \t eps:  0.233\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 2.3695\n",
      "Episode Count:  1458 \t Cumulative Reward:  -129.6 \t eps:  0.232\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 3.0252\n",
      "Episode Count:  1459 \t Cumulative Reward:  58.51 \t eps:  0.232\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.5837\n",
      "Episode Count:  1460 \t Cumulative Reward:  33.42 \t eps:  0.232\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.0775\n",
      "Episode Count:  1461 \t Cumulative Reward:  23.83 \t eps:  0.232\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.3866\n",
      "Episode Count:  1462 \t Cumulative Reward:  35.01 \t eps:  0.231\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.2212\n",
      "Episode Count:  1463 \t Cumulative Reward:  17.29 \t eps:  0.231\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.3847\n",
      "Episode Count:  1464 \t Cumulative Reward:  25.04 \t eps:  0.231\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 2.6391\n",
      "Episode Count:  1465 \t Cumulative Reward:  39.58 \t eps:  0.231\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.7156\n",
      "Episode Count:  1466 \t Cumulative Reward:  59.06 \t eps:  0.23\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.6516: 0s \n",
      "Episode Count:  1467 \t Cumulative Reward:  16.27 \t eps:  0.23\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.3661\n",
      "Episode Count:  1468 \t Cumulative Reward:  46.12 \t eps:  0.23\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.6059\n",
      "Episode Count:  1469 \t Cumulative Reward:  54.55 \t eps:  0.23\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.8426\n",
      "Episode Count:  1470 \t Cumulative Reward:  62.98 \t eps:  0.23\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.6555\n",
      "Episode Count:  1471 \t Cumulative Reward:  78.45 \t eps:  0.229\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.5873\n",
      "Episode Count:  1472 \t Cumulative Reward:  14.15 \t eps:  0.229\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4339\n",
      "Episode Count:  1473 \t Cumulative Reward:  33.15 \t eps:  0.229\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4466\n",
      "Episode Count:  1474 \t Cumulative Reward:  22.47 \t eps:  0.229\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.1762\n",
      "Episode Count:  1475 \t Cumulative Reward:  10.6 \t eps:  0.228\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.1130\n",
      "Episode Count:  1476 \t Cumulative Reward:  110.63 \t eps:  0.228\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 2.5673\n",
      "Episode Count:  1477 \t Cumulative Reward:  60.55 \t eps:  0.228\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.4334\n",
      "Episode Count:  1478 \t Cumulative Reward:  57.7 \t eps:  0.228\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.5932\n",
      "Episode Count:  1479 \t Cumulative Reward:  22.03 \t eps:  0.227\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.6832\n",
      "Episode Count:  1480 \t Cumulative Reward:  3.42 \t eps:  0.227\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4554: 0s \n",
      "Episode Count:  1481 \t Cumulative Reward:  128.93 \t eps:  0.227\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.7786\n",
      "Episode Count:  1482 \t Cumulative Reward:  59.01 \t eps:  0.227\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 2.3260\n",
      "Episode Count:  1483 \t Cumulative Reward:  174.77 \t eps:  0.227\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 3.0111\n",
      "Episode Count:  1484 \t Cumulative Reward:  16.47 \t eps:  0.226\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 3.2473\n",
      "Episode Count:  1485 \t Cumulative Reward:  39.04 \t eps:  0.226\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.4523\n",
      "Episode Count:  1486 \t Cumulative Reward:  21.89 \t eps:  0.226\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.6620\n",
      "Episode Count:  1487 \t Cumulative Reward:  13.43 \t eps:  0.226\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.6476\n",
      "Episode Count:  1488 \t Cumulative Reward:  21.12 \t eps:  0.225\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.7401\n",
      "Episode Count:  1489 \t Cumulative Reward:  69.42 \t eps:  0.225\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 2.9069\n",
      "Episode Count:  1490 \t Cumulative Reward:  38.87 \t eps:  0.225\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.5510\n",
      "Episode Count:  1491 \t Cumulative Reward:  8.76 \t eps:  0.225\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.2083\n",
      "Episode Count:  1492 \t Cumulative Reward:  14.35 \t eps:  0.225\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.1354\n",
      "Episode Count:  1493 \t Cumulative Reward:  69.89 \t eps:  0.224\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.6977\n",
      "Episode Count:  1494 \t Cumulative Reward:  7.08 \t eps:  0.224\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.5113\n",
      "Episode Count:  1495 \t Cumulative Reward:  67.39 \t eps:  0.224\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.0274\n",
      "Episode Count:  1496 \t Cumulative Reward:  12.47 \t eps:  0.224\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.7745\n",
      "Episode Count:  1497 \t Cumulative Reward:  24.76 \t eps:  0.223\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.6376\n",
      "Episode Count:  1498 \t Cumulative Reward:  53.43 \t eps:  0.223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 73ms/step - loss: 3.1131\n",
      "Episode Count:  1499 \t Cumulative Reward:  -0.36 \t eps:  0.223\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.3892\n",
      "Episode Count:  1500 \t Cumulative Reward:  82.19 \t eps:  0.223\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6327\n",
      "Episode Count:  1501 \t Cumulative Reward:  24.72 \t eps:  0.223\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.5871\n",
      "Episode Count:  1502 \t Cumulative Reward:  25.51 \t eps:  0.222\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.7298\n",
      "Episode Count:  1503 \t Cumulative Reward:  45.24 \t eps:  0.222\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.5469\n",
      "Episode Count:  1504 \t Cumulative Reward:  23.62 \t eps:  0.222\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.2230\n",
      "Episode Count:  1505 \t Cumulative Reward:  141.29 \t eps:  0.222\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 3.8756\n",
      "Episode Count:  1506 \t Cumulative Reward:  103.72 \t eps:  0.221\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 3.3991\n",
      "Episode Count:  1507 \t Cumulative Reward:  22.89 \t eps:  0.221\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.2800\n",
      "Episode Count:  1508 \t Cumulative Reward:  38.0 \t eps:  0.221\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.0341\n",
      "Episode Count:  1509 \t Cumulative Reward:  41.02 \t eps:  0.221\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 3.1247\n",
      "Episode Count:  1510 \t Cumulative Reward:  38.59 \t eps:  0.221\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 3.4251\n",
      "Episode Count:  1511 \t Cumulative Reward:  3.47 \t eps:  0.22\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.8819\n",
      "Episode Count:  1512 \t Cumulative Reward:  35.77 \t eps:  0.22\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.4067\n",
      "Episode Count:  1513 \t Cumulative Reward:  85.43 \t eps:  0.22\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 3.1221\n",
      "Episode Count:  1514 \t Cumulative Reward:  23.58 \t eps:  0.22\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.9508\n",
      "Episode Count:  1515 \t Cumulative Reward:  21.2 \t eps:  0.219\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.7813\n",
      "Episode Count:  1516 \t Cumulative Reward:  22.64 \t eps:  0.219\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.0553\n",
      "Episode Count:  1517 \t Cumulative Reward:  34.43 \t eps:  0.219\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.8189\n",
      "Episode Count:  1518 \t Cumulative Reward:  18.85 \t eps:  0.219\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 3.3827\n",
      "Episode Count:  1519 \t Cumulative Reward:  19.34 \t eps:  0.219\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.3041\n",
      "Episode Count:  1520 \t Cumulative Reward:  164.6 \t eps:  0.218\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.7326\n",
      "Episode Count:  1521 \t Cumulative Reward:  30.94 \t eps:  0.218\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 3.2064\n",
      "Episode Count:  1522 \t Cumulative Reward:  53.1 \t eps:  0.218\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.2222\n",
      "Episode Count:  1523 \t Cumulative Reward:  104.57 \t eps:  0.218\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.5329\n",
      "Episode Count:  1524 \t Cumulative Reward:  43.68 \t eps:  0.217\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.9007\n",
      "Episode Count:  1525 \t Cumulative Reward:  24.44 \t eps:  0.217\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 3.0902\n",
      "Episode Count:  1526 \t Cumulative Reward:  15.45 \t eps:  0.217\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 3.2504\n",
      "Episode Count:  1527 \t Cumulative Reward:  95.01 \t eps:  0.217\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.1237\n",
      "Episode Count:  1528 \t Cumulative Reward:  24.51 \t eps:  0.217\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.3753\n",
      "Episode Count:  1529 \t Cumulative Reward:  65.87 \t eps:  0.216\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 3.4621\n",
      "Episode Count:  1530 \t Cumulative Reward:  34.08 \t eps:  0.216\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.9907\n",
      "Episode Count:  1531 \t Cumulative Reward:  53.94 \t eps:  0.216\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.8703\n",
      "Episode Count:  1532 \t Cumulative Reward:  21.82 \t eps:  0.216\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 2.6401: 0s - loss: 2\n",
      "Episode Count:  1533 \t Cumulative Reward:  33.01 \t eps:  0.216\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 3.1954\n",
      "Episode Count:  1534 \t Cumulative Reward:  50.27 \t eps:  0.215\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 3.0915\n",
      "Episode Count:  1535 \t Cumulative Reward:  42.4 \t eps:  0.215\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.1999\n",
      "Episode Count:  1536 \t Cumulative Reward:  67.01 \t eps:  0.215\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3545\n",
      "Episode Count:  1537 \t Cumulative Reward:  110.91 \t eps:  0.215\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 3.6726\n",
      "Episode Count:  1538 \t Cumulative Reward:  149.02 \t eps:  0.214\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.6220: 0s - loss: 3\n",
      "Episode Count:  1539 \t Cumulative Reward:  6.23 \t eps:  0.214\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5010\n",
      "Episode Count:  1540 \t Cumulative Reward:  124.05 \t eps:  0.214\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.4497\n",
      "Episode Count:  1541 \t Cumulative Reward:  57.08 \t eps:  0.214\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.1900\n",
      "Episode Count:  1542 \t Cumulative Reward:  41.52 \t eps:  0.214\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.9514\n",
      "Episode Count:  1543 \t Cumulative Reward:  18.87 \t eps:  0.213\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.3151\n",
      "Episode Count:  1544 \t Cumulative Reward:  165.75 \t eps:  0.213\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.5842\n",
      "Episode Count:  1545 \t Cumulative Reward:  23.91 \t eps:  0.213\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 3.4885\n",
      "Episode Count:  1546 \t Cumulative Reward:  8.92 \t eps:  0.213\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 2.9584\n",
      "Episode Count:  1547 \t Cumulative Reward:  38.61 \t eps:  0.213\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0838\n",
      "Episode Count:  1548 \t Cumulative Reward:  99.13 \t eps:  0.212\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.3019\n",
      "Episode Count:  1549 \t Cumulative Reward:  61.68 \t eps:  0.212\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 3.3582\n",
      "Episode Count:  1550 \t Cumulative Reward:  13.01 \t eps:  0.212\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.5939\n",
      "Episode Count:  1551 \t Cumulative Reward:  35.32 \t eps:  0.212\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.9510\n",
      "Episode Count:  1552 \t Cumulative Reward:  37.35 \t eps:  0.211\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 3.5676\n",
      "Episode Count:  1553 \t Cumulative Reward:  58.57 \t eps:  0.211\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 3.4145\n",
      "Episode Count:  1554 \t Cumulative Reward:  18.96 \t eps:  0.211\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 3.7386\n",
      "Episode Count:  1555 \t Cumulative Reward:  130.64 \t eps:  0.211\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 3.8954\n",
      "Episode Count:  1556 \t Cumulative Reward:  19.59 \t eps:  0.211\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 3.0658\n",
      "Episode Count:  1557 \t Cumulative Reward:  24.26 \t eps:  0.21\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4648\n",
      "Episode Count:  1558 \t Cumulative Reward:  33.46 \t eps:  0.21\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 3.2551\n",
      "Episode Count:  1559 \t Cumulative Reward:  28.3 \t eps:  0.21\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.3100\n",
      "Episode Count:  1560 \t Cumulative Reward:  9.21 \t eps:  0.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 74ms/step - loss: 3.1232\n",
      "Episode Count:  1561 \t Cumulative Reward:  2.27 \t eps:  0.21\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 3.1458\n",
      "Episode Count:  1562 \t Cumulative Reward:  17.53 \t eps:  0.209\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.8070\n",
      "Episode Count:  1563 \t Cumulative Reward:  139.14 \t eps:  0.209\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.9829\n",
      "Episode Count:  1564 \t Cumulative Reward:  32.42 \t eps:  0.209\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 3.0418\n",
      "Episode Count:  1565 \t Cumulative Reward:  28.92 \t eps:  0.209\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.8541\n",
      "Episode Count:  1566 \t Cumulative Reward:  50.41 \t eps:  0.209\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.9211\n",
      "Episode Count:  1567 \t Cumulative Reward:  51.94 \t eps:  0.208\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2825\n",
      "Episode Count:  1568 \t Cumulative Reward:  14.17 \t eps:  0.208\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.5678\n",
      "Episode Count:  1569 \t Cumulative Reward:  39.8 \t eps:  0.208\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 3.2766\n",
      "Episode Count:  1570 \t Cumulative Reward:  38.97 \t eps:  0.208\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.8532\n",
      "Episode Count:  1571 \t Cumulative Reward:  45.17 \t eps:  0.207\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 2.6889\n",
      "Episode Count:  1572 \t Cumulative Reward:  71.18 \t eps:  0.207\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.9639\n",
      "Episode Count:  1573 \t Cumulative Reward:  32.13 \t eps:  0.207\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 2.8364\n",
      "Episode Count:  1574 \t Cumulative Reward:  52.14 \t eps:  0.207\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 3.5372\n",
      "Episode Count:  1575 \t Cumulative Reward:  14.05 \t eps:  0.207\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.0088\n",
      "Episode Count:  1576 \t Cumulative Reward:  46.92 \t eps:  0.206\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 3.2529\n",
      "Episode Count:  1577 \t Cumulative Reward:  16.98 \t eps:  0.206\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 3.0606\n",
      "Episode Count:  1578 \t Cumulative Reward:  65.06 \t eps:  0.206\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.5569\n",
      "Episode Count:  1579 \t Cumulative Reward:  3.8 \t eps:  0.206\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.8349\n",
      "Episode Count:  1580 \t Cumulative Reward:  53.76 \t eps:  0.206\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.9006\n",
      "Episode Count:  1581 \t Cumulative Reward:  27.26 \t eps:  0.205\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.9114\n",
      "Episode Count:  1582 \t Cumulative Reward:  32.75 \t eps:  0.205\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.0633\n",
      "Episode Count:  1583 \t Cumulative Reward:  41.28 \t eps:  0.205\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 3.1200\n",
      "Episode Count:  1584 \t Cumulative Reward:  53.18 \t eps:  0.205\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.7529\n",
      "Episode Count:  1585 \t Cumulative Reward:  36.24 \t eps:  0.205\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.5592\n",
      "Episode Count:  1586 \t Cumulative Reward:  33.68 \t eps:  0.204\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.7718\n",
      "Episode Count:  1587 \t Cumulative Reward:  37.14 \t eps:  0.204\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 2.8794\n",
      "Episode Count:  1588 \t Cumulative Reward:  18.91 \t eps:  0.204\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.8675: 0s - lo\n",
      "Episode Count:  1589 \t Cumulative Reward:  19.03 \t eps:  0.204\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.1104\n",
      "Episode Count:  1590 \t Cumulative Reward:  28.67 \t eps:  0.204\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.2759\n",
      "Episode Count:  1591 \t Cumulative Reward:  32.73 \t eps:  0.203\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.0563\n",
      "Episode Count:  1592 \t Cumulative Reward:  147.28 \t eps:  0.203\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 3.2861\n",
      "Episode Count:  1593 \t Cumulative Reward:  39.81 \t eps:  0.203\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.1727\n",
      "Episode Count:  1594 \t Cumulative Reward:  148.97 \t eps:  0.203\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.9209\n",
      "Episode Count:  1595 \t Cumulative Reward:  46.08 \t eps:  0.203\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.7783\n",
      "Episode Count:  1596 \t Cumulative Reward:  60.02 \t eps:  0.202\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 3.2630\n",
      "Episode Count:  1597 \t Cumulative Reward:  29.02 \t eps:  0.202\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.9024: 0s \n",
      "Episode Count:  1598 \t Cumulative Reward:  61.97 \t eps:  0.202\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.6088: 0s - loss: 2.6\n",
      "Episode Count:  1599 \t Cumulative Reward:  83.1 \t eps:  0.202\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.2051\n",
      "run 0: cumulative_reward: 22.58, ran for: 17 timesteps\n",
      "run 1: cumulative_reward: 16.55, ran for: 8 timesteps\n",
      "run 2: cumulative_reward: 37.92, ran for: 19 timesteps\n",
      "run 3: cumulative_reward: 34.29, ran for: 16 timesteps\n",
      "run 4: cumulative_reward: 20.47, ran for: 11 timesteps\n",
      "average performance:  26.362000000000002\n",
      "Episode Count:  1600 \t Cumulative Reward:  39.6 \t eps:  0.202\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.1979\n",
      "Episode Count:  1601 \t Cumulative Reward:  15.06 \t eps:  0.201\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 2.8093\n",
      "Episode Count:  1602 \t Cumulative Reward:  3.83 \t eps:  0.201\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.6647\n",
      "Episode Count:  1603 \t Cumulative Reward:  22.79 \t eps:  0.201\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.7316\n",
      "Episode Count:  1604 \t Cumulative Reward:  64.14 \t eps:  0.201\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.8123\n",
      "Episode Count:  1605 \t Cumulative Reward:  45.41 \t eps:  0.201\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.7239\n",
      "Episode Count:  1606 \t Cumulative Reward:  5.12 \t eps:  0.2\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.6350\n",
      "Episode Count:  1607 \t Cumulative Reward:  47.15 \t eps:  0.2\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.9346\n",
      "Episode Count:  1608 \t Cumulative Reward:  8.9 \t eps:  0.2\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.3150\n",
      "Episode Count:  1609 \t Cumulative Reward:  22.18 \t eps:  0.2\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.4190\n",
      "Episode Count:  1610 \t Cumulative Reward:  21.55 \t eps:  0.2\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.1801\n",
      "Episode Count:  1611 \t Cumulative Reward:  30.76 \t eps:  0.199\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.6809\n",
      "Episode Count:  1612 \t Cumulative Reward:  74.77 \t eps:  0.199\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.4415\n",
      "Episode Count:  1613 \t Cumulative Reward:  73.67 \t eps:  0.199\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.8267\n",
      "Episode Count:  1614 \t Cumulative Reward:  70.27 \t eps:  0.199\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.5512\n",
      "Episode Count:  1615 \t Cumulative Reward:  20.9 \t eps:  0.199\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.6400\n",
      "Episode Count:  1616 \t Cumulative Reward:  154.76 \t eps:  0.198\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 2.3321\n",
      "Episode Count:  1617 \t Cumulative Reward:  43.62 \t eps:  0.198\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.2257\n",
      "Episode Count:  1618 \t Cumulative Reward:  58.61 \t eps:  0.198\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.5956\n",
      "Episode Count:  1619 \t Cumulative Reward:  12.98 \t eps:  0.198\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.5196\n",
      "Episode Count:  1620 \t Cumulative Reward:  65.47 \t eps:  0.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 74ms/step - loss: 2.5224\n",
      "Episode Count:  1621 \t Cumulative Reward:  56.13 \t eps:  0.197\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.2573\n",
      "Episode Count:  1622 \t Cumulative Reward:  68.79 \t eps:  0.197\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 2.4137\n",
      "Episode Count:  1623 \t Cumulative Reward:  19.97 \t eps:  0.197\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 2.4728\n",
      "Episode Count:  1624 \t Cumulative Reward:  21.76 \t eps:  0.197\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.1606\n",
      "Episode Count:  1625 \t Cumulative Reward:  33.61 \t eps:  0.197\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.6507\n",
      "Episode Count:  1626 \t Cumulative Reward:  20.39 \t eps:  0.196\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.4484\n",
      "Episode Count:  1627 \t Cumulative Reward:  19.01 \t eps:  0.196\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.3155\n",
      "Episode Count:  1628 \t Cumulative Reward:  10.42 \t eps:  0.196\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.4301\n",
      "Episode Count:  1629 \t Cumulative Reward:  42.11 \t eps:  0.196\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.6499\n",
      "Episode Count:  1630 \t Cumulative Reward:  106.45 \t eps:  0.196\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 2.5113\n",
      "Episode Count:  1631 \t Cumulative Reward:  38.57 \t eps:  0.195\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.5665\n",
      "Episode Count:  1632 \t Cumulative Reward:  33.0 \t eps:  0.195\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 1.9793\n",
      "Episode Count:  1633 \t Cumulative Reward:  14.57 \t eps:  0.195\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.3055\n",
      "Episode Count:  1634 \t Cumulative Reward:  44.12 \t eps:  0.195\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.5405\n",
      "Episode Count:  1635 \t Cumulative Reward:  33.77 \t eps:  0.195\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.1892\n",
      "Episode Count:  1636 \t Cumulative Reward:  112.78 \t eps:  0.194\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.2673\n",
      "Episode Count:  1637 \t Cumulative Reward:  79.05 \t eps:  0.194\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 2.7928\n",
      "Episode Count:  1638 \t Cumulative Reward:  19.13 \t eps:  0.194\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 2.3867\n",
      "Episode Count:  1639 \t Cumulative Reward:  3.37 \t eps:  0.194\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 2.6772\n",
      "Episode Count:  1640 \t Cumulative Reward:  23.41 \t eps:  0.194\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.7521\n",
      "Episode Count:  1641 \t Cumulative Reward:  22.08 \t eps:  0.193\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.5428\n",
      "Episode Count:  1642 \t Cumulative Reward:  38.55 \t eps:  0.193\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.6839\n",
      "Episode Count:  1643 \t Cumulative Reward:  24.12 \t eps:  0.193\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.7298\n",
      "Episode Count:  1644 \t Cumulative Reward:  29.68 \t eps:  0.193\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.3430\n",
      "Episode Count:  1645 \t Cumulative Reward:  29.08 \t eps:  0.193\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.4430\n",
      "Episode Count:  1646 \t Cumulative Reward:  12.68 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.3302\n",
      "Episode Count:  1647 \t Cumulative Reward:  52.22 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.8234\n",
      "Episode Count:  1648 \t Cumulative Reward:  25.74 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.7294\n",
      "Episode Count:  1649 \t Cumulative Reward:  72.81 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.5865\n",
      "Episode Count:  1650 \t Cumulative Reward:  42.48 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.6693\n",
      "Episode Count:  1651 \t Cumulative Reward:  19.39 \t eps:  0.192\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 2.5262\n",
      "Episode Count:  1652 \t Cumulative Reward:  16.66 \t eps:  0.191\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.9858: 0s - \n",
      "Episode Count:  1653 \t Cumulative Reward:  12.81 \t eps:  0.191\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.6527\n",
      "Episode Count:  1654 \t Cumulative Reward:  14.4 \t eps:  0.191\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 2.3228\n",
      "Episode Count:  1655 \t Cumulative Reward:  51.95 \t eps:  0.191\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 1.9501\n",
      "Episode Count:  1656 \t Cumulative Reward:  21.49 \t eps:  0.191\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.4353\n",
      "Episode Count:  1657 \t Cumulative Reward:  78.57 \t eps:  0.19\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.4074\n",
      "Episode Count:  1658 \t Cumulative Reward:  47.13 \t eps:  0.19\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.8122\n",
      "Episode Count:  1659 \t Cumulative Reward:  20.98 \t eps:  0.19\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.7184\n",
      "Episode Count:  1660 \t Cumulative Reward:  29.86 \t eps:  0.19\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 2.7344\n",
      "Episode Count:  1661 \t Cumulative Reward:  36.13 \t eps:  0.19\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.6530\n",
      "Episode Count:  1662 \t Cumulative Reward:  42.09 \t eps:  0.189\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.5284\n",
      "Episode Count:  1663 \t Cumulative Reward:  41.86 \t eps:  0.189\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 2.2217\n",
      "Episode Count:  1664 \t Cumulative Reward:  19.71 \t eps:  0.189\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.1149\n",
      "Episode Count:  1665 \t Cumulative Reward:  31.62 \t eps:  0.189\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.4564\n",
      "Episode Count:  1666 \t Cumulative Reward:  42.06 \t eps:  0.189\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.5483\n",
      "Episode Count:  1667 \t Cumulative Reward:  45.1 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.7784\n",
      "Episode Count:  1668 \t Cumulative Reward:  64.11 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.6784\n",
      "Episode Count:  1669 \t Cumulative Reward:  46.48 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 2.5147\n",
      "Episode Count:  1670 \t Cumulative Reward:  86.65 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.4677\n",
      "Episode Count:  1671 \t Cumulative Reward:  32.48 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 2.6222\n",
      "Episode Count:  1672 \t Cumulative Reward:  28.93 \t eps:  0.188\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.2619\n",
      "Episode Count:  1673 \t Cumulative Reward:  31.03 \t eps:  0.187\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 2.7164\n",
      "Episode Count:  1674 \t Cumulative Reward:  43.68 \t eps:  0.187\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.5002\n",
      "Episode Count:  1675 \t Cumulative Reward:  85.91 \t eps:  0.187\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.5651\n",
      "Episode Count:  1676 \t Cumulative Reward:  35.42 \t eps:  0.187\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 2.4627\n",
      "Episode Count:  1677 \t Cumulative Reward:  84.55 \t eps:  0.187\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.5574\n",
      "Episode Count:  1678 \t Cumulative Reward:  15.72 \t eps:  0.186\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.6123\n",
      "Episode Count:  1679 \t Cumulative Reward:  53.11 \t eps:  0.186\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 2.1552\n",
      "Episode Count:  1680 \t Cumulative Reward:  23.29 \t eps:  0.186\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 2.0208\n",
      "Episode Count:  1681 \t Cumulative Reward:  14.26 \t eps:  0.186\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.1314\n",
      "Episode Count:  1682 \t Cumulative Reward:  44.75 \t eps:  0.186\n",
      "16/16 [==============================] - 1s 79ms/step - loss: 2.3876\n",
      "Episode Count:  1683 \t Cumulative Reward:  73.71 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.3158\n",
      "Episode Count:  1684 \t Cumulative Reward:  98.6 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.5697\n",
      "Episode Count:  1685 \t Cumulative Reward:  81.87 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.1829\n",
      "Episode Count:  1686 \t Cumulative Reward:  52.91 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.3775\n",
      "Episode Count:  1687 \t Cumulative Reward:  129.74 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.5049\n",
      "Episode Count:  1688 \t Cumulative Reward:  9.34 \t eps:  0.185\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 2.3847\n",
      "Episode Count:  1689 \t Cumulative Reward:  15.27 \t eps:  0.184\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 2.7705\n",
      "Episode Count:  1690 \t Cumulative Reward:  46.95 \t eps:  0.184\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.3664\n",
      "Episode Count:  1691 \t Cumulative Reward:  124.36 \t eps:  0.184\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 2.6536\n",
      "Episode Count:  1692 \t Cumulative Reward:  17.25 \t eps:  0.184\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.2298\n",
      "Episode Count:  1693 \t Cumulative Reward:  84.74 \t eps:  0.184\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.3034\n",
      "Episode Count:  1694 \t Cumulative Reward:  51.46 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.2267\n",
      "Episode Count:  1695 \t Cumulative Reward:  102.84 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 2.4854\n",
      "Episode Count:  1696 \t Cumulative Reward:  30.0 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.3706\n",
      "Episode Count:  1697 \t Cumulative Reward:  20.72 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.3774\n",
      "Episode Count:  1698 \t Cumulative Reward:  12.2 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 2.4703\n",
      "Episode Count:  1699 \t Cumulative Reward:  47.59 \t eps:  0.183\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.7536\n",
      "Episode Count:  1700 \t Cumulative Reward:  37.21 \t eps:  0.182\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.7310\n",
      "Episode Count:  1701 \t Cumulative Reward:  38.76 \t eps:  0.182\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.0512\n",
      "Episode Count:  1702 \t Cumulative Reward:  22.21 \t eps:  0.182\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.7395\n",
      "Episode Count:  1703 \t Cumulative Reward:  64.1 \t eps:  0.182\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 2.5698\n",
      "Episode Count:  1704 \t Cumulative Reward:  12.53 \t eps:  0.182\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.4246\n",
      "Episode Count:  1705 \t Cumulative Reward:  22.78 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 3.1408\n",
      "Episode Count:  1706 \t Cumulative Reward:  87.33 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.7189\n",
      "Episode Count:  1707 \t Cumulative Reward:  18.21 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.2720\n",
      "Episode Count:  1708 \t Cumulative Reward:  73.76 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.7593\n",
      "Episode Count:  1709 \t Cumulative Reward:  0.34 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.3232\n",
      "Episode Count:  1710 \t Cumulative Reward:  36.57 \t eps:  0.181\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 2.6181\n",
      "Episode Count:  1711 \t Cumulative Reward:  17.87 \t eps:  0.18\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 2.3763\n",
      "Episode Count:  1712 \t Cumulative Reward:  28.37 \t eps:  0.18\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.8615\n",
      "Episode Count:  1713 \t Cumulative Reward:  27.66 \t eps:  0.18\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.5915\n",
      "Episode Count:  1714 \t Cumulative Reward:  46.3 \t eps:  0.18\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.4062\n",
      "Episode Count:  1715 \t Cumulative Reward:  44.54 \t eps:  0.18\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.6189\n",
      "Episode Count:  1716 \t Cumulative Reward:  34.4 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.2066\n",
      "Episode Count:  1717 \t Cumulative Reward:  48.67 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 2.4126\n",
      "Episode Count:  1718 \t Cumulative Reward:  12.85 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.6633\n",
      "Episode Count:  1719 \t Cumulative Reward:  31.62 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.4393\n",
      "Episode Count:  1720 \t Cumulative Reward:  52.04 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.6706\n",
      "Episode Count:  1721 \t Cumulative Reward:  52.3 \t eps:  0.179\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.3128\n",
      "Episode Count:  1722 \t Cumulative Reward:  7.35 \t eps:  0.178\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.2550\n",
      "Episode Count:  1723 \t Cumulative Reward:  15.04 \t eps:  0.178\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.4919\n",
      "Episode Count:  1724 \t Cumulative Reward:  14.11 \t eps:  0.178\n",
      "16/16 [==============================] - 2s 106ms/step - loss: 2.3287\n",
      "Episode Count:  1725 \t Cumulative Reward:  3.59 \t eps:  0.178\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.3501\n",
      "Episode Count:  1726 \t Cumulative Reward:  47.09 \t eps:  0.178\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.6034\n",
      "Episode Count:  1727 \t Cumulative Reward:  57.74 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.1812\n",
      "Episode Count:  1728 \t Cumulative Reward:  17.5 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.4193\n",
      "Episode Count:  1729 \t Cumulative Reward:  38.32 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 2.3855\n",
      "Episode Count:  1730 \t Cumulative Reward:  19.97 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.3150\n",
      "Episode Count:  1731 \t Cumulative Reward:  50.24 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.5591\n",
      "Episode Count:  1732 \t Cumulative Reward:  10.25 \t eps:  0.177\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.2501\n",
      "Episode Count:  1733 \t Cumulative Reward:  18.68 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.2845\n",
      "Episode Count:  1734 \t Cumulative Reward:  47.57 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.0130\n",
      "Episode Count:  1735 \t Cumulative Reward:  39.37 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.0836\n",
      "Episode Count:  1736 \t Cumulative Reward:  43.06 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.1033\n",
      "Episode Count:  1737 \t Cumulative Reward:  36.62 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 2.2411\n",
      "Episode Count:  1738 \t Cumulative Reward:  22.87 \t eps:  0.176\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.0872\n",
      "Episode Count:  1739 \t Cumulative Reward:  11.49 \t eps:  0.175\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.0889\n",
      "Episode Count:  1740 \t Cumulative Reward:  35.86 \t eps:  0.175\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.0327\n",
      "Episode Count:  1741 \t Cumulative Reward:  6.71 \t eps:  0.175\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.1230\n",
      "Episode Count:  1742 \t Cumulative Reward:  4.96 \t eps:  0.175\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.3877\n",
      "Episode Count:  1743 \t Cumulative Reward:  20.57 \t eps:  0.175\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 1.9961\n",
      "Episode Count:  1744 \t Cumulative Reward:  33.64 \t eps:  0.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 110ms/step - loss: 2.3881\n",
      "Episode Count:  1745 \t Cumulative Reward:  74.64 \t eps:  0.174\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.1903\n",
      "Episode Count:  1746 \t Cumulative Reward:  28.87 \t eps:  0.174\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 2.6068\n",
      "Episode Count:  1747 \t Cumulative Reward:  20.8 \t eps:  0.174\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.5729\n",
      "Episode Count:  1748 \t Cumulative Reward:  28.55 \t eps:  0.174\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 2.5119\n",
      "Episode Count:  1749 \t Cumulative Reward:  43.31 \t eps:  0.174\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.5301\n",
      "Episode Count:  1750 \t Cumulative Reward:  38.27 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 110ms/step - loss: 2.2666\n",
      "Episode Count:  1751 \t Cumulative Reward:  94.67 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.1752\n",
      "Episode Count:  1752 \t Cumulative Reward:  67.06 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.2417\n",
      "Episode Count:  1753 \t Cumulative Reward:  32.37 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.2288\n",
      "Episode Count:  1754 \t Cumulative Reward:  18.02 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 2.2023\n",
      "Episode Count:  1755 \t Cumulative Reward:  16.13 \t eps:  0.173\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.1105\n",
      "Episode Count:  1756 \t Cumulative Reward:  48.46 \t eps:  0.172\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 2.4709\n",
      "Episode Count:  1757 \t Cumulative Reward:  24.75 \t eps:  0.172\n",
      "16/16 [==============================] - 2s 106ms/step - loss: 2.3746\n",
      "Episode Count:  1758 \t Cumulative Reward:  17.57 \t eps:  0.172\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.3724\n",
      "Episode Count:  1759 \t Cumulative Reward:  32.27 \t eps:  0.172\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 2.4557\n",
      "Episode Count:  1760 \t Cumulative Reward:  22.42 \t eps:  0.172\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 2.2340\n",
      "Episode Count:  1761 \t Cumulative Reward:  18.04 \t eps:  0.172\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 2.9821\n",
      "Episode Count:  1762 \t Cumulative Reward:  13.64 \t eps:  0.171\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 2.2149\n",
      "Episode Count:  1763 \t Cumulative Reward:  54.4 \t eps:  0.171\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 2.2296\n",
      "Episode Count:  1764 \t Cumulative Reward:  94.75 \t eps:  0.171\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.3127\n",
      "Episode Count:  1765 \t Cumulative Reward:  29.59 \t eps:  0.171\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 2.3404\n",
      "Episode Count:  1766 \t Cumulative Reward:  35.26 \t eps:  0.171\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.4196\n",
      "Episode Count:  1767 \t Cumulative Reward:  38.86 \t eps:  0.171\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.4129\n",
      "Episode Count:  1768 \t Cumulative Reward:  38.78 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.2419\n",
      "Episode Count:  1769 \t Cumulative Reward:  21.34 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.6476\n",
      "Episode Count:  1770 \t Cumulative Reward:  16.97 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.4172\n",
      "Episode Count:  1771 \t Cumulative Reward:  29.52 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.2991\n",
      "Episode Count:  1772 \t Cumulative Reward:  66.38 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 2.1745\n",
      "Episode Count:  1773 \t Cumulative Reward:  44.32 \t eps:  0.17\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.4692\n",
      "Episode Count:  1774 \t Cumulative Reward:  39.88 \t eps:  0.169\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.3299\n",
      "Episode Count:  1775 \t Cumulative Reward:  28.19 \t eps:  0.169\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.0057\n",
      "Episode Count:  1776 \t Cumulative Reward:  63.19 \t eps:  0.169\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.2876\n",
      "Episode Count:  1777 \t Cumulative Reward:  26.45 \t eps:  0.169\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.2104\n",
      "Episode Count:  1778 \t Cumulative Reward:  16.62 \t eps:  0.169\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.1866\n",
      "Episode Count:  1779 \t Cumulative Reward:  40.36 \t eps:  0.168\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.0697\n",
      "Episode Count:  1780 \t Cumulative Reward:  14.95 \t eps:  0.168\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 2.2183\n",
      "Episode Count:  1781 \t Cumulative Reward:  29.79 \t eps:  0.168\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 2.3041\n",
      "Episode Count:  1782 \t Cumulative Reward:  53.9 \t eps:  0.168\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.8936\n",
      "Episode Count:  1783 \t Cumulative Reward:  7.63 \t eps:  0.168\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.2584\n",
      "Episode Count:  1784 \t Cumulative Reward:  64.82 \t eps:  0.168\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 2.2773\n",
      "Episode Count:  1785 \t Cumulative Reward:  21.38 \t eps:  0.167\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.0045\n",
      "Episode Count:  1786 \t Cumulative Reward:  44.48 \t eps:  0.167\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 1.9259\n",
      "Episode Count:  1787 \t Cumulative Reward:  45.32 \t eps:  0.167\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.4492\n",
      "Episode Count:  1788 \t Cumulative Reward:  49.72 \t eps:  0.167\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.2742: 0s - loss: 2.31\n",
      "Episode Count:  1789 \t Cumulative Reward:  34.51 \t eps:  0.167\n",
      "16/16 [==============================] - 2s 94ms/step - loss: 2.5457\n",
      "Episode Count:  1790 \t Cumulative Reward:  46.29 \t eps:  0.167\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 2.1480\n",
      "Episode Count:  1791 \t Cumulative Reward:  28.67 \t eps:  0.166\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.5622\n",
      "Episode Count:  1792 \t Cumulative Reward:  37.6 \t eps:  0.166\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.0870\n",
      "Episode Count:  1793 \t Cumulative Reward:  24.51 \t eps:  0.166\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 2.1184\n",
      "Episode Count:  1794 \t Cumulative Reward:  110.15 \t eps:  0.166\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.4877\n",
      "Episode Count:  1795 \t Cumulative Reward:  82.25 \t eps:  0.166\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.2468\n",
      "Episode Count:  1796 \t Cumulative Reward:  24.55 \t eps:  0.166\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.1997\n",
      "Episode Count:  1797 \t Cumulative Reward:  43.73 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 2.0666\n",
      "Episode Count:  1798 \t Cumulative Reward:  38.28 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.6539\n",
      "Episode Count:  1799 \t Cumulative Reward:  24.2 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 3.4339\n",
      "run 0: cumulative_reward: 16.36, ran for: 10 timesteps\n",
      "run 1: cumulative_reward: 23.65, ran for: 9 timesteps\n",
      "run 2: cumulative_reward: 18.64, ran for: 5 timesteps\n",
      "run 3: cumulative_reward: 35.66, ran for: 10 timesteps\n",
      "run 4: cumulative_reward: 22.61, ran for: 17 timesteps\n",
      "average performance:  23.384\n",
      "Episode Count:  1800 \t Cumulative Reward:  20.11 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 2.9838\n",
      "Episode Count:  1801 \t Cumulative Reward:  49.16 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 3.4285\n",
      "Episode Count:  1802 \t Cumulative Reward:  37.09 \t eps:  0.165\n",
      "16/16 [==============================] - 1s 93ms/step - loss: 2.7717\n",
      "Episode Count:  1803 \t Cumulative Reward:  22.27 \t eps:  0.164\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 2.7246\n",
      "Episode Count:  1804 \t Cumulative Reward:  15.32 \t eps:  0.164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 104ms/step - loss: 3.5836\n",
      "Episode Count:  1805 \t Cumulative Reward:  24.43 \t eps:  0.164\n",
      "16/16 [==============================] - 2s 105ms/step - loss: 3.1645\n",
      "Episode Count:  1806 \t Cumulative Reward:  25.55 \t eps:  0.164\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.8738\n",
      "Episode Count:  1807 \t Cumulative Reward:  59.17 \t eps:  0.164\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.6561\n",
      "Episode Count:  1808 \t Cumulative Reward:  23.77 \t eps:  0.164\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 3.2212\n",
      "Episode Count:  1809 \t Cumulative Reward:  32.98 \t eps:  0.164\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 2.6896\n",
      "Episode Count:  1810 \t Cumulative Reward:  76.34 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.9414\n",
      "Episode Count:  1811 \t Cumulative Reward:  22.01 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 112ms/step - loss: 2.8564\n",
      "Episode Count:  1812 \t Cumulative Reward:  51.41 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 3.1619\n",
      "Episode Count:  1813 \t Cumulative Reward:  29.42 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 3.3891\n",
      "Episode Count:  1814 \t Cumulative Reward:  24.85 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 111ms/step - loss: 2.7933\n",
      "Episode Count:  1815 \t Cumulative Reward:  58.39 \t eps:  0.163\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 3.3223\n",
      "Episode Count:  1816 \t Cumulative Reward:  101.28 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 3.3869\n",
      "Episode Count:  1817 \t Cumulative Reward:  21.45 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.7603\n",
      "Episode Count:  1818 \t Cumulative Reward:  23.01 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.8492\n",
      "Episode Count:  1819 \t Cumulative Reward:  31.8 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.9128\n",
      "Episode Count:  1820 \t Cumulative Reward:  27.96 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.5909\n",
      "Episode Count:  1821 \t Cumulative Reward:  45.26 \t eps:  0.162\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.8201\n",
      "Episode Count:  1822 \t Cumulative Reward:  31.67 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.8221\n",
      "Episode Count:  1823 \t Cumulative Reward:  24.58 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.8516\n",
      "Episode Count:  1824 \t Cumulative Reward:  -0.09 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 3.1933\n",
      "Episode Count:  1825 \t Cumulative Reward:  28.21 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 3.4098\n",
      "Episode Count:  1826 \t Cumulative Reward:  16.42 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.5729\n",
      "Episode Count:  1827 \t Cumulative Reward:  22.19 \t eps:  0.161\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.7959\n",
      "Episode Count:  1828 \t Cumulative Reward:  26.51 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.6946\n",
      "Episode Count:  1829 \t Cumulative Reward:  30.56 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.6559\n",
      "Episode Count:  1830 \t Cumulative Reward:  23.56 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 2.4539\n",
      "Episode Count:  1831 \t Cumulative Reward:  55.31 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 125ms/step - loss: 2.9436\n",
      "Episode Count:  1832 \t Cumulative Reward:  24.28 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 122ms/step - loss: 3.0618\n",
      "Episode Count:  1833 \t Cumulative Reward:  53.43 \t eps:  0.16\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.3532\n",
      "Episode Count:  1834 \t Cumulative Reward:  58.58 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.7025\n",
      "Episode Count:  1835 \t Cumulative Reward:  7.63 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.5677\n",
      "Episode Count:  1836 \t Cumulative Reward:  21.68 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.7268\n",
      "Episode Count:  1837 \t Cumulative Reward:  27.14 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.4893\n",
      "Episode Count:  1838 \t Cumulative Reward:  29.14 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.6156\n",
      "Episode Count:  1839 \t Cumulative Reward:  48.8 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.8563\n",
      "Episode Count:  1840 \t Cumulative Reward:  45.69 \t eps:  0.159\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.7836\n",
      "Episode Count:  1841 \t Cumulative Reward:  23.18 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 3.2545\n",
      "Episode Count:  1842 \t Cumulative Reward:  21.42 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.8569\n",
      "Episode Count:  1843 \t Cumulative Reward:  20.48 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.8427\n",
      "Episode Count:  1844 \t Cumulative Reward:  36.05 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.6996\n",
      "Episode Count:  1845 \t Cumulative Reward:  26.67 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.6404\n",
      "Episode Count:  1846 \t Cumulative Reward:  59.67 \t eps:  0.158\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.6635\n",
      "Episode Count:  1847 \t Cumulative Reward:  26.57 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.1888\n",
      "Episode Count:  1848 \t Cumulative Reward:  20.6 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.4033\n",
      "Episode Count:  1849 \t Cumulative Reward:  26.2 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.3431\n",
      "Episode Count:  1850 \t Cumulative Reward:  26.2 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.5550\n",
      "Episode Count:  1851 \t Cumulative Reward:  19.33 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.4510\n",
      "Episode Count:  1852 \t Cumulative Reward:  33.61 \t eps:  0.157\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 2.3374\n",
      "Episode Count:  1853 \t Cumulative Reward:  22.33 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 2.6396\n",
      "Episode Count:  1854 \t Cumulative Reward:  43.38 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.7124\n",
      "Episode Count:  1855 \t Cumulative Reward:  70.37 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 119ms/step - loss: 3.0019\n",
      "Episode Count:  1856 \t Cumulative Reward:  3.54 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 2.6614\n",
      "Episode Count:  1857 \t Cumulative Reward:  24.56 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.4278\n",
      "Episode Count:  1858 \t Cumulative Reward:  36.82 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.7706\n",
      "Episode Count:  1859 \t Cumulative Reward:  26.3 \t eps:  0.156\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 2.7307\n",
      "Episode Count:  1860 \t Cumulative Reward:  24.17 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 1.9681\n",
      "Episode Count:  1861 \t Cumulative Reward:  27.08 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 3.0871\n",
      "Episode Count:  1862 \t Cumulative Reward:  43.16 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 116ms/step - loss: 2.7627\n",
      "Episode Count:  1863 \t Cumulative Reward:  20.77 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 114ms/step - loss: 2.6064\n",
      "Episode Count:  1864 \t Cumulative Reward:  24.04 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 117ms/step - loss: 2.6564\n",
      "Episode Count:  1865 \t Cumulative Reward:  20.66 \t eps:  0.155\n",
      "16/16 [==============================] - 2s 120ms/step - loss: 2.6264\n",
      "Episode Count:  1866 \t Cumulative Reward:  89.7 \t eps:  0.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 119ms/step - loss: 2.4012\n",
      "Episode Count:  1867 \t Cumulative Reward:  32.02 \t eps:  0.154\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.4572\n",
      "Episode Count:  1868 \t Cumulative Reward:  20.87 \t eps:  0.154\n",
      "16/16 [==============================] - 2s 127ms/step - loss: 2.3544\n",
      "Episode Count:  1869 \t Cumulative Reward:  16.21 \t eps:  0.154\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 2.3356\n",
      "Episode Count:  1870 \t Cumulative Reward:  41.29 \t eps:  0.154\n",
      "16/16 [==============================] - 2s 121ms/step - loss: 2.3228\n",
      "Episode Count:  1871 \t Cumulative Reward:  20.61 \t eps:  0.154\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 1.9814\n",
      "Episode Count:  1872 \t Cumulative Reward:  127.43 \t eps:  0.154\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 2.1959\n",
      "Episode Count:  1873 \t Cumulative Reward:  82.45 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.7692\n",
      "Episode Count:  1874 \t Cumulative Reward:  39.33 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 2.6942\n",
      "Episode Count:  1875 \t Cumulative Reward:  10.27 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.4743\n",
      "Episode Count:  1876 \t Cumulative Reward:  73.38 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.5034\n",
      "Episode Count:  1877 \t Cumulative Reward:  80.51 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.7483\n",
      "Episode Count:  1878 \t Cumulative Reward:  178.19 \t eps:  0.153\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.5247\n",
      "Episode Count:  1879 \t Cumulative Reward:  51.51 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 86ms/step - loss: 2.7989\n",
      "Episode Count:  1880 \t Cumulative Reward:  50.49 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 2.6640: 0s - l\n",
      "Episode Count:  1881 \t Cumulative Reward:  15.06 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 87ms/step - loss: 2.5281\n",
      "Episode Count:  1882 \t Cumulative Reward:  209.77 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 2.4372\n",
      "Episode Count:  1883 \t Cumulative Reward:  31.43 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 2.7995\n",
      "Episode Count:  1884 \t Cumulative Reward:  14.23 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.6809\n",
      "Episode Count:  1885 \t Cumulative Reward:  61.78 \t eps:  0.152\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.4429\n",
      "Episode Count:  1886 \t Cumulative Reward:  67.0 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.7833\n",
      "Episode Count:  1887 \t Cumulative Reward:  40.89 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.0323\n",
      "Episode Count:  1888 \t Cumulative Reward:  26.3 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.8079\n",
      "Episode Count:  1889 \t Cumulative Reward:  186.01 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.7983\n",
      "Episode Count:  1890 \t Cumulative Reward:  51.5 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.6739\n",
      "Episode Count:  1891 \t Cumulative Reward:  47.23 \t eps:  0.151\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.9987\n",
      "Episode Count:  1892 \t Cumulative Reward:  45.55 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.5421\n",
      "Episode Count:  1893 \t Cumulative Reward:  7.8 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.0668\n",
      "Episode Count:  1894 \t Cumulative Reward:  27.71 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.8734\n",
      "Episode Count:  1895 \t Cumulative Reward:  46.93 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 2.9614\n",
      "Episode Count:  1896 \t Cumulative Reward:  115.5 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.0156\n",
      "Episode Count:  1897 \t Cumulative Reward:  52.62 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.7981\n",
      "Episode Count:  1898 \t Cumulative Reward:  35.16 \t eps:  0.15\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.1033\n",
      "Episode Count:  1899 \t Cumulative Reward:  26.62 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.6007\n",
      "Episode Count:  1900 \t Cumulative Reward:  100.39 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.9159\n",
      "Episode Count:  1901 \t Cumulative Reward:  133.88 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6176\n",
      "Episode Count:  1902 \t Cumulative Reward:  14.46 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.1751\n",
      "Episode Count:  1903 \t Cumulative Reward:  99.82 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.9950\n",
      "Episode Count:  1904 \t Cumulative Reward:  96.93 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.4826\n",
      "Episode Count:  1905 \t Cumulative Reward:  42.91 \t eps:  0.149\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 4.0839: 0s - loss: 4.15\n",
      "Episode Count:  1906 \t Cumulative Reward:  33.18 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.1292\n",
      "Episode Count:  1907 \t Cumulative Reward:  96.37 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.2855\n",
      "Episode Count:  1908 \t Cumulative Reward:  136.37 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5911\n",
      "Episode Count:  1909 \t Cumulative Reward:  55.22 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5297\n",
      "Episode Count:  1910 \t Cumulative Reward:  160.61 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.3840\n",
      "Episode Count:  1911 \t Cumulative Reward:  77.18 \t eps:  0.148\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2217\n",
      "Episode Count:  1912 \t Cumulative Reward:  121.36 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6534\n",
      "Episode Count:  1913 \t Cumulative Reward:  66.65 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0785\n",
      "Episode Count:  1914 \t Cumulative Reward:  37.36 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.9414: 0s - loss: 3\n",
      "Episode Count:  1915 \t Cumulative Reward:  32.26 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.2785\n",
      "Episode Count:  1916 \t Cumulative Reward:  32.51 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.9911\n",
      "Episode Count:  1917 \t Cumulative Reward:  63.07 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0333\n",
      "Episode Count:  1918 \t Cumulative Reward:  39.71 \t eps:  0.147\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9713\n",
      "Episode Count:  1919 \t Cumulative Reward:  132.99 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.6687\n",
      "Episode Count:  1920 \t Cumulative Reward:  57.32 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.6375\n",
      "Episode Count:  1921 \t Cumulative Reward:  123.95 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7279\n",
      "Episode Count:  1922 \t Cumulative Reward:  47.5 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.2931\n",
      "Episode Count:  1923 \t Cumulative Reward:  36.59 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.3220\n",
      "Episode Count:  1924 \t Cumulative Reward:  72.48 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 4.1408\n",
      "Episode Count:  1925 \t Cumulative Reward:  35.23 \t eps:  0.146\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6936\n",
      "Episode Count:  1926 \t Cumulative Reward:  102.37 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 3.8835\n",
      "Episode Count:  1927 \t Cumulative Reward:  42.57 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 4.1101\n",
      "Episode Count:  1928 \t Cumulative Reward:  38.33 \t eps:  0.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 77ms/step - loss: 3.1475\n",
      "Episode Count:  1929 \t Cumulative Reward:  24.48 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.7426\n",
      "Episode Count:  1930 \t Cumulative Reward:  30.59 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 3.4549\n",
      "Episode Count:  1931 \t Cumulative Reward:  24.01 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 3.7410\n",
      "Episode Count:  1932 \t Cumulative Reward:  37.97 \t eps:  0.145\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 3.6861\n",
      "Episode Count:  1933 \t Cumulative Reward:  33.77 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 3.6563: 0s - loss: 3.59\n",
      "Episode Count:  1934 \t Cumulative Reward:  19.29 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.5635\n",
      "Episode Count:  1935 \t Cumulative Reward:  28.17 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.8318: 0s - loss: 3.831\n",
      "Episode Count:  1936 \t Cumulative Reward:  20.69 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6653\n",
      "Episode Count:  1937 \t Cumulative Reward:  69.1 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.3968\n",
      "Episode Count:  1938 \t Cumulative Reward:  111.46 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5901\n",
      "Episode Count:  1939 \t Cumulative Reward:  51.81 \t eps:  0.144\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0184\n",
      "Episode Count:  1940 \t Cumulative Reward:  68.01 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.7110\n",
      "Episode Count:  1941 \t Cumulative Reward:  17.22 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.3035\n",
      "Episode Count:  1942 \t Cumulative Reward:  151.2 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.9623\n",
      "Episode Count:  1943 \t Cumulative Reward:  77.4 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.1623\n",
      "Episode Count:  1944 \t Cumulative Reward:  71.7 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 83ms/step - loss: 3.7238\n",
      "Episode Count:  1945 \t Cumulative Reward:  20.49 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 76ms/step - loss: 3.3536\n",
      "Episode Count:  1946 \t Cumulative Reward:  26.43 \t eps:  0.143\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.5650\n",
      "Episode Count:  1947 \t Cumulative Reward:  44.78 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.5498\n",
      "Episode Count:  1948 \t Cumulative Reward:  22.17 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3331\n",
      "Episode Count:  1949 \t Cumulative Reward:  136.22 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.2327\n",
      "Episode Count:  1950 \t Cumulative Reward:  29.76 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.4267\n",
      "Episode Count:  1951 \t Cumulative Reward:  57.2 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.7363\n",
      "Episode Count:  1952 \t Cumulative Reward:  89.01 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.1607\n",
      "Episode Count:  1953 \t Cumulative Reward:  34.91 \t eps:  0.142\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2860\n",
      "Episode Count:  1954 \t Cumulative Reward:  50.54 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7638\n",
      "Episode Count:  1955 \t Cumulative Reward:  85.09 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.3531\n",
      "Episode Count:  1956 \t Cumulative Reward:  63.51 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.0078\n",
      "Episode Count:  1957 \t Cumulative Reward:  32.69 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.4255\n",
      "Episode Count:  1958 \t Cumulative Reward:  59.93 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 80ms/step - loss: 3.3025\n",
      "Episode Count:  1959 \t Cumulative Reward:  27.32 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.0536\n",
      "Episode Count:  1960 \t Cumulative Reward:  35.64 \t eps:  0.141\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 3.4341\n",
      "Episode Count:  1961 \t Cumulative Reward:  44.69 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 81ms/step - loss: 3.5918\n",
      "Episode Count:  1962 \t Cumulative Reward:  21.61 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4646\n",
      "Episode Count:  1963 \t Cumulative Reward:  125.75 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.5818\n",
      "Episode Count:  1964 \t Cumulative Reward:  84.4 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.2394\n",
      "Episode Count:  1965 \t Cumulative Reward:  117.93 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6574\n",
      "Episode Count:  1966 \t Cumulative Reward:  66.18 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 3.1738\n",
      "Episode Count:  1967 \t Cumulative Reward:  37.39 \t eps:  0.14\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 3.0149\n",
      "Episode Count:  1968 \t Cumulative Reward:  24.87 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.5376\n",
      "Episode Count:  1969 \t Cumulative Reward:  154.59 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 3.3570: 0s - los\n",
      "Episode Count:  1970 \t Cumulative Reward:  22.66 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.8941\n",
      "Episode Count:  1971 \t Cumulative Reward:  43.28 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0124\n",
      "Episode Count:  1972 \t Cumulative Reward:  27.3 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.0725\n",
      "Episode Count:  1973 \t Cumulative Reward:  21.18 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5183\n",
      "Episode Count:  1974 \t Cumulative Reward:  76.74 \t eps:  0.139\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.4652\n",
      "Episode Count:  1975 \t Cumulative Reward:  75.57 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5655\n",
      "Episode Count:  1976 \t Cumulative Reward:  -63.07 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6452\n",
      "Episode Count:  1977 \t Cumulative Reward:  49.08 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.5914\n",
      "Episode Count:  1978 \t Cumulative Reward:  51.37 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.4422\n",
      "Episode Count:  1979 \t Cumulative Reward:  49.2 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.2066\n",
      "Episode Count:  1980 \t Cumulative Reward:  11.51 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.4806\n",
      "Episode Count:  1981 \t Cumulative Reward:  27.98 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.5740\n",
      "Episode Count:  1982 \t Cumulative Reward:  56.75 \t eps:  0.138\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6588\n",
      "Episode Count:  1983 \t Cumulative Reward:  61.56 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.4838\n",
      "Episode Count:  1984 \t Cumulative Reward:  51.99 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 2.9939\n",
      "Episode Count:  1985 \t Cumulative Reward:  19.1 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6193\n",
      "Episode Count:  1986 \t Cumulative Reward:  42.3 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4303\n",
      "Episode Count:  1987 \t Cumulative Reward:  19.56 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.3424\n",
      "Episode Count:  1988 \t Cumulative Reward:  46.36 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.2503\n",
      "Episode Count:  1989 \t Cumulative Reward:  24.02 \t eps:  0.137\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.1652\n",
      "Episode Count:  1990 \t Cumulative Reward:  24.57 \t eps:  0.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 70ms/step - loss: 3.3470\n",
      "Episode Count:  1991 \t Cumulative Reward:  25.89 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5346\n",
      "Episode Count:  1992 \t Cumulative Reward:  154.3 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.4070\n",
      "Episode Count:  1993 \t Cumulative Reward:  95.34 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6655\n",
      "Episode Count:  1994 \t Cumulative Reward:  12.84 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.0054\n",
      "Episode Count:  1995 \t Cumulative Reward:  51.53 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2703\n",
      "Episode Count:  1996 \t Cumulative Reward:  25.07 \t eps:  0.136\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.3943\n",
      "Episode Count:  1997 \t Cumulative Reward:  10.07 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.0001\n",
      "Episode Count:  1998 \t Cumulative Reward:  75.0 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5769\n",
      "Episode Count:  1999 \t Cumulative Reward:  54.48 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.7324\n",
      "run 0: cumulative_reward: 26.33, ran for: 19 timesteps\n",
      "run 1: cumulative_reward: 52.74, ran for: 34 timesteps\n",
      "run 2: cumulative_reward: 33.54, ran for: 32 timesteps\n",
      "run 3: cumulative_reward: 85.22, ran for: 36 timesteps\n",
      "run 4: cumulative_reward: 12.14, ran for: 17 timesteps\n",
      "average performance:  41.99399999999999\n",
      "Episode Count:  2000 \t Cumulative Reward:  71.07 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.4620\n",
      "Episode Count:  2001 \t Cumulative Reward:  126.1 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9274\n",
      "Episode Count:  2002 \t Cumulative Reward:  20.21 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.6593\n",
      "Episode Count:  2003 \t Cumulative Reward:  40.52 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.7543\n",
      "Episode Count:  2004 \t Cumulative Reward:  35.63 \t eps:  0.135\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.2368\n",
      "Episode Count:  2005 \t Cumulative Reward:  25.2 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.5770\n",
      "Episode Count:  2006 \t Cumulative Reward:  17.82 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9061\n",
      "Episode Count:  2007 \t Cumulative Reward:  60.33 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.9337\n",
      "Episode Count:  2008 \t Cumulative Reward:  13.41 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3764\n",
      "Episode Count:  2009 \t Cumulative Reward:  52.63 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.9353\n",
      "Episode Count:  2010 \t Cumulative Reward:  36.0 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5470\n",
      "Episode Count:  2011 \t Cumulative Reward:  74.84 \t eps:  0.134\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.2231\n",
      "Episode Count:  2012 \t Cumulative Reward:  27.46 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.9854\n",
      "Episode Count:  2013 \t Cumulative Reward:  79.6 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.4714\n",
      "Episode Count:  2014 \t Cumulative Reward:  136.27 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.2451\n",
      "Episode Count:  2015 \t Cumulative Reward:  41.61 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5876\n",
      "Episode Count:  2016 \t Cumulative Reward:  18.74 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.9298\n",
      "Episode Count:  2017 \t Cumulative Reward:  104.98 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0529\n",
      "Episode Count:  2018 \t Cumulative Reward:  15.35 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.4877\n",
      "Episode Count:  2019 \t Cumulative Reward:  32.59 \t eps:  0.133\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.3968\n",
      "Episode Count:  2020 \t Cumulative Reward:  28.89 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2091\n",
      "Episode Count:  2021 \t Cumulative Reward:  34.84 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.2909\n",
      "Episode Count:  2022 \t Cumulative Reward:  67.66 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.7972\n",
      "Episode Count:  2023 \t Cumulative Reward:  21.67 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5384\n",
      "Episode Count:  2024 \t Cumulative Reward:  29.0 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6583\n",
      "Episode Count:  2025 \t Cumulative Reward:  43.48 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.2696\n",
      "Episode Count:  2026 \t Cumulative Reward:  89.52 \t eps:  0.132\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4433\n",
      "Episode Count:  2027 \t Cumulative Reward:  46.19 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.9856\n",
      "Episode Count:  2028 \t Cumulative Reward:  47.41 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.8279\n",
      "Episode Count:  2029 \t Cumulative Reward:  90.19 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5036\n",
      "Episode Count:  2030 \t Cumulative Reward:  18.22 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.3957\n",
      "Episode Count:  2031 \t Cumulative Reward:  67.7 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5994\n",
      "Episode Count:  2032 \t Cumulative Reward:  81.43 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7931\n",
      "Episode Count:  2033 \t Cumulative Reward:  37.99 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.8701\n",
      "Episode Count:  2034 \t Cumulative Reward:  65.95 \t eps:  0.131\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.4672\n",
      "Episode Count:  2035 \t Cumulative Reward:  23.71 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4820\n",
      "Episode Count:  2036 \t Cumulative Reward:  37.68 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6334\n",
      "Episode Count:  2037 \t Cumulative Reward:  48.74 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6656\n",
      "Episode Count:  2038 \t Cumulative Reward:  8.93 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.3521\n",
      "Episode Count:  2039 \t Cumulative Reward:  51.31 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.5832\n",
      "Episode Count:  2040 \t Cumulative Reward:  46.88 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.3687\n",
      "Episode Count:  2041 \t Cumulative Reward:  76.95 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.7283\n",
      "Episode Count:  2042 \t Cumulative Reward:  26.75 \t eps:  0.13\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6760\n",
      "Episode Count:  2043 \t Cumulative Reward:  79.95 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6853\n",
      "Episode Count:  2044 \t Cumulative Reward:  21.25 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.9592\n",
      "Episode Count:  2045 \t Cumulative Reward:  44.71 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.3354\n",
      "Episode Count:  2046 \t Cumulative Reward:  42.5 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.4632\n",
      "Episode Count:  2047 \t Cumulative Reward:  17.96 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.8810\n",
      "Episode Count:  2048 \t Cumulative Reward:  13.31 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.3478\n",
      "Episode Count:  2049 \t Cumulative Reward:  28.0 \t eps:  0.129\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9724\n",
      "Episode Count:  2050 \t Cumulative Reward:  144.42 \t eps:  0.128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 72ms/step - loss: 2.8929\n",
      "Episode Count:  2051 \t Cumulative Reward:  49.21 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.4707\n",
      "Episode Count:  2052 \t Cumulative Reward:  24.07 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 2.8588\n",
      "Episode Count:  2053 \t Cumulative Reward:  47.36 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.2912\n",
      "Episode Count:  2054 \t Cumulative Reward:  54.17 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8286\n",
      "Episode Count:  2055 \t Cumulative Reward:  14.8 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.5063\n",
      "Episode Count:  2056 \t Cumulative Reward:  146.69 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.4415\n",
      "Episode Count:  2057 \t Cumulative Reward:  78.22 \t eps:  0.128\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.5632\n",
      "Episode Count:  2058 \t Cumulative Reward:  43.12 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.8871\n",
      "Episode Count:  2059 \t Cumulative Reward:  34.7 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.0103\n",
      "Episode Count:  2060 \t Cumulative Reward:  7.82 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.2384\n",
      "Episode Count:  2061 \t Cumulative Reward:  39.83 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.7323\n",
      "Episode Count:  2062 \t Cumulative Reward:  87.15 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8864\n",
      "Episode Count:  2063 \t Cumulative Reward:  77.5 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.1724\n",
      "Episode Count:  2064 \t Cumulative Reward:  96.91 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6911\n",
      "Episode Count:  2065 \t Cumulative Reward:  46.71 \t eps:  0.127\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.3478\n",
      "Episode Count:  2066 \t Cumulative Reward:  37.97 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.1705\n",
      "Episode Count:  2067 \t Cumulative Reward:  40.91 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8726\n",
      "Episode Count:  2068 \t Cumulative Reward:  57.39 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.7054\n",
      "Episode Count:  2069 \t Cumulative Reward:  39.96 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.0456\n",
      "Episode Count:  2070 \t Cumulative Reward:  37.7 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6333\n",
      "Episode Count:  2071 \t Cumulative Reward:  50.6 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.1167\n",
      "Episode Count:  2072 \t Cumulative Reward:  48.75 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.3887\n",
      "Episode Count:  2073 \t Cumulative Reward:  98.03 \t eps:  0.126\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.0527\n",
      "Episode Count:  2074 \t Cumulative Reward:  32.02 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.5879\n",
      "Episode Count:  2075 \t Cumulative Reward:  98.39 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.4322\n",
      "Episode Count:  2076 \t Cumulative Reward:  47.59 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0852\n",
      "Episode Count:  2077 \t Cumulative Reward:  78.8 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6746\n",
      "Episode Count:  2078 \t Cumulative Reward:  101.66 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.7223\n",
      "Episode Count:  2079 \t Cumulative Reward:  45.05 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.3180\n",
      "Episode Count:  2080 \t Cumulative Reward:  17.48 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.0309\n",
      "Episode Count:  2081 \t Cumulative Reward:  10.62 \t eps:  0.125\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.5727\n",
      "Episode Count:  2082 \t Cumulative Reward:  81.97 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.7544\n",
      "Episode Count:  2083 \t Cumulative Reward:  41.95 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.3605\n",
      "Episode Count:  2084 \t Cumulative Reward:  20.7 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.2057\n",
      "Episode Count:  2085 \t Cumulative Reward:  17.31 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.1503\n",
      "Episode Count:  2086 \t Cumulative Reward:  68.67 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.0400\n",
      "Episode Count:  2087 \t Cumulative Reward:  55.41 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.2118\n",
      "Episode Count:  2088 \t Cumulative Reward:  22.05 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.2056\n",
      "Episode Count:  2089 \t Cumulative Reward:  6.3 \t eps:  0.124\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.6808\n",
      "Episode Count:  2090 \t Cumulative Reward:  7.78 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.8688\n",
      "Episode Count:  2091 \t Cumulative Reward:  15.0 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.7618\n",
      "Episode Count:  2092 \t Cumulative Reward:  16.56 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.0913\n",
      "Episode Count:  2093 \t Cumulative Reward:  141.72 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.7014\n",
      "Episode Count:  2094 \t Cumulative Reward:  47.96 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.3160\n",
      "Episode Count:  2095 \t Cumulative Reward:  73.01 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0693\n",
      "Episode Count:  2096 \t Cumulative Reward:  62.29 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.7096\n",
      "Episode Count:  2097 \t Cumulative Reward:  32.34 \t eps:  0.123\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8005\n",
      "Episode Count:  2098 \t Cumulative Reward:  60.62 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6189\n",
      "Episode Count:  2099 \t Cumulative Reward:  31.71 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.9018\n",
      "Episode Count:  2100 \t Cumulative Reward:  108.91 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 5.4252\n",
      "Episode Count:  2101 \t Cumulative Reward:  23.3 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 4.3162\n",
      "Episode Count:  2102 \t Cumulative Reward:  50.7 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.9833\n",
      "Episode Count:  2103 \t Cumulative Reward:  20.99 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3684\n",
      "Episode Count:  2104 \t Cumulative Reward:  32.02 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.2754\n",
      "Episode Count:  2105 \t Cumulative Reward:  29.62 \t eps:  0.122\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9108\n",
      "Episode Count:  2106 \t Cumulative Reward:  30.22 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.1008\n",
      "Episode Count:  2107 \t Cumulative Reward:  86.88 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.7770\n",
      "Episode Count:  2108 \t Cumulative Reward:  23.18 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.5836\n",
      "Episode Count:  2109 \t Cumulative Reward:  28.87 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.8301\n",
      "Episode Count:  2110 \t Cumulative Reward:  87.33 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0806\n",
      "Episode Count:  2111 \t Cumulative Reward:  30.95 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0528\n",
      "Episode Count:  2112 \t Cumulative Reward:  43.99 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 4.5372\n",
      "Episode Count:  2113 \t Cumulative Reward:  106.56 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8630\n",
      "Episode Count:  2114 \t Cumulative Reward:  31.77 \t eps:  0.121\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.3322\n",
      "Episode Count:  2115 \t Cumulative Reward:  12.27 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.2175\n",
      "Episode Count:  2116 \t Cumulative Reward:  36.5 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6075\n",
      "Episode Count:  2117 \t Cumulative Reward:  47.47 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.6853\n",
      "Episode Count:  2118 \t Cumulative Reward:  44.15 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8241\n",
      "Episode Count:  2119 \t Cumulative Reward:  60.45 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8644\n",
      "Episode Count:  2120 \t Cumulative Reward:  88.49 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.0493\n",
      "Episode Count:  2121 \t Cumulative Reward:  108.76 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.5094\n",
      "Episode Count:  2122 \t Cumulative Reward:  44.21 \t eps:  0.12\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3341\n",
      "Episode Count:  2123 \t Cumulative Reward:  47.76 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0640\n",
      "Episode Count:  2124 \t Cumulative Reward:  54.93 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.5664\n",
      "Episode Count:  2125 \t Cumulative Reward:  19.83 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6289\n",
      "Episode Count:  2126 \t Cumulative Reward:  48.17 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.0186\n",
      "Episode Count:  2127 \t Cumulative Reward:  12.62 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8491\n",
      "Episode Count:  2128 \t Cumulative Reward:  18.94 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.8887\n",
      "Episode Count:  2129 \t Cumulative Reward:  29.55 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.2172\n",
      "Episode Count:  2130 \t Cumulative Reward:  110.95 \t eps:  0.119\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8591\n",
      "Episode Count:  2131 \t Cumulative Reward:  33.84 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.7477\n",
      "Episode Count:  2132 \t Cumulative Reward:  47.6 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.1107\n",
      "Episode Count:  2133 \t Cumulative Reward:  32.79 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5110\n",
      "Episode Count:  2134 \t Cumulative Reward:  34.93 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6254\n",
      "Episode Count:  2135 \t Cumulative Reward:  40.7 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9367\n",
      "Episode Count:  2136 \t Cumulative Reward:  80.83 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.5972\n",
      "Episode Count:  2137 \t Cumulative Reward:  56.26 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9758\n",
      "Episode Count:  2138 \t Cumulative Reward:  87.82 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.5832\n",
      "Episode Count:  2139 \t Cumulative Reward:  132.42 \t eps:  0.118\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8533\n",
      "Episode Count:  2140 \t Cumulative Reward:  41.39 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.2331\n",
      "Episode Count:  2141 \t Cumulative Reward:  85.33 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 3.5068\n",
      "Episode Count:  2142 \t Cumulative Reward:  38.93 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8661\n",
      "Episode Count:  2143 \t Cumulative Reward:  33.63 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8454\n",
      "Episode Count:  2144 \t Cumulative Reward:  42.25 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.1688\n",
      "Episode Count:  2145 \t Cumulative Reward:  -31.83 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.7443\n",
      "Episode Count:  2146 \t Cumulative Reward:  21.49 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6067\n",
      "Episode Count:  2147 \t Cumulative Reward:  69.82 \t eps:  0.117\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8177\n",
      "Episode Count:  2148 \t Cumulative Reward:  12.42 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.2649\n",
      "Episode Count:  2149 \t Cumulative Reward:  54.23 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8026\n",
      "Episode Count:  2150 \t Cumulative Reward:  98.31 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8359\n",
      "Episode Count:  2151 \t Cumulative Reward:  26.82 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9787\n",
      "Episode Count:  2152 \t Cumulative Reward:  195.75 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.5562\n",
      "Episode Count:  2153 \t Cumulative Reward:  13.57 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.4406\n",
      "Episode Count:  2154 \t Cumulative Reward:  37.4 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.4022\n",
      "Episode Count:  2155 \t Cumulative Reward:  58.47 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.8969\n",
      "Episode Count:  2156 \t Cumulative Reward:  26.77 \t eps:  0.116\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 3.7940\n",
      "Episode Count:  2157 \t Cumulative Reward:  36.59 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 4.4689\n",
      "Episode Count:  2158 \t Cumulative Reward:  48.52 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6505\n",
      "Episode Count:  2159 \t Cumulative Reward:  40.86 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3058\n",
      "Episode Count:  2160 \t Cumulative Reward:  39.74 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.3160\n",
      "Episode Count:  2161 \t Cumulative Reward:  30.72 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 2.9968\n",
      "Episode Count:  2162 \t Cumulative Reward:  21.0 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.2882\n",
      "Episode Count:  2163 \t Cumulative Reward:  40.06 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.6374\n",
      "Episode Count:  2164 \t Cumulative Reward:  24.24 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.5625\n",
      "Episode Count:  2165 \t Cumulative Reward:  43.65 \t eps:  0.115\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.8200\n",
      "Episode Count:  2166 \t Cumulative Reward:  27.11 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3570\n",
      "Episode Count:  2167 \t Cumulative Reward:  41.46 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.3563\n",
      "Episode Count:  2168 \t Cumulative Reward:  31.04 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.4104\n",
      "Episode Count:  2169 \t Cumulative Reward:  58.84 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.9197\n",
      "Episode Count:  2170 \t Cumulative Reward:  58.7 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0894\n",
      "Episode Count:  2171 \t Cumulative Reward:  33.98 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0245\n",
      "Episode Count:  2172 \t Cumulative Reward:  35.79 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.9117\n",
      "Episode Count:  2173 \t Cumulative Reward:  39.85 \t eps:  0.114\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.4211\n",
      "Episode Count:  2174 \t Cumulative Reward:  38.15 \t eps:  0.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 69ms/step - loss: 3.2952\n",
      "Episode Count:  2175 \t Cumulative Reward:  70.48 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.7615\n",
      "Episode Count:  2176 \t Cumulative Reward:  86.59 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.9962\n",
      "Episode Count:  2177 \t Cumulative Reward:  16.36 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8809\n",
      "Episode Count:  2178 \t Cumulative Reward:  41.85 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.5139\n",
      "Episode Count:  2179 \t Cumulative Reward:  41.13 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 3.9957\n",
      "Episode Count:  2180 \t Cumulative Reward:  17.52 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 4.5927\n",
      "Episode Count:  2181 \t Cumulative Reward:  27.36 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0546\n",
      "Episode Count:  2182 \t Cumulative Reward:  16.49 \t eps:  0.113\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.1987\n",
      "Episode Count:  2183 \t Cumulative Reward:  44.84 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0366\n",
      "Episode Count:  2184 \t Cumulative Reward:  0.29 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.6015\n",
      "Episode Count:  2185 \t Cumulative Reward:  6.33 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0268\n",
      "Episode Count:  2186 \t Cumulative Reward:  46.89 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.6410\n",
      "Episode Count:  2187 \t Cumulative Reward:  21.16 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.8944\n",
      "Episode Count:  2188 \t Cumulative Reward:  35.76 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0702\n",
      "Episode Count:  2189 \t Cumulative Reward:  31.04 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.8799\n",
      "Episode Count:  2190 \t Cumulative Reward:  39.93 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.7034\n",
      "Episode Count:  2191 \t Cumulative Reward:  33.07 \t eps:  0.112\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0421\n",
      "Episode Count:  2192 \t Cumulative Reward:  71.01 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.9776\n",
      "Episode Count:  2193 \t Cumulative Reward:  29.25 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 3.6582\n",
      "Episode Count:  2194 \t Cumulative Reward:  44.35 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.0838\n",
      "Episode Count:  2195 \t Cumulative Reward:  141.45 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.9167\n",
      "Episode Count:  2196 \t Cumulative Reward:  62.51 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.1686\n",
      "Episode Count:  2197 \t Cumulative Reward:  59.59 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.5109\n",
      "Episode Count:  2198 \t Cumulative Reward:  47.45 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.2807\n",
      "Episode Count:  2199 \t Cumulative Reward:  28.17 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.7966\n",
      "run 0: cumulative_reward: 61.66, ran for: 26 timesteps\n",
      "run 1: cumulative_reward: 2.6, ran for: 50 timesteps\n",
      "run 2: cumulative_reward: 78.54, ran for: 43 timesteps\n",
      "run 3: cumulative_reward: 68.05, ran for: 40 timesteps\n",
      "run 4: cumulative_reward: 20.29, ran for: 13 timesteps\n",
      "average performance:  46.228\n",
      "Episode Count:  2200 \t Cumulative Reward:  98.82 \t eps:  0.111\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.8102\n",
      "Episode Count:  2201 \t Cumulative Reward:  10.44 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 5.6293\n",
      "Episode Count:  2202 \t Cumulative Reward:  17.64 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.4311\n",
      "Episode Count:  2203 \t Cumulative Reward:  9.85 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.2899\n",
      "Episode Count:  2204 \t Cumulative Reward:  11.56 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 5.3885\n",
      "Episode Count:  2205 \t Cumulative Reward:  66.08 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.1769\n",
      "Episode Count:  2206 \t Cumulative Reward:  31.41 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.7450\n",
      "Episode Count:  2207 \t Cumulative Reward:  43.18 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 3.9995\n",
      "Episode Count:  2208 \t Cumulative Reward:  6.53 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.3449\n",
      "Episode Count:  2209 \t Cumulative Reward:  8.77 \t eps:  0.11\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 4.0866\n",
      "Episode Count:  2210 \t Cumulative Reward:  34.09 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.9154\n",
      "Episode Count:  2211 \t Cumulative Reward:  36.82 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.5649\n",
      "Episode Count:  2212 \t Cumulative Reward:  24.5 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.3745\n",
      "Episode Count:  2213 \t Cumulative Reward:  43.61 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.7502\n",
      "Episode Count:  2214 \t Cumulative Reward:  26.82 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.0911\n",
      "Episode Count:  2215 \t Cumulative Reward:  69.02 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6278\n",
      "Episode Count:  2216 \t Cumulative Reward:  31.92 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.2639\n",
      "Episode Count:  2217 \t Cumulative Reward:  21.06 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 4.1275\n",
      "Episode Count:  2218 \t Cumulative Reward:  22.17 \t eps:  0.109\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.7831\n",
      "Episode Count:  2219 \t Cumulative Reward:  35.69 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0602\n",
      "Episode Count:  2220 \t Cumulative Reward:  45.63 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.1719\n",
      "Episode Count:  2221 \t Cumulative Reward:  14.81 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6983\n",
      "Episode Count:  2222 \t Cumulative Reward:  11.08 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 4.5989\n",
      "Episode Count:  2223 \t Cumulative Reward:  39.79 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.5683\n",
      "Episode Count:  2224 \t Cumulative Reward:  138.89 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4807\n",
      "Episode Count:  2225 \t Cumulative Reward:  52.02 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.3698\n",
      "Episode Count:  2226 \t Cumulative Reward:  46.58 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.5268\n",
      "Episode Count:  2227 \t Cumulative Reward:  25.14 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.8884\n",
      "Episode Count:  2228 \t Cumulative Reward:  32.95 \t eps:  0.108\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.2183\n",
      "Episode Count:  2229 \t Cumulative Reward:  42.76 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3466\n",
      "Episode Count:  2230 \t Cumulative Reward:  51.04 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.5941\n",
      "Episode Count:  2231 \t Cumulative Reward:  22.49 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.7330\n",
      "Episode Count:  2232 \t Cumulative Reward:  29.95 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.5587\n",
      "Episode Count:  2233 \t Cumulative Reward:  79.66 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.7446\n",
      "Episode Count:  2234 \t Cumulative Reward:  34.41 \t eps:  0.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 71ms/step - loss: 3.8197\n",
      "Episode Count:  2235 \t Cumulative Reward:  23.42 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.7487\n",
      "Episode Count:  2236 \t Cumulative Reward:  18.67 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 3.6986\n",
      "Episode Count:  2237 \t Cumulative Reward:  106.86 \t eps:  0.107\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.6743\n",
      "Episode Count:  2238 \t Cumulative Reward:  30.95 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8054\n",
      "Episode Count:  2239 \t Cumulative Reward:  13.26 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.3556\n",
      "Episode Count:  2240 \t Cumulative Reward:  39.76 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.1736\n",
      "Episode Count:  2241 \t Cumulative Reward:  36.64 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.2880\n",
      "Episode Count:  2242 \t Cumulative Reward:  68.01 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3006\n",
      "Episode Count:  2243 \t Cumulative Reward:  21.18 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8403\n",
      "Episode Count:  2244 \t Cumulative Reward:  51.66 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7235\n",
      "Episode Count:  2245 \t Cumulative Reward:  13.32 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7522\n",
      "Episode Count:  2246 \t Cumulative Reward:  53.48 \t eps:  0.106\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7425\n",
      "Episode Count:  2247 \t Cumulative Reward:  31.51 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 3.0754\n",
      "Episode Count:  2248 \t Cumulative Reward:  46.29 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.2708\n",
      "Episode Count:  2249 \t Cumulative Reward:  70.49 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4303\n",
      "Episode Count:  2250 \t Cumulative Reward:  18.88 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.9716\n",
      "Episode Count:  2251 \t Cumulative Reward:  19.87 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.1374\n",
      "Episode Count:  2252 \t Cumulative Reward:  14.9 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9463\n",
      "Episode Count:  2253 \t Cumulative Reward:  23.68 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6400\n",
      "Episode Count:  2254 \t Cumulative Reward:  28.79 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.7273\n",
      "Episode Count:  2255 \t Cumulative Reward:  93.95 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.1731\n",
      "Episode Count:  2256 \t Cumulative Reward:  60.54 \t eps:  0.105\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8003\n",
      "Episode Count:  2257 \t Cumulative Reward:  127.44 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7270\n",
      "Episode Count:  2258 \t Cumulative Reward:  63.98 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.3270\n",
      "Episode Count:  2259 \t Cumulative Reward:  20.4 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.3308\n",
      "Episode Count:  2260 \t Cumulative Reward:  66.06 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9232\n",
      "Episode Count:  2261 \t Cumulative Reward:  75.75 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.6193\n",
      "Episode Count:  2262 \t Cumulative Reward:  42.53 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.8458\n",
      "Episode Count:  2263 \t Cumulative Reward:  6.49 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.4523\n",
      "Episode Count:  2264 \t Cumulative Reward:  23.89 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.9994\n",
      "Episode Count:  2265 \t Cumulative Reward:  183.42 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0673\n",
      "Episode Count:  2266 \t Cumulative Reward:  105.58 \t eps:  0.104\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.1192\n",
      "Episode Count:  2267 \t Cumulative Reward:  114.57 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8712\n",
      "Episode Count:  2268 \t Cumulative Reward:  69.49 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8994\n",
      "Episode Count:  2269 \t Cumulative Reward:  64.94 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9654\n",
      "Episode Count:  2270 \t Cumulative Reward:  93.97 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.5780\n",
      "Episode Count:  2271 \t Cumulative Reward:  94.91 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.0752\n",
      "Episode Count:  2272 \t Cumulative Reward:  26.76 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3460\n",
      "Episode Count:  2273 \t Cumulative Reward:  31.93 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6515\n",
      "Episode Count:  2274 \t Cumulative Reward:  41.09 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6936\n",
      "Episode Count:  2275 \t Cumulative Reward:  51.45 \t eps:  0.103\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.8740\n",
      "Episode Count:  2276 \t Cumulative Reward:  3.19 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 2.7638\n",
      "Episode Count:  2277 \t Cumulative Reward:  64.24 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.3462\n",
      "Episode Count:  2278 \t Cumulative Reward:  32.86 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.8039\n",
      "Episode Count:  2279 \t Cumulative Reward:  15.41 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.9930\n",
      "Episode Count:  2280 \t Cumulative Reward:  18.4 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.8775\n",
      "Episode Count:  2281 \t Cumulative Reward:  49.85 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.7584\n",
      "Episode Count:  2282 \t Cumulative Reward:  140.29 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.0515\n",
      "Episode Count:  2283 \t Cumulative Reward:  18.61 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.9894\n",
      "Episode Count:  2284 \t Cumulative Reward:  1.37 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.4020\n",
      "Episode Count:  2285 \t Cumulative Reward:  25.9 \t eps:  0.102\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.9303\n",
      "Episode Count:  2286 \t Cumulative Reward:  101.26 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.4631\n",
      "Episode Count:  2287 \t Cumulative Reward:  120.93 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.6384\n",
      "Episode Count:  2288 \t Cumulative Reward:  90.42 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7602\n",
      "Episode Count:  2289 \t Cumulative Reward:  39.72 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.3395\n",
      "Episode Count:  2290 \t Cumulative Reward:  107.36 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.0258\n",
      "Episode Count:  2291 \t Cumulative Reward:  43.48 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.5929\n",
      "Episode Count:  2292 \t Cumulative Reward:  16.33 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7746\n",
      "Episode Count:  2293 \t Cumulative Reward:  12.93 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.7433\n",
      "Episode Count:  2294 \t Cumulative Reward:  23.49 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.8011\n",
      "Episode Count:  2295 \t Cumulative Reward:  50.97 \t eps:  0.101\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.8733\n",
      "Episode Count:  2296 \t Cumulative Reward:  46.33 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.4242\n",
      "Episode Count:  2297 \t Cumulative Reward:  8.89 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.2563\n",
      "Episode Count:  2298 \t Cumulative Reward:  59.95 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.1802\n",
      "Episode Count:  2299 \t Cumulative Reward:  21.56 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.9513\n",
      "Episode Count:  2300 \t Cumulative Reward:  53.02 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.2586\n",
      "Episode Count:  2301 \t Cumulative Reward:  37.02 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 4.2902\n",
      "Episode Count:  2302 \t Cumulative Reward:  152.87 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.2488\n",
      "Episode Count:  2303 \t Cumulative Reward:  22.94 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.0605\n",
      "Episode Count:  2304 \t Cumulative Reward:  8.65 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.2664\n",
      "Episode Count:  2305 \t Cumulative Reward:  46.58 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 4.4762\n",
      "Episode Count:  2306 \t Cumulative Reward:  73.54 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.5801\n",
      "Episode Count:  2307 \t Cumulative Reward:  34.08 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 5.4011\n",
      "Episode Count:  2308 \t Cumulative Reward:  135.11 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.0830\n",
      "Episode Count:  2309 \t Cumulative Reward:  36.63 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.5030\n",
      "Episode Count:  2310 \t Cumulative Reward:  58.02 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 3.9451\n",
      "Episode Count:  2311 \t Cumulative Reward:  93.04 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 4.5359\n",
      "Episode Count:  2312 \t Cumulative Reward:  98.89 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 4.1893\n",
      "Episode Count:  2313 \t Cumulative Reward:  27.89 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 3.8257\n",
      "Episode Count:  2314 \t Cumulative Reward:  45.24 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 3.3989\n",
      "Episode Count:  2315 \t Cumulative Reward:  5.3 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 4.0591\n",
      "Episode Count:  2316 \t Cumulative Reward:  48.35 \t eps:  0.1\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 3.9177\n",
      "Episode Count:  2317 \t Cumulative Reward:  76.11 \t eps:  0.1\n",
      "16/16 [==============================] - 2s 153ms/step - loss: 4.4155\n",
      "Episode Count:  2318 \t Cumulative Reward:  25.15 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 199ms/step - loss: 4.4273\n",
      "Episode Count:  2319 \t Cumulative Reward:  22.74 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 4.1994\n",
      "Episode Count:  2320 \t Cumulative Reward:  14.85 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 3.8129\n",
      "Episode Count:  2321 \t Cumulative Reward:  25.9 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.4451\n",
      "Episode Count:  2322 \t Cumulative Reward:  30.6 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 4.5563\n",
      "Episode Count:  2323 \t Cumulative Reward:  26.43 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 198ms/step - loss: 3.0275\n",
      "Episode Count:  2324 \t Cumulative Reward:  54.92 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 4.8638\n",
      "Episode Count:  2325 \t Cumulative Reward:  39.99 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 4.2034\n",
      "Episode Count:  2326 \t Cumulative Reward:  35.29 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.4288\n",
      "Episode Count:  2327 \t Cumulative Reward:  30.76 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.7571\n",
      "Episode Count:  2328 \t Cumulative Reward:  6.71 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 4.2097\n",
      "Episode Count:  2329 \t Cumulative Reward:  35.28 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 4.2271\n",
      "Episode Count:  2330 \t Cumulative Reward:  -49.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.9217\n",
      "Episode Count:  2331 \t Cumulative Reward:  26.35 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 4.2467\n",
      "Episode Count:  2332 \t Cumulative Reward:  40.82 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 3.4173\n",
      "Episode Count:  2333 \t Cumulative Reward:  19.73 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 3.8164\n",
      "Episode Count:  2334 \t Cumulative Reward:  59.03 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 4.4189\n",
      "Episode Count:  2335 \t Cumulative Reward:  46.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 3.3765\n",
      "Episode Count:  2336 \t Cumulative Reward:  56.31 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 197ms/step - loss: 3.9479\n",
      "Episode Count:  2337 \t Cumulative Reward:  15.41 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 196ms/step - loss: 4.5485\n",
      "Episode Count:  2338 \t Cumulative Reward:  18.84 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 4.1431\n",
      "Episode Count:  2339 \t Cumulative Reward:  35.21 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 4.4379\n",
      "Episode Count:  2340 \t Cumulative Reward:  24.87 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 3.8515\n",
      "Episode Count:  2341 \t Cumulative Reward:  19.03 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 4.1465\n",
      "Episode Count:  2342 \t Cumulative Reward:  72.1 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 5.3170\n",
      "Episode Count:  2343 \t Cumulative Reward:  57.08 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 3.9042\n",
      "Episode Count:  2344 \t Cumulative Reward:  39.98 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.6679\n",
      "Episode Count:  2345 \t Cumulative Reward:  43.7 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 3.7821\n",
      "Episode Count:  2346 \t Cumulative Reward:  28.67 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.8647\n",
      "Episode Count:  2347 \t Cumulative Reward:  27.75 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.6612\n",
      "Episode Count:  2348 \t Cumulative Reward:  13.6 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.5622\n",
      "Episode Count:  2349 \t Cumulative Reward:  15.19 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.5049\n",
      "Episode Count:  2350 \t Cumulative Reward:  11.61 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 3.2997\n",
      "Episode Count:  2351 \t Cumulative Reward:  20.78 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 4.3222\n",
      "Episode Count:  2352 \t Cumulative Reward:  28.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 4.0204\n",
      "Episode Count:  2353 \t Cumulative Reward:  22.59 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.9746\n",
      "Episode Count:  2354 \t Cumulative Reward:  26.95 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 4.0684\n",
      "Episode Count:  2355 \t Cumulative Reward:  29.21 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.8968\n",
      "Episode Count:  2356 \t Cumulative Reward:  10.26 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 4.1054\n",
      "Episode Count:  2357 \t Cumulative Reward:  28.84 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 169ms/step - loss: 3.6130\n",
      "Episode Count:  2358 \t Cumulative Reward:  13.36 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 3.7161\n",
      "Episode Count:  2359 \t Cumulative Reward:  40.53 \t eps:  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 188ms/step - loss: 3.5120\n",
      "Episode Count:  2360 \t Cumulative Reward:  23.88 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 3.4478\n",
      "Episode Count:  2361 \t Cumulative Reward:  41.59 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 4.3492\n",
      "Episode Count:  2362 \t Cumulative Reward:  106.83 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 3.2108\n",
      "Episode Count:  2363 \t Cumulative Reward:  31.87 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 4.5797\n",
      "Episode Count:  2364 \t Cumulative Reward:  47.6 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 4.4326\n",
      "Episode Count:  2365 \t Cumulative Reward:  82.1 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.8967\n",
      "Episode Count:  2366 \t Cumulative Reward:  35.76 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.7110\n",
      "Episode Count:  2367 \t Cumulative Reward:  40.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 193ms/step - loss: 3.8856\n",
      "Episode Count:  2368 \t Cumulative Reward:  30.43 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.6892\n",
      "Episode Count:  2369 \t Cumulative Reward:  24.94 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 3.5429\n",
      "Episode Count:  2370 \t Cumulative Reward:  15.05 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.1427\n",
      "Episode Count:  2371 \t Cumulative Reward:  32.14 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 3.6509\n",
      "Episode Count:  2372 \t Cumulative Reward:  20.14 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 4.1868\n",
      "Episode Count:  2373 \t Cumulative Reward:  25.08 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.4834\n",
      "Episode Count:  2374 \t Cumulative Reward:  55.07 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 4.0621\n",
      "Episode Count:  2375 \t Cumulative Reward:  9.86 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 3.2467\n",
      "Episode Count:  2376 \t Cumulative Reward:  52.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 4.0994\n",
      "Episode Count:  2377 \t Cumulative Reward:  17.99 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 3.5884\n",
      "Episode Count:  2378 \t Cumulative Reward:  23.8 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 3.1111\n",
      "Episode Count:  2379 \t Cumulative Reward:  8.89 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 3.0528\n",
      "Episode Count:  2380 \t Cumulative Reward:  84.67 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 3.6374\n",
      "Episode Count:  2381 \t Cumulative Reward:  51.16 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 3.6902\n",
      "Episode Count:  2382 \t Cumulative Reward:  38.92 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 3.8749\n",
      "Episode Count:  2383 \t Cumulative Reward:  38.65 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 3.6857\n",
      "Episode Count:  2384 \t Cumulative Reward:  30.94 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 3.5085\n",
      "Episode Count:  2385 \t Cumulative Reward:  22.68 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.6774\n",
      "Episode Count:  2386 \t Cumulative Reward:  45.59 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 4.0266\n",
      "Episode Count:  2387 \t Cumulative Reward:  53.63 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.1546\n",
      "Episode Count:  2388 \t Cumulative Reward:  16.26 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.0107\n",
      "Episode Count:  2389 \t Cumulative Reward:  22.06 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 3.3150\n",
      "Episode Count:  2390 \t Cumulative Reward:  23.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.9177\n",
      "Episode Count:  2391 \t Cumulative Reward:  90.5 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.8802\n",
      "Episode Count:  2392 \t Cumulative Reward:  33.83 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.9142\n",
      "Episode Count:  2393 \t Cumulative Reward:  27.8 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 3.4580\n",
      "Episode Count:  2394 \t Cumulative Reward:  41.38 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.0659\n",
      "Episode Count:  2395 \t Cumulative Reward:  27.64 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.9207\n",
      "Episode Count:  2396 \t Cumulative Reward:  31.49 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.4859\n",
      "Episode Count:  2397 \t Cumulative Reward:  18.78 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 3.9861\n",
      "Episode Count:  2398 \t Cumulative Reward:  51.23 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.1326\n",
      "Episode Count:  2399 \t Cumulative Reward:  22.73 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 5.0320\n",
      "run 0: cumulative_reward: 51.33, ran for: 25 timesteps\n",
      "run 1: cumulative_reward: 35.84, ran for: 31 timesteps\n",
      "run 2: cumulative_reward: 39.57, ran for: 10 timesteps\n",
      "run 3: cumulative_reward: 30.51, ran for: 16 timesteps\n",
      "run 4: cumulative_reward: 50.87, ran for: 27 timesteps\n",
      "average performance:  41.624\n",
      "Episode Count:  2400 \t Cumulative Reward:  30.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.1804\n",
      "Episode Count:  2401 \t Cumulative Reward:  23.79 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.9043\n",
      "Episode Count:  2402 \t Cumulative Reward:  30.27 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.5683\n",
      "Episode Count:  2403 \t Cumulative Reward:  51.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 4.1972\n",
      "Episode Count:  2404 \t Cumulative Reward:  43.87 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 3.8280\n",
      "Episode Count:  2405 \t Cumulative Reward:  69.18 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.2616\n",
      "Episode Count:  2406 \t Cumulative Reward:  7.53 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 3.8769\n",
      "Episode Count:  2407 \t Cumulative Reward:  116.98 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 4.1473\n",
      "Episode Count:  2408 \t Cumulative Reward:  11.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 3.8598\n",
      "Episode Count:  2409 \t Cumulative Reward:  12.37 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 4.4358\n",
      "Episode Count:  2410 \t Cumulative Reward:  174.78 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.1821\n",
      "Episode Count:  2411 \t Cumulative Reward:  60.39 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 4.5369\n",
      "Episode Count:  2412 \t Cumulative Reward:  24.36 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.7369\n",
      "Episode Count:  2413 \t Cumulative Reward:  21.92 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 5.1678\n",
      "Episode Count:  2414 \t Cumulative Reward:  85.41 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.9360\n",
      "Episode Count:  2415 \t Cumulative Reward:  30.0 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 4.4095\n",
      "Episode Count:  2416 \t Cumulative Reward:  189.84 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 3.9414\n",
      "Episode Count:  2417 \t Cumulative Reward:  30.43 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 4.9128\n",
      "Episode Count:  2418 \t Cumulative Reward:  63.23 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 4.6350\n",
      "Episode Count:  2419 \t Cumulative Reward:  44.64 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 3.7108\n",
      "Episode Count:  2420 \t Cumulative Reward:  70.52 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.9957\n",
      "Episode Count:  2421 \t Cumulative Reward:  -0.18 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.5695\n",
      "Episode Count:  2422 \t Cumulative Reward:  35.74 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 181ms/step - loss: 4.2390\n",
      "Episode Count:  2423 \t Cumulative Reward:  26.49 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.9759\n",
      "Episode Count:  2424 \t Cumulative Reward:  -0.03 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 4.7000\n",
      "Episode Count:  2425 \t Cumulative Reward:  16.01 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 4.2727\n",
      "Episode Count:  2426 \t Cumulative Reward:  21.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 4.2066\n",
      "Episode Count:  2427 \t Cumulative Reward:  20.98 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 4.2822\n",
      "Episode Count:  2428 \t Cumulative Reward:  25.58 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 4.2178\n",
      "Episode Count:  2429 \t Cumulative Reward:  15.38 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.8086\n",
      "Episode Count:  2430 \t Cumulative Reward:  38.61 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.9545\n",
      "Episode Count:  2431 \t Cumulative Reward:  48.13 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.0832\n",
      "Episode Count:  2432 \t Cumulative Reward:  53.25 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 4.3681\n",
      "Episode Count:  2433 \t Cumulative Reward:  33.6 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 4.1557\n",
      "Episode Count:  2434 \t Cumulative Reward:  102.44 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 3.6240\n",
      "Episode Count:  2435 \t Cumulative Reward:  43.55 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 4.8610\n",
      "Episode Count:  2436 \t Cumulative Reward:  45.48 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.5279\n",
      "Episode Count:  2437 \t Cumulative Reward:  40.26 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 5.0763\n",
      "Episode Count:  2438 \t Cumulative Reward:  24.8 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 5.1271\n",
      "Episode Count:  2439 \t Cumulative Reward:  26.44 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.1154\n",
      "Episode Count:  2440 \t Cumulative Reward:  32.01 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 3.8228\n",
      "Episode Count:  2441 \t Cumulative Reward:  35.27 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 4.2199\n",
      "Episode Count:  2442 \t Cumulative Reward:  21.16 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 4.8322\n",
      "Episode Count:  2443 \t Cumulative Reward:  39.71 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.8650\n",
      "Episode Count:  2444 \t Cumulative Reward:  10.83 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 185ms/step - loss: 3.8232\n",
      "Episode Count:  2445 \t Cumulative Reward:  36.16 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 3.9332\n",
      "Episode Count:  2446 \t Cumulative Reward:  68.43 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.5072\n",
      "Episode Count:  2447 \t Cumulative Reward:  41.3 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.2806\n",
      "Episode Count:  2448 \t Cumulative Reward:  22.79 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 4.6063\n",
      "Episode Count:  2449 \t Cumulative Reward:  85.51 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 4.4608\n",
      "Episode Count:  2450 \t Cumulative Reward:  4.05 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 4.3821\n",
      "Episode Count:  2451 \t Cumulative Reward:  34.52 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 3.5331\n",
      "Episode Count:  2452 \t Cumulative Reward:  -0.26 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.0995\n",
      "Episode Count:  2453 \t Cumulative Reward:  14.67 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 215ms/step - loss: 4.1423\n",
      "Episode Count:  2454 \t Cumulative Reward:  0.61 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 3.8588\n",
      "Episode Count:  2455 \t Cumulative Reward:  29.21 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 189ms/step - loss: 4.4383\n",
      "Episode Count:  2456 \t Cumulative Reward:  41.77 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 4.5483\n",
      "Episode Count:  2457 \t Cumulative Reward:  26.11 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 203ms/step - loss: 3.9123\n",
      "Episode Count:  2458 \t Cumulative Reward:  18.12 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 4.5245\n",
      "Episode Count:  2459 \t Cumulative Reward:  86.13 \t eps:  0.1\n",
      "16/16 [==============================] - 4s 228ms/step - loss: 3.4468\n",
      "Episode Count:  2460 \t Cumulative Reward:  32.62 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 5.3629 1s \n",
      "Episode Count:  2461 \t Cumulative Reward:  19.93 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.9058\n",
      "Episode Count:  2462 \t Cumulative Reward:  53.06 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 194ms/step - loss: 3.8645\n",
      "Episode Count:  2463 \t Cumulative Reward:  120.36 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 4.3552\n",
      "Episode Count:  2464 \t Cumulative Reward:  24.51 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 202ms/step - loss: 5.6782\n",
      "Episode Count:  2465 \t Cumulative Reward:  60.1 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 3.7813\n",
      "Episode Count:  2466 \t Cumulative Reward:  32.07 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 4.0296\n",
      "Episode Count:  2467 \t Cumulative Reward:  8.96 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 201ms/step - loss: 4.5846\n",
      "Episode Count:  2468 \t Cumulative Reward:  57.16 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 4.8626\n",
      "Episode Count:  2469 \t Cumulative Reward:  47.96 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 4.5785\n",
      "Episode Count:  2470 \t Cumulative Reward:  50.41 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 5.0650\n",
      "Episode Count:  2471 \t Cumulative Reward:  -0.59 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 5.2208\n",
      "Episode Count:  2472 \t Cumulative Reward:  23.4 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 4.7252\n",
      "Episode Count:  2473 \t Cumulative Reward:  20.75 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 4.7385\n",
      "Episode Count:  2474 \t Cumulative Reward:  35.35 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 5.0299\n",
      "Episode Count:  2475 \t Cumulative Reward:  61.0 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 217ms/step - loss: 4.7612\n",
      "Episode Count:  2476 \t Cumulative Reward:  25.92 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.1952\n",
      "Episode Count:  2477 \t Cumulative Reward:  4.37 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 4.1300\n",
      "Episode Count:  2478 \t Cumulative Reward:  37.24 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 4.9700\n",
      "Episode Count:  2479 \t Cumulative Reward:  24.09 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.8034\n",
      "Episode Count:  2480 \t Cumulative Reward:  44.32 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 4.7475\n",
      "Episode Count:  2481 \t Cumulative Reward:  57.48 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 4.3699\n",
      "Episode Count:  2482 \t Cumulative Reward:  28.49 \t eps:  0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 176ms/step - loss: 5.1623\n",
      "Episode Count:  2483 \t Cumulative Reward:  19.14 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 4.8798\n",
      "Episode Count:  2484 \t Cumulative Reward:  21.71 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 4.3453\n",
      "Episode Count:  2485 \t Cumulative Reward:  20.15 \t eps:  0.1\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 4.3378\n",
      "Episode Count:  2486 \t Cumulative Reward:  23.55 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 4.3468\n",
      "Episode Count:  2487 \t Cumulative Reward:  17.12 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 4.8319\n",
      "Episode Count:  2488 \t Cumulative Reward:  7.65 \t eps:  0.1\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 5.5147\n",
      "Episode Count:  2489 \t Cumulative Reward:  24.5 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 4.5987\n",
      "Episode Count:  2490 \t Cumulative Reward:  18.25 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 3.8500\n",
      "Episode Count:  2491 \t Cumulative Reward:  37.16 \t eps:  0.1\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 3.9035\n",
      "Episode Count:  2492 \t Cumulative Reward:  31.92 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 4.6966\n",
      "Episode Count:  2493 \t Cumulative Reward:  24.69 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 4.4830\n",
      "Episode Count:  2494 \t Cumulative Reward:  30.59 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 4.4510\n",
      "Episode Count:  2495 \t Cumulative Reward:  16.86 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 4.7280\n",
      "Episode Count:  2496 \t Cumulative Reward:  26.18 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 5.5315\n",
      "Episode Count:  2497 \t Cumulative Reward:  20.26 \t eps:  0.1\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 3.6636\n",
      "Episode Count:  2498 \t Cumulative Reward:  41.04 \t eps:  0.1\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 4.3288\n",
      "Episode Count:  2499 \t Cumulative Reward:  85.36 \t eps:  0.1\n"
     ]
    }
   ],
   "source": [
    "history = train_agent(contd = True,\n",
    "            verbose = True, \n",
    "            save_path = 'training_progress',\n",
    "            contd_path = 'training_progress', \n",
    "            network_name = 'DuelingDdqn.h5',\n",
    "            num_episodes = 1000,\n",
    "            discount = 0.99, \n",
    "            batch_size = 512, \n",
    "            N = 100, # how often to clone the target policy\n",
    "            memory_size = 4096,\n",
    "            eps_decay_rate = 0.999,\n",
    "            max_exp_rate = 0.2, \n",
    "            min_exp_rate = 0.1,\n",
    "            max_reward = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_agent(runs = 10, model_name = 'DuelingDdqn.h5', env = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DQNAgent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
